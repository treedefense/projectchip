// Code generated by pggen DO NOT EDIT.

package db

import (
	"context"
	"database/sql"
	"fmt"
	"github.com/ethanpailes/pgtypes"
	"github.com/opendoor/pggen"
	"github.com/opendoor/pggen/include"
	"github.com/opendoor/pggen/unstable"
	"strings"
	"sync"
)

// PGClient wraps either a 'sql.DB' or a 'sql.Tx'. All pggen-generated
// database access methods for this package are attached to it.
type PGClient struct {
	impl       pgClientImpl
	topLevelDB pggen.DBConn

	errorConverter func(error) error

	// These column indexes are used at run time to enable us to 'SELECT *' against
	// a table that has the same columns in a different order from the ones that we
	// saw in the table we used to generate code. This means that you don't have to worry
	// about migrations merging in a slightly different order than their timestamps have
	// breaking 'SELECT *'.
	rwlockForAccount                    sync.RWMutex
	colIdxTabForAccount                 []int
	rwlockForLocation                   sync.RWMutex
	colIdxTabForLocation                []int
	rwlockForCourse                     sync.RWMutex
	colIdxTabForCourse                  []int
	rwlockForHole                       sync.RWMutex
	colIdxTabForHole                    []int
	rwlockForMatch                      sync.RWMutex
	colIdxTabForMatch                   []int
	rwlockForMatchParticipant           sync.RWMutex
	colIdxTabForMatchParticipant        []int
	rwlockForMatchStroke                sync.RWMutex
	colIdxTabForMatchStroke             []int
	rwlockForGetAllLocationsRow         sync.RWMutex
	colIdxTabForGetAllLocationsRow      []int
	rwlockForGetCoursesAtLocationRow    sync.RWMutex
	colIdxTabForGetCoursesAtLocationRow []int
	rwlockForGetHolesAtCourseRow        sync.RWMutex
	colIdxTabForGetHolesAtCourseRow     []int
}

// bogus usage so we can compile with no tables configured
var _ = sync.RWMutex{}

// NewPGClient creates a new PGClient out of a '*sql.DB' or a
// custom wrapper around a db connection.
//
// If you provide your own wrapper around a '*sql.DB' for logging or
// custom tracing, you MUST forward all calls to an underlying '*sql.DB'
// member of your wrapper.
//
// If the DBConn passed into NewPGClient implements an ErrorConverter
// method which returns a func(error) error, the result of calling the
// ErrorConverter method will be called on every error that the generated
// code returns right before the error is returned. If ErrorConverter
// returns nil or is not present, it will default to the identity function.
func NewPGClient(conn pggen.DBConn) *PGClient {
	client := PGClient{
		topLevelDB: conn,
	}
	client.impl = pgClientImpl{
		db:     conn,
		client: &client,
	}

	// extract the optional error converter routine
	ec, ok := conn.(interface {
		ErrorConverter() func(error) error
	})
	if ok {
		client.errorConverter = ec.ErrorConverter()
	}
	if client.errorConverter == nil {
		client.errorConverter = func(err error) error { return err }
	}

	return &client
}

func (p *PGClient) Handle() pggen.DBHandle {
	return p.topLevelDB
}

func (p *PGClient) BeginTx(ctx context.Context, opts *sql.TxOptions) (*TxPGClient, error) {
	tx, err := p.topLevelDB.BeginTx(ctx, opts)
	if err != nil {
		return nil, p.errorConverter(err)
	}

	return &TxPGClient{
		impl: pgClientImpl{
			db:     tx,
			client: p,
		},
	}, nil
}

func (p *PGClient) Conn(ctx context.Context) (*ConnPGClient, error) {
	conn, err := p.topLevelDB.Conn(ctx)
	if err != nil {
		return nil, p.errorConverter(err)
	}

	return &ConnPGClient{impl: pgClientImpl{db: conn, client: p}}, nil
}

// A postgres client that operates within a transaction. Supports all the same
// generated methods that PGClient does.
type TxPGClient struct {
	impl pgClientImpl
}

func (tx *TxPGClient) Handle() pggen.DBHandle {
	return tx.impl.db.(*sql.Tx)
}

func (tx *TxPGClient) Rollback() error {
	return tx.impl.db.(*sql.Tx).Rollback()
}

func (tx *TxPGClient) Commit() error {
	return tx.impl.db.(*sql.Tx).Commit()
}

type ConnPGClient struct {
	impl pgClientImpl
}

func (conn *ConnPGClient) Close() error {
	return conn.impl.db.(*sql.Conn).Close()
}

func (conn *ConnPGClient) Handle() pggen.DBHandle {
	return conn.impl.db
}

// A database client that can wrap either a direct database connection or a transaction
type pgClientImpl struct {
	db pggen.DBHandle
	// a reference back to the owning PGClient so we can always get at the resolver tables
	client *PGClient
}

func (p *PGClient) GetAccount(
	ctx context.Context,
	id int64,
	opts ...pggen.GetOpt,
) (*Account, error) {
	return p.impl.getAccount(ctx, id)
}
func (tx *TxPGClient) GetAccount(
	ctx context.Context,
	id int64,
	opts ...pggen.GetOpt,
) (*Account, error) {
	return tx.impl.getAccount(ctx, id)
}
func (conn *ConnPGClient) GetAccount(
	ctx context.Context,
	id int64,
	opts ...pggen.GetOpt,
) (*Account, error) {
	return conn.impl.getAccount(ctx, id)
}
func (p *pgClientImpl) getAccount(
	ctx context.Context,
	id int64,
	opts ...pggen.GetOpt,
) (*Account, error) {
	values, err := p.listAccount(ctx, []int64{id}, true /* isGet */)
	if err != nil {
		return nil, err
	}

	// ListAccount always returns the same number of records as were
	// requested, so this is safe.
	return &values[0], err
}

func (p *PGClient) ListAccount(
	ctx context.Context,
	ids []int64,
	opts ...pggen.ListOpt,
) (ret []Account, err error) {
	return p.impl.listAccount(ctx, ids, false /* isGet */, opts...)
}
func (tx *TxPGClient) ListAccount(
	ctx context.Context,
	ids []int64,
	opts ...pggen.ListOpt,
) (ret []Account, err error) {
	return tx.impl.listAccount(ctx, ids, false /* isGet */, opts...)
}
func (conn *ConnPGClient) ListAccount(
	ctx context.Context,
	ids []int64,
	opts ...pggen.ListOpt,
) (ret []Account, err error) {
	return conn.impl.listAccount(ctx, ids, false /* isGet */, opts...)
}
func (p *pgClientImpl) listAccount(
	ctx context.Context,
	ids []int64,
	isGet bool,
	opts ...pggen.ListOpt,
) (ret []Account, err error) {
	opt := pggen.ListOptions{}
	for _, o := range opts {
		o(&opt)
	}
	if len(ids) == 0 {
		return []Account{}, nil
	}

	rows, err := p.queryContext(
		ctx,
		`SELECT * FROM accounts WHERE "id" = ANY($1)`,
		pgtypes.Array(ids),
	)
	if err != nil {
		return nil, p.client.errorConverter(err)
	}
	defer func() {
		if err == nil {
			err = rows.Close()
			if err != nil {
				ret = nil
				err = p.client.errorConverter(err)
			}
		} else {
			rowErr := rows.Close()
			if rowErr != nil {
				err = p.client.errorConverter(fmt.Errorf("%s AND %s", err.Error(), rowErr.Error()))
			}
		}
	}()

	ret = make([]Account, 0, len(ids))
	for rows.Next() {
		var value Account
		err = value.Scan(ctx, p.client, rows)
		if err != nil {
			return nil, p.client.errorConverter(err)
		}
		ret = append(ret, value)
	}

	if len(ret) != len(ids) {
		if isGet {
			return nil, p.client.errorConverter(&unstable.NotFoundError{
				Msg: "GetAccount: record not found",
			})
		} else if !opt.SucceedOnPartialResults {
			return nil, p.client.errorConverter(&unstable.NotFoundError{
				Msg: fmt.Sprintf(
					"ListAccount: asked for %d records, found %d",
					len(ids),
					len(ret),
				),
			})
		}
	}

	return ret, nil
}

// Insert a Account into the database. Returns the primary
// key of the inserted row.
func (p *PGClient) InsertAccount(
	ctx context.Context,
	value *Account,
	opts ...pggen.InsertOpt,
) (ret int64, err error) {
	return p.impl.insertAccount(ctx, value, opts...)
}

// Insert a Account into the database. Returns the primary
// key of the inserted row.
func (tx *TxPGClient) InsertAccount(
	ctx context.Context,
	value *Account,
	opts ...pggen.InsertOpt,
) (ret int64, err error) {
	return tx.impl.insertAccount(ctx, value, opts...)
}

// Insert a Account into the database. Returns the primary
// key of the inserted row.
func (conn *ConnPGClient) InsertAccount(
	ctx context.Context,
	value *Account,
	opts ...pggen.InsertOpt,
) (ret int64, err error) {
	return conn.impl.insertAccount(ctx, value, opts...)
}

// Insert a Account into the database. Returns the primary
// key of the inserted row.
func (p *pgClientImpl) insertAccount(
	ctx context.Context,
	value *Account,
	opts ...pggen.InsertOpt,
) (ret int64, err error) {
	var ids []int64
	ids, err = p.bulkInsertAccount(ctx, []Account{*value}, opts...)
	if err != nil {
		return ret, p.client.errorConverter(err)
	}

	if len(ids) != 1 {
		return ret, p.client.errorConverter(fmt.Errorf("inserting a Account: %d ids (expected 1)", len(ids)))
	}

	ret = ids[0]
	return
}

// Insert a list of Account. Returns a list of the primary keys of
// the inserted rows.
func (p *PGClient) BulkInsertAccount(
	ctx context.Context,
	values []Account,
	opts ...pggen.InsertOpt,
) ([]int64, error) {
	return p.impl.bulkInsertAccount(ctx, values, opts...)
}

// Insert a list of Account. Returns a list of the primary keys of
// the inserted rows.
func (tx *TxPGClient) BulkInsertAccount(
	ctx context.Context,
	values []Account,
	opts ...pggen.InsertOpt,
) ([]int64, error) {
	return tx.impl.bulkInsertAccount(ctx, values, opts...)
}

// Insert a list of Account. Returns a list of the primary keys of
// the inserted rows.
func (conn *ConnPGClient) BulkInsertAccount(
	ctx context.Context,
	values []Account,
	opts ...pggen.InsertOpt,
) ([]int64, error) {
	return conn.impl.bulkInsertAccount(ctx, values, opts...)
}

// Insert a list of Account. Returns a list of the primary keys of
// the inserted rows.
func (p *pgClientImpl) bulkInsertAccount(
	ctx context.Context,
	values []Account,
	opts ...pggen.InsertOpt,
) ([]int64, error) {
	if len(values) == 0 {
		return []int64{}, nil
	}

	opt := pggen.InsertOptions{}
	for _, o := range opts {
		o(&opt)
	}

	defaultFields := opt.DefaultFields.Intersection(defaultableColsForAccount)
	args := make([]interface{}, 0, 3*len(values))
	for _, v := range values {
		if opt.UsePkey && !defaultFields.Test(AccountIdFieldIndex) {
			args = append(args, v.Id)
		}
		if !defaultFields.Test(AccountNicknameFieldIndex) {
			args = append(args, v.Nickname)
		}
		if !defaultFields.Test(AccountEmailFieldIndex) {
			args = append(args, v.Email)
		}
	}

	bulkInsertQuery := genBulkInsertStmt(
		`accounts`,
		fieldsForAccount,
		len(values),
		"id",
		opt.UsePkey,
		defaultFields,
	)

	rows, err := p.queryContext(ctx, bulkInsertQuery, args...)
	if err != nil {
		return nil, p.client.errorConverter(err)
	}
	defer rows.Close()

	ids := make([]int64, 0, len(values))
	for rows.Next() {
		var id int64
		err = rows.Scan(&(id))
		if err != nil {
			return nil, p.client.errorConverter(err)
		}
		ids = append(ids, id)
	}

	return ids, nil
}

// bit indicies for 'fieldMask' parameters
const (
	AccountIdFieldIndex       int = 0
	AccountNicknameFieldIndex int = 1
	AccountEmailFieldIndex    int = 2
	AccountMaxFieldIndex      int = (3 - 1)
)

// A field set saying that all fields in Account should be updated.
// For use as a 'fieldMask' parameter
var AccountAllFields pggen.FieldSet = pggen.NewFieldSetFilled(3)

var defaultableColsForAccount = func() pggen.FieldSet {
	fs := pggen.NewFieldSet(AccountMaxFieldIndex)
	fs.Set(AccountIdFieldIndex, true)
	return fs
}()

var fieldsForAccount []fieldNameAndIdx = []fieldNameAndIdx{
	{name: `id`, idx: AccountIdFieldIndex},
	{name: `nickname`, idx: AccountNicknameFieldIndex},
	{name: `email`, idx: AccountEmailFieldIndex},
}

// Update a Account. 'value' must at the least have
// a primary key set. The 'fieldMask' field set indicates which fields
// should be updated in the database.
//
// Returns the primary key of the updated row.
func (p *PGClient) UpdateAccount(
	ctx context.Context,
	value *Account,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpdateOpt,
) (ret int64, err error) {
	return p.impl.updateAccount(ctx, value, fieldMask, opts...)
}

// Update a Account. 'value' must at the least have
// a primary key set. The 'fieldMask' field set indicates which fields
// should be updated in the database.
//
// Returns the primary key of the updated row.
func (tx *TxPGClient) UpdateAccount(
	ctx context.Context,
	value *Account,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpdateOpt,
) (ret int64, err error) {
	return tx.impl.updateAccount(ctx, value, fieldMask, opts...)
}

// Update a Account. 'value' must at the least have
// a primary key set. The 'fieldMask' field set indicates which fields
// should be updated in the database.
//
// Returns the primary key of the updated row.
func (conn *ConnPGClient) UpdateAccount(
	ctx context.Context,
	value *Account,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpdateOpt,
) (ret int64, err error) {
	return conn.impl.updateAccount(ctx, value, fieldMask, opts...)
}
func (p *pgClientImpl) updateAccount(
	ctx context.Context,
	value *Account,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpdateOpt,
) (ret int64, err error) {
	opt := pggen.UpdateOptions{}
	for _, o := range opts {
		o(&opt)
	}

	if !fieldMask.Test(AccountIdFieldIndex) {
		return ret, p.client.errorConverter(fmt.Errorf(`primary key required for updates to 'accounts'`))
	}

	updateStmt := genUpdateStmt(
		`accounts`,
		"id",
		fieldsForAccount,
		fieldMask,
		"id",
	)

	args := make([]interface{}, 0, 3)
	if fieldMask.Test(AccountIdFieldIndex) {
		args = append(args, value.Id)
	}
	if fieldMask.Test(AccountNicknameFieldIndex) {
		args = append(args, value.Nickname)
	}
	if fieldMask.Test(AccountEmailFieldIndex) {
		args = append(args, value.Email)
	}

	// add the primary key arg for the WHERE condition
	args = append(args, value.Id)

	var id int64
	err = p.db.QueryRowContext(ctx, updateStmt, args...).
		Scan(&(id))
	if err != nil {
		return ret, p.client.errorConverter(err)
	}

	return id, nil
}

// Upsert a Account value. If the given value conflicts with
// an existing row in the database, use the provided value to update that row
// rather than inserting it. Only the fields specified by 'fieldMask' are
// actually updated. All other fields are left as-is.
func (p *PGClient) UpsertAccount(
	ctx context.Context,
	value *Account,
	constraintNames []string,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpsertOpt,
) (ret int64, err error) {
	var val []int64
	val, err = p.impl.bulkUpsertAccount(ctx, []Account{*value}, constraintNames, fieldMask, opts...)
	if err != nil {
		return
	}
	if len(val) == 1 {
		return val[0], nil
	}

	// only possible if no upsert fields were specified by the field mask
	return value.Id, nil
}

// Upsert a Account value. If the given value conflicts with
// an existing row in the database, use the provided value to update that row
// rather than inserting it. Only the fields specified by 'fieldMask' are
// actually updated. All other fields are left as-is.
func (tx *TxPGClient) UpsertAccount(
	ctx context.Context,
	value *Account,
	constraintNames []string,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpsertOpt,
) (ret int64, err error) {
	var val []int64
	val, err = tx.impl.bulkUpsertAccount(ctx, []Account{*value}, constraintNames, fieldMask, opts...)
	if err != nil {
		return
	}
	if len(val) == 1 {
		return val[0], nil
	}

	// only possible if no upsert fields were specified by the field mask
	return value.Id, nil
}

// Upsert a Account value. If the given value conflicts with
// an existing row in the database, use the provided value to update that row
// rather than inserting it. Only the fields specified by 'fieldMask' are
// actually updated. All other fields are left as-is.
func (conn *ConnPGClient) UpsertAccount(
	ctx context.Context,
	value *Account,
	constraintNames []string,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpsertOpt,
) (ret int64, err error) {
	var val []int64
	val, err = conn.impl.bulkUpsertAccount(ctx, []Account{*value}, constraintNames, fieldMask, opts...)
	if err != nil {
		return
	}
	if len(val) == 1 {
		return val[0], nil
	}

	// only possible if no upsert fields were specified by the field mask
	return value.Id, nil
}

// Upsert a set of Account values. If any of the given values conflict with
// existing rows in the database, use the provided values to update the rows which
// exist in the database rather than inserting them. Only the fields specified by
// 'fieldMask' are actually updated. All other fields are left as-is.
func (p *PGClient) BulkUpsertAccount(
	ctx context.Context,
	values []Account,
	constraintNames []string,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpsertOpt,
) (ret []int64, err error) {
	return p.impl.bulkUpsertAccount(ctx, values, constraintNames, fieldMask, opts...)
}

// Upsert a set of Account values. If any of the given values conflict with
// existing rows in the database, use the provided values to update the rows which
// exist in the database rather than inserting them. Only the fields specified by
// 'fieldMask' are actually updated. All other fields are left as-is.
func (tx *TxPGClient) BulkUpsertAccount(
	ctx context.Context,
	values []Account,
	constraintNames []string,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpsertOpt,
) (ret []int64, err error) {
	return tx.impl.bulkUpsertAccount(ctx, values, constraintNames, fieldMask, opts...)
}

// Upsert a set of Account values. If any of the given values conflict with
// existing rows in the database, use the provided values to update the rows which
// exist in the database rather than inserting them. Only the fields specified by
// 'fieldMask' are actually updated. All other fields are left as-is.
func (conn *ConnPGClient) BulkUpsertAccount(
	ctx context.Context,
	values []Account,
	constraintNames []string,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpsertOpt,
) (ret []int64, err error) {
	return conn.impl.bulkUpsertAccount(ctx, values, constraintNames, fieldMask, opts...)
}
func (p *pgClientImpl) bulkUpsertAccount(
	ctx context.Context,
	values []Account,
	constraintNames []string,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpsertOpt,
) ([]int64, error) {
	if len(values) == 0 {
		return []int64{}, nil
	}

	options := pggen.UpsertOptions{}
	for _, opt := range opts {
		opt(&options)
	}

	if constraintNames == nil || len(constraintNames) == 0 {
		constraintNames = []string{`id`}
	}

	defaultFields := options.DefaultFields.Intersection(defaultableColsForAccount)
	var stmt strings.Builder
	genInsertCommon(
		&stmt,
		`accounts`,
		fieldsForAccount,
		len(values),
		`id`,
		options.UsePkey,
		defaultFields,
	)

	setBits := fieldMask.CountSetBits()
	hasConflictAction := setBits > 1 ||
		(setBits == 1 && fieldMask.Test(AccountIdFieldIndex) && options.UsePkey) ||
		(setBits == 1 && !fieldMask.Test(AccountIdFieldIndex))

	if hasConflictAction {
		stmt.WriteString("ON CONFLICT (")
		stmt.WriteString(strings.Join(constraintNames, ","))
		stmt.WriteString(") DO UPDATE SET ")

		updateCols := make([]string, 0, 3)
		updateExprs := make([]string, 0, 3)
		if options.UsePkey {
			updateCols = append(updateCols, `id`)
			updateExprs = append(updateExprs, `excluded.id`)
		}
		if fieldMask.Test(AccountNicknameFieldIndex) {
			updateCols = append(updateCols, `nickname`)
			updateExprs = append(updateExprs, `excluded.nickname`)
		}
		if fieldMask.Test(AccountEmailFieldIndex) {
			updateCols = append(updateCols, `email`)
			updateExprs = append(updateExprs, `excluded.email`)
		}
		if len(updateCols) > 1 {
			stmt.WriteRune('(')
		}
		stmt.WriteString(strings.Join(updateCols, ","))
		if len(updateCols) > 1 {
			stmt.WriteRune(')')
		}
		stmt.WriteString(" = ")
		if len(updateCols) > 1 {
			stmt.WriteRune('(')
		}
		stmt.WriteString(strings.Join(updateExprs, ","))
		if len(updateCols) > 1 {
			stmt.WriteRune(')')
		}
	} else {
		stmt.WriteString("ON CONFLICT DO NOTHING")
	}

	stmt.WriteString(` RETURNING "id"`)

	args := make([]interface{}, 0, 3*len(values))
	for _, v := range values {
		if options.UsePkey && !defaultFields.Test(AccountIdFieldIndex) {
			args = append(args, v.Id)
		}
		if !defaultFields.Test(AccountNicknameFieldIndex) {
			args = append(args, v.Nickname)
		}
		if !defaultFields.Test(AccountEmailFieldIndex) {
			args = append(args, v.Email)
		}
	}

	rows, err := p.queryContext(ctx, stmt.String(), args...)
	if err != nil {
		return nil, p.client.errorConverter(err)
	}
	defer rows.Close()

	ids := make([]int64, 0, len(values))
	for rows.Next() {
		var id int64
		err = rows.Scan(&(id))
		if err != nil {
			return nil, p.client.errorConverter(err)
		}
		ids = append(ids, id)
	}

	return ids, nil
}

func (p *PGClient) DeleteAccount(
	ctx context.Context,
	id int64,
	opts ...pggen.DeleteOpt,
) error {
	return p.impl.bulkDeleteAccount(ctx, []int64{id}, opts...)
}
func (tx *TxPGClient) DeleteAccount(
	ctx context.Context,
	id int64,
	opts ...pggen.DeleteOpt,
) error {
	return tx.impl.bulkDeleteAccount(ctx, []int64{id}, opts...)
}
func (conn *ConnPGClient) DeleteAccount(
	ctx context.Context,
	id int64,
	opts ...pggen.DeleteOpt,
) error {
	return conn.impl.bulkDeleteAccount(ctx, []int64{id}, opts...)
}

func (p *PGClient) BulkDeleteAccount(
	ctx context.Context,
	ids []int64,
	opts ...pggen.DeleteOpt,
) error {
	return p.impl.bulkDeleteAccount(ctx, ids, opts...)
}
func (tx *TxPGClient) BulkDeleteAccount(
	ctx context.Context,
	ids []int64,
	opts ...pggen.DeleteOpt,
) error {
	return tx.impl.bulkDeleteAccount(ctx, ids, opts...)
}
func (conn *ConnPGClient) BulkDeleteAccount(
	ctx context.Context,
	ids []int64,
	opts ...pggen.DeleteOpt,
) error {
	return conn.impl.bulkDeleteAccount(ctx, ids, opts...)
}
func (p *pgClientImpl) bulkDeleteAccount(
	ctx context.Context,
	ids []int64,
	opts ...pggen.DeleteOpt,
) error {
	if len(ids) == 0 {
		return nil
	}

	options := pggen.DeleteOptions{}
	for _, o := range opts {
		o(&options)
	}
	res, err := p.db.ExecContext(
		ctx,
		`DELETE FROM accounts WHERE "id" = ANY($1)`,
		pgtypes.Array(ids),
	)
	if err != nil {
		return p.client.errorConverter(err)
	}

	nrows, err := res.RowsAffected()
	if err != nil {
		return p.client.errorConverter(err)
	}

	if nrows != int64(len(ids)) {
		return p.client.errorConverter(fmt.Errorf(
			"BulkDeleteAccount: %d rows deleted, expected %d",
			nrows,
			len(ids),
		))
	}

	return err
}

var AccountAllIncludes *include.Spec = include.Must(include.Parse(
	`accounts.{match_participants.{accounts,matches.{courses.{holes.{courses,match_strokes.{accounts,holes,matches}},locations.courses,matches},match_participants,match_strokes}},match_strokes}`,
))

func (p *PGClient) AccountFillIncludes(
	ctx context.Context,
	rec *Account,
	includes *include.Spec,
	opts ...pggen.IncludeOpt,
) error {
	return p.impl.privateAccountBulkFillIncludes(ctx, []*Account{rec}, includes)
}
func (tx *TxPGClient) AccountFillIncludes(
	ctx context.Context,
	rec *Account,
	includes *include.Spec,
	opts ...pggen.IncludeOpt,
) error {
	return tx.impl.privateAccountBulkFillIncludes(ctx, []*Account{rec}, includes)
}
func (conn *ConnPGClient) AccountFillIncludes(
	ctx context.Context,
	rec *Account,
	includes *include.Spec,
	opts ...pggen.IncludeOpt,
) error {
	return conn.impl.privateAccountBulkFillIncludes(ctx, []*Account{rec}, includes)
}

func (p *PGClient) AccountBulkFillIncludes(
	ctx context.Context,
	recs []*Account,
	includes *include.Spec,
	opts ...pggen.IncludeOpt,
) error {
	return p.impl.privateAccountBulkFillIncludes(ctx, recs, includes)
}
func (tx *TxPGClient) AccountBulkFillIncludes(
	ctx context.Context,
	recs []*Account,
	includes *include.Spec,
	opts ...pggen.IncludeOpt,
) error {
	return tx.impl.privateAccountBulkFillIncludes(ctx, recs, includes)
}
func (conn *ConnPGClient) AccountBulkFillIncludes(
	ctx context.Context,
	recs []*Account,
	includes *include.Spec,
	opts ...pggen.IncludeOpt,
) error {
	return conn.impl.privateAccountBulkFillIncludes(ctx, recs, includes)
}
func (p *pgClientImpl) privateAccountBulkFillIncludes(
	ctx context.Context,
	recs []*Account,
	includes *include.Spec,
	opts ...pggen.IncludeOpt,
) error {
	loadedRecordTab := map[string]interface{}{}

	return p.implAccountBulkFillIncludes(ctx, recs, includes, loadedRecordTab)
}

func (p *pgClientImpl) implAccountBulkFillIncludes(
	ctx context.Context,
	recs []*Account,
	includes *include.Spec,
	loadedRecordTab map[string]interface{},
) (err error) {
	if includes.TableName != `accounts` {
		return p.client.errorConverter(fmt.Errorf(
			`expected includes for 'accounts', got '%s'`,
			includes.TableName,
		))
	}

	loadedTab, inMap := loadedRecordTab[`accounts`]
	if inMap {
		idToRecord := loadedTab.(map[int64]*Account)
		for _, r := range recs {
			_, alreadyLoaded := idToRecord[r.Id]
			if !alreadyLoaded {
				idToRecord[r.Id] = r
			}
		}
	} else {
		idToRecord := make(map[int64]*Account, len(recs))
		for _, r := range recs {
			idToRecord[r.Id] = r
		}
		loadedRecordTab[`accounts`] = idToRecord
	}
	var subSpec *include.Spec
	var inIncludeSet bool
	// Fill in the MatchParticipants if it is in includes
	subSpec, inIncludeSet = includes.Includes[`match_participants`]
	if inIncludeSet {
		err = p.privateAccountFillMatchParticipants(ctx, loadedRecordTab)
		if err != nil {
			return p.client.errorConverter(err)
		}

		subRecs := make([]*MatchParticipant, 0, len(recs))
		for _, outer := range recs {
			for i := range outer.MatchParticipants {
				subRecs = append(subRecs, outer.MatchParticipants[i])
			}
		}

		err = p.implMatchParticipantBulkFillIncludes(ctx, subRecs, subSpec, loadedRecordTab)
		if err != nil {
			return p.client.errorConverter(err)
		}
	}
	// Fill in the MatchStrokes if it is in includes
	subSpec, inIncludeSet = includes.Includes[`match_strokes`]
	if inIncludeSet {
		err = p.privateAccountFillMatchStrokes(ctx, loadedRecordTab)
		if err != nil {
			return p.client.errorConverter(err)
		}

		subRecs := make([]*MatchStroke, 0, len(recs))
		for _, outer := range recs {
			for i := range outer.MatchStrokes {
				subRecs = append(subRecs, outer.MatchStrokes[i])
			}
		}

		err = p.implMatchStrokeBulkFillIncludes(ctx, subRecs, subSpec, loadedRecordTab)
		if err != nil {
			return p.client.errorConverter(err)
		}
	}

	return
}

// For a given set of Account, fill in all the MatchParticipant
// connected to them using a single query.
func (p *pgClientImpl) privateAccountFillMatchParticipants(
	ctx context.Context,
	loadedRecordTab map[string]interface{},
) error {
	parentLoadedTab, inMap := loadedRecordTab[`accounts`]
	if !inMap {
		return fmt.Errorf("internal pggen error: table not pre-loaded")
	}
	parentIDToRecord := parentLoadedTab.(map[int64]*Account)
	ids := make([]int64, 0, len(parentIDToRecord))
	for _, rec := range parentIDToRecord {
		ids = append(ids, rec.Id)
	}

	var childIDToRecord map[int64]*MatchParticipant
	childLoadedTab, inMap := loadedRecordTab[`match_participants`]
	if inMap {
		childIDToRecord = childLoadedTab.(map[int64]*MatchParticipant)
	} else {
		childIDToRecord = map[int64]*MatchParticipant{}
	}

	rows, err := p.queryContext(
		ctx,
		`SELECT * FROM match_participants
		 WHERE "account_id" = ANY($1)
		 `,
		pgtypes.Array(ids),
	)
	if err != nil {
		return p.client.errorConverter(err)
	}
	defer rows.Close()

	// pull all the child records from the database and associate them with
	// the correct parent.
	for rows.Next() {
		var scannedChildRec MatchParticipant
		err = scannedChildRec.Scan(ctx, p.client, rows)
		if err != nil {
			return p.client.errorConverter(err)
		}

		var childRec *MatchParticipant

		preloadedChildRec, alreadyLoaded := childIDToRecord[scannedChildRec.Id]
		if alreadyLoaded {
			childRec = preloadedChildRec
		} else {
			childRec = &scannedChildRec
			childIDToRecord[scannedChildRec.Id] = &scannedChildRec
		}
		parentRec := parentIDToRecord[childRec.AccountId]
		parentRec.MatchParticipants = append(parentRec.MatchParticipants, childRec)
	}

	loadedRecordTab[`match_participants`] = childIDToRecord

	return nil
}

// For a given set of Account, fill in all the MatchStroke
// connected to them using a single query.
func (p *pgClientImpl) privateAccountFillMatchStrokes(
	ctx context.Context,
	loadedRecordTab map[string]interface{},
) error {
	parentLoadedTab, inMap := loadedRecordTab[`accounts`]
	if !inMap {
		return fmt.Errorf("internal pggen error: table not pre-loaded")
	}
	parentIDToRecord := parentLoadedTab.(map[int64]*Account)
	ids := make([]int64, 0, len(parentIDToRecord))
	for _, rec := range parentIDToRecord {
		ids = append(ids, rec.Id)
	}

	var childIDToRecord map[int64]*MatchStroke
	childLoadedTab, inMap := loadedRecordTab[`match_strokes`]
	if inMap {
		childIDToRecord = childLoadedTab.(map[int64]*MatchStroke)
	} else {
		childIDToRecord = map[int64]*MatchStroke{}
	}

	rows, err := p.queryContext(
		ctx,
		`SELECT * FROM match_strokes
		 WHERE "account_id" = ANY($1)
		 `,
		pgtypes.Array(ids),
	)
	if err != nil {
		return p.client.errorConverter(err)
	}
	defer rows.Close()

	// pull all the child records from the database and associate them with
	// the correct parent.
	for rows.Next() {
		var scannedChildRec MatchStroke
		err = scannedChildRec.Scan(ctx, p.client, rows)
		if err != nil {
			return p.client.errorConverter(err)
		}

		var childRec *MatchStroke

		preloadedChildRec, alreadyLoaded := childIDToRecord[scannedChildRec.Id]
		if alreadyLoaded {
			childRec = preloadedChildRec
		} else {
			childRec = &scannedChildRec
			childIDToRecord[scannedChildRec.Id] = &scannedChildRec
		}
		parentRec := parentIDToRecord[childRec.AccountId]
		parentRec.MatchStrokes = append(parentRec.MatchStrokes, childRec)
	}

	loadedRecordTab[`match_strokes`] = childIDToRecord

	return nil
}

func (p *PGClient) GetLocation(
	ctx context.Context,
	id int64,
	opts ...pggen.GetOpt,
) (*Location, error) {
	return p.impl.getLocation(ctx, id)
}
func (tx *TxPGClient) GetLocation(
	ctx context.Context,
	id int64,
	opts ...pggen.GetOpt,
) (*Location, error) {
	return tx.impl.getLocation(ctx, id)
}
func (conn *ConnPGClient) GetLocation(
	ctx context.Context,
	id int64,
	opts ...pggen.GetOpt,
) (*Location, error) {
	return conn.impl.getLocation(ctx, id)
}
func (p *pgClientImpl) getLocation(
	ctx context.Context,
	id int64,
	opts ...pggen.GetOpt,
) (*Location, error) {
	values, err := p.listLocation(ctx, []int64{id}, true /* isGet */)
	if err != nil {
		return nil, err
	}

	// ListLocation always returns the same number of records as were
	// requested, so this is safe.
	return &values[0], err
}

func (p *PGClient) ListLocation(
	ctx context.Context,
	ids []int64,
	opts ...pggen.ListOpt,
) (ret []Location, err error) {
	return p.impl.listLocation(ctx, ids, false /* isGet */, opts...)
}
func (tx *TxPGClient) ListLocation(
	ctx context.Context,
	ids []int64,
	opts ...pggen.ListOpt,
) (ret []Location, err error) {
	return tx.impl.listLocation(ctx, ids, false /* isGet */, opts...)
}
func (conn *ConnPGClient) ListLocation(
	ctx context.Context,
	ids []int64,
	opts ...pggen.ListOpt,
) (ret []Location, err error) {
	return conn.impl.listLocation(ctx, ids, false /* isGet */, opts...)
}
func (p *pgClientImpl) listLocation(
	ctx context.Context,
	ids []int64,
	isGet bool,
	opts ...pggen.ListOpt,
) (ret []Location, err error) {
	opt := pggen.ListOptions{}
	for _, o := range opts {
		o(&opt)
	}
	if len(ids) == 0 {
		return []Location{}, nil
	}

	rows, err := p.queryContext(
		ctx,
		`SELECT * FROM locations WHERE "id" = ANY($1)`,
		pgtypes.Array(ids),
	)
	if err != nil {
		return nil, p.client.errorConverter(err)
	}
	defer func() {
		if err == nil {
			err = rows.Close()
			if err != nil {
				ret = nil
				err = p.client.errorConverter(err)
			}
		} else {
			rowErr := rows.Close()
			if rowErr != nil {
				err = p.client.errorConverter(fmt.Errorf("%s AND %s", err.Error(), rowErr.Error()))
			}
		}
	}()

	ret = make([]Location, 0, len(ids))
	for rows.Next() {
		var value Location
		err = value.Scan(ctx, p.client, rows)
		if err != nil {
			return nil, p.client.errorConverter(err)
		}
		ret = append(ret, value)
	}

	if len(ret) != len(ids) {
		if isGet {
			return nil, p.client.errorConverter(&unstable.NotFoundError{
				Msg: "GetLocation: record not found",
			})
		} else if !opt.SucceedOnPartialResults {
			return nil, p.client.errorConverter(&unstable.NotFoundError{
				Msg: fmt.Sprintf(
					"ListLocation: asked for %d records, found %d",
					len(ids),
					len(ret),
				),
			})
		}
	}

	return ret, nil
}

// Insert a Location into the database. Returns the primary
// key of the inserted row.
func (p *PGClient) InsertLocation(
	ctx context.Context,
	value *Location,
	opts ...pggen.InsertOpt,
) (ret int64, err error) {
	return p.impl.insertLocation(ctx, value, opts...)
}

// Insert a Location into the database. Returns the primary
// key of the inserted row.
func (tx *TxPGClient) InsertLocation(
	ctx context.Context,
	value *Location,
	opts ...pggen.InsertOpt,
) (ret int64, err error) {
	return tx.impl.insertLocation(ctx, value, opts...)
}

// Insert a Location into the database. Returns the primary
// key of the inserted row.
func (conn *ConnPGClient) InsertLocation(
	ctx context.Context,
	value *Location,
	opts ...pggen.InsertOpt,
) (ret int64, err error) {
	return conn.impl.insertLocation(ctx, value, opts...)
}

// Insert a Location into the database. Returns the primary
// key of the inserted row.
func (p *pgClientImpl) insertLocation(
	ctx context.Context,
	value *Location,
	opts ...pggen.InsertOpt,
) (ret int64, err error) {
	var ids []int64
	ids, err = p.bulkInsertLocation(ctx, []Location{*value}, opts...)
	if err != nil {
		return ret, p.client.errorConverter(err)
	}

	if len(ids) != 1 {
		return ret, p.client.errorConverter(fmt.Errorf("inserting a Location: %d ids (expected 1)", len(ids)))
	}

	ret = ids[0]
	return
}

// Insert a list of Location. Returns a list of the primary keys of
// the inserted rows.
func (p *PGClient) BulkInsertLocation(
	ctx context.Context,
	values []Location,
	opts ...pggen.InsertOpt,
) ([]int64, error) {
	return p.impl.bulkInsertLocation(ctx, values, opts...)
}

// Insert a list of Location. Returns a list of the primary keys of
// the inserted rows.
func (tx *TxPGClient) BulkInsertLocation(
	ctx context.Context,
	values []Location,
	opts ...pggen.InsertOpt,
) ([]int64, error) {
	return tx.impl.bulkInsertLocation(ctx, values, opts...)
}

// Insert a list of Location. Returns a list of the primary keys of
// the inserted rows.
func (conn *ConnPGClient) BulkInsertLocation(
	ctx context.Context,
	values []Location,
	opts ...pggen.InsertOpt,
) ([]int64, error) {
	return conn.impl.bulkInsertLocation(ctx, values, opts...)
}

// Insert a list of Location. Returns a list of the primary keys of
// the inserted rows.
func (p *pgClientImpl) bulkInsertLocation(
	ctx context.Context,
	values []Location,
	opts ...pggen.InsertOpt,
) ([]int64, error) {
	if len(values) == 0 {
		return []int64{}, nil
	}

	opt := pggen.InsertOptions{}
	for _, o := range opts {
		o(&opt)
	}

	defaultFields := opt.DefaultFields.Intersection(defaultableColsForLocation)
	args := make([]interface{}, 0, 2*len(values))
	for _, v := range values {
		if opt.UsePkey && !defaultFields.Test(LocationIdFieldIndex) {
			args = append(args, v.Id)
		}
		if !defaultFields.Test(LocationNameFieldIndex) {
			args = append(args, v.Name)
		}
	}

	bulkInsertQuery := genBulkInsertStmt(
		`locations`,
		fieldsForLocation,
		len(values),
		"id",
		opt.UsePkey,
		defaultFields,
	)

	rows, err := p.queryContext(ctx, bulkInsertQuery, args...)
	if err != nil {
		return nil, p.client.errorConverter(err)
	}
	defer rows.Close()

	ids := make([]int64, 0, len(values))
	for rows.Next() {
		var id int64
		err = rows.Scan(&(id))
		if err != nil {
			return nil, p.client.errorConverter(err)
		}
		ids = append(ids, id)
	}

	return ids, nil
}

// bit indicies for 'fieldMask' parameters
const (
	LocationIdFieldIndex   int = 0
	LocationNameFieldIndex int = 1
	LocationMaxFieldIndex  int = (2 - 1)
)

// A field set saying that all fields in Location should be updated.
// For use as a 'fieldMask' parameter
var LocationAllFields pggen.FieldSet = pggen.NewFieldSetFilled(2)

var defaultableColsForLocation = func() pggen.FieldSet {
	fs := pggen.NewFieldSet(LocationMaxFieldIndex)
	fs.Set(LocationIdFieldIndex, true)
	return fs
}()

var fieldsForLocation []fieldNameAndIdx = []fieldNameAndIdx{
	{name: `id`, idx: LocationIdFieldIndex},
	{name: `name`, idx: LocationNameFieldIndex},
}

// Update a Location. 'value' must at the least have
// a primary key set. The 'fieldMask' field set indicates which fields
// should be updated in the database.
//
// Returns the primary key of the updated row.
func (p *PGClient) UpdateLocation(
	ctx context.Context,
	value *Location,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpdateOpt,
) (ret int64, err error) {
	return p.impl.updateLocation(ctx, value, fieldMask, opts...)
}

// Update a Location. 'value' must at the least have
// a primary key set. The 'fieldMask' field set indicates which fields
// should be updated in the database.
//
// Returns the primary key of the updated row.
func (tx *TxPGClient) UpdateLocation(
	ctx context.Context,
	value *Location,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpdateOpt,
) (ret int64, err error) {
	return tx.impl.updateLocation(ctx, value, fieldMask, opts...)
}

// Update a Location. 'value' must at the least have
// a primary key set. The 'fieldMask' field set indicates which fields
// should be updated in the database.
//
// Returns the primary key of the updated row.
func (conn *ConnPGClient) UpdateLocation(
	ctx context.Context,
	value *Location,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpdateOpt,
) (ret int64, err error) {
	return conn.impl.updateLocation(ctx, value, fieldMask, opts...)
}
func (p *pgClientImpl) updateLocation(
	ctx context.Context,
	value *Location,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpdateOpt,
) (ret int64, err error) {
	opt := pggen.UpdateOptions{}
	for _, o := range opts {
		o(&opt)
	}

	if !fieldMask.Test(LocationIdFieldIndex) {
		return ret, p.client.errorConverter(fmt.Errorf(`primary key required for updates to 'locations'`))
	}

	updateStmt := genUpdateStmt(
		`locations`,
		"id",
		fieldsForLocation,
		fieldMask,
		"id",
	)

	args := make([]interface{}, 0, 2)
	if fieldMask.Test(LocationIdFieldIndex) {
		args = append(args, value.Id)
	}
	if fieldMask.Test(LocationNameFieldIndex) {
		args = append(args, value.Name)
	}

	// add the primary key arg for the WHERE condition
	args = append(args, value.Id)

	var id int64
	err = p.db.QueryRowContext(ctx, updateStmt, args...).
		Scan(&(id))
	if err != nil {
		return ret, p.client.errorConverter(err)
	}

	return id, nil
}

// Upsert a Location value. If the given value conflicts with
// an existing row in the database, use the provided value to update that row
// rather than inserting it. Only the fields specified by 'fieldMask' are
// actually updated. All other fields are left as-is.
func (p *PGClient) UpsertLocation(
	ctx context.Context,
	value *Location,
	constraintNames []string,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpsertOpt,
) (ret int64, err error) {
	var val []int64
	val, err = p.impl.bulkUpsertLocation(ctx, []Location{*value}, constraintNames, fieldMask, opts...)
	if err != nil {
		return
	}
	if len(val) == 1 {
		return val[0], nil
	}

	// only possible if no upsert fields were specified by the field mask
	return value.Id, nil
}

// Upsert a Location value. If the given value conflicts with
// an existing row in the database, use the provided value to update that row
// rather than inserting it. Only the fields specified by 'fieldMask' are
// actually updated. All other fields are left as-is.
func (tx *TxPGClient) UpsertLocation(
	ctx context.Context,
	value *Location,
	constraintNames []string,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpsertOpt,
) (ret int64, err error) {
	var val []int64
	val, err = tx.impl.bulkUpsertLocation(ctx, []Location{*value}, constraintNames, fieldMask, opts...)
	if err != nil {
		return
	}
	if len(val) == 1 {
		return val[0], nil
	}

	// only possible if no upsert fields were specified by the field mask
	return value.Id, nil
}

// Upsert a Location value. If the given value conflicts with
// an existing row in the database, use the provided value to update that row
// rather than inserting it. Only the fields specified by 'fieldMask' are
// actually updated. All other fields are left as-is.
func (conn *ConnPGClient) UpsertLocation(
	ctx context.Context,
	value *Location,
	constraintNames []string,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpsertOpt,
) (ret int64, err error) {
	var val []int64
	val, err = conn.impl.bulkUpsertLocation(ctx, []Location{*value}, constraintNames, fieldMask, opts...)
	if err != nil {
		return
	}
	if len(val) == 1 {
		return val[0], nil
	}

	// only possible if no upsert fields were specified by the field mask
	return value.Id, nil
}

// Upsert a set of Location values. If any of the given values conflict with
// existing rows in the database, use the provided values to update the rows which
// exist in the database rather than inserting them. Only the fields specified by
// 'fieldMask' are actually updated. All other fields are left as-is.
func (p *PGClient) BulkUpsertLocation(
	ctx context.Context,
	values []Location,
	constraintNames []string,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpsertOpt,
) (ret []int64, err error) {
	return p.impl.bulkUpsertLocation(ctx, values, constraintNames, fieldMask, opts...)
}

// Upsert a set of Location values. If any of the given values conflict with
// existing rows in the database, use the provided values to update the rows which
// exist in the database rather than inserting them. Only the fields specified by
// 'fieldMask' are actually updated. All other fields are left as-is.
func (tx *TxPGClient) BulkUpsertLocation(
	ctx context.Context,
	values []Location,
	constraintNames []string,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpsertOpt,
) (ret []int64, err error) {
	return tx.impl.bulkUpsertLocation(ctx, values, constraintNames, fieldMask, opts...)
}

// Upsert a set of Location values. If any of the given values conflict with
// existing rows in the database, use the provided values to update the rows which
// exist in the database rather than inserting them. Only the fields specified by
// 'fieldMask' are actually updated. All other fields are left as-is.
func (conn *ConnPGClient) BulkUpsertLocation(
	ctx context.Context,
	values []Location,
	constraintNames []string,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpsertOpt,
) (ret []int64, err error) {
	return conn.impl.bulkUpsertLocation(ctx, values, constraintNames, fieldMask, opts...)
}
func (p *pgClientImpl) bulkUpsertLocation(
	ctx context.Context,
	values []Location,
	constraintNames []string,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpsertOpt,
) ([]int64, error) {
	if len(values) == 0 {
		return []int64{}, nil
	}

	options := pggen.UpsertOptions{}
	for _, opt := range opts {
		opt(&options)
	}

	if constraintNames == nil || len(constraintNames) == 0 {
		constraintNames = []string{`id`}
	}

	defaultFields := options.DefaultFields.Intersection(defaultableColsForLocation)
	var stmt strings.Builder
	genInsertCommon(
		&stmt,
		`locations`,
		fieldsForLocation,
		len(values),
		`id`,
		options.UsePkey,
		defaultFields,
	)

	setBits := fieldMask.CountSetBits()
	hasConflictAction := setBits > 1 ||
		(setBits == 1 && fieldMask.Test(LocationIdFieldIndex) && options.UsePkey) ||
		(setBits == 1 && !fieldMask.Test(LocationIdFieldIndex))

	if hasConflictAction {
		stmt.WriteString("ON CONFLICT (")
		stmt.WriteString(strings.Join(constraintNames, ","))
		stmt.WriteString(") DO UPDATE SET ")

		updateCols := make([]string, 0, 2)
		updateExprs := make([]string, 0, 2)
		if options.UsePkey {
			updateCols = append(updateCols, `id`)
			updateExprs = append(updateExprs, `excluded.id`)
		}
		if fieldMask.Test(LocationNameFieldIndex) {
			updateCols = append(updateCols, `name`)
			updateExprs = append(updateExprs, `excluded.name`)
		}
		if len(updateCols) > 1 {
			stmt.WriteRune('(')
		}
		stmt.WriteString(strings.Join(updateCols, ","))
		if len(updateCols) > 1 {
			stmt.WriteRune(')')
		}
		stmt.WriteString(" = ")
		if len(updateCols) > 1 {
			stmt.WriteRune('(')
		}
		stmt.WriteString(strings.Join(updateExprs, ","))
		if len(updateCols) > 1 {
			stmt.WriteRune(')')
		}
	} else {
		stmt.WriteString("ON CONFLICT DO NOTHING")
	}

	stmt.WriteString(` RETURNING "id"`)

	args := make([]interface{}, 0, 2*len(values))
	for _, v := range values {
		if options.UsePkey && !defaultFields.Test(LocationIdFieldIndex) {
			args = append(args, v.Id)
		}
		if !defaultFields.Test(LocationNameFieldIndex) {
			args = append(args, v.Name)
		}
	}

	rows, err := p.queryContext(ctx, stmt.String(), args...)
	if err != nil {
		return nil, p.client.errorConverter(err)
	}
	defer rows.Close()

	ids := make([]int64, 0, len(values))
	for rows.Next() {
		var id int64
		err = rows.Scan(&(id))
		if err != nil {
			return nil, p.client.errorConverter(err)
		}
		ids = append(ids, id)
	}

	return ids, nil
}

func (p *PGClient) DeleteLocation(
	ctx context.Context,
	id int64,
	opts ...pggen.DeleteOpt,
) error {
	return p.impl.bulkDeleteLocation(ctx, []int64{id}, opts...)
}
func (tx *TxPGClient) DeleteLocation(
	ctx context.Context,
	id int64,
	opts ...pggen.DeleteOpt,
) error {
	return tx.impl.bulkDeleteLocation(ctx, []int64{id}, opts...)
}
func (conn *ConnPGClient) DeleteLocation(
	ctx context.Context,
	id int64,
	opts ...pggen.DeleteOpt,
) error {
	return conn.impl.bulkDeleteLocation(ctx, []int64{id}, opts...)
}

func (p *PGClient) BulkDeleteLocation(
	ctx context.Context,
	ids []int64,
	opts ...pggen.DeleteOpt,
) error {
	return p.impl.bulkDeleteLocation(ctx, ids, opts...)
}
func (tx *TxPGClient) BulkDeleteLocation(
	ctx context.Context,
	ids []int64,
	opts ...pggen.DeleteOpt,
) error {
	return tx.impl.bulkDeleteLocation(ctx, ids, opts...)
}
func (conn *ConnPGClient) BulkDeleteLocation(
	ctx context.Context,
	ids []int64,
	opts ...pggen.DeleteOpt,
) error {
	return conn.impl.bulkDeleteLocation(ctx, ids, opts...)
}
func (p *pgClientImpl) bulkDeleteLocation(
	ctx context.Context,
	ids []int64,
	opts ...pggen.DeleteOpt,
) error {
	if len(ids) == 0 {
		return nil
	}

	options := pggen.DeleteOptions{}
	for _, o := range opts {
		o(&options)
	}
	res, err := p.db.ExecContext(
		ctx,
		`DELETE FROM locations WHERE "id" = ANY($1)`,
		pgtypes.Array(ids),
	)
	if err != nil {
		return p.client.errorConverter(err)
	}

	nrows, err := res.RowsAffected()
	if err != nil {
		return p.client.errorConverter(err)
	}

	if nrows != int64(len(ids)) {
		return p.client.errorConverter(fmt.Errorf(
			"BulkDeleteLocation: %d rows deleted, expected %d",
			nrows,
			len(ids),
		))
	}

	return err
}

var LocationAllIncludes *include.Spec = include.Must(include.Parse(
	`locations.courses.{holes.{courses,match_strokes.{accounts.{match_participants.{accounts,matches.{courses,match_participants,match_strokes}},match_strokes},holes,matches}},locations,matches}`,
))

func (p *PGClient) LocationFillIncludes(
	ctx context.Context,
	rec *Location,
	includes *include.Spec,
	opts ...pggen.IncludeOpt,
) error {
	return p.impl.privateLocationBulkFillIncludes(ctx, []*Location{rec}, includes)
}
func (tx *TxPGClient) LocationFillIncludes(
	ctx context.Context,
	rec *Location,
	includes *include.Spec,
	opts ...pggen.IncludeOpt,
) error {
	return tx.impl.privateLocationBulkFillIncludes(ctx, []*Location{rec}, includes)
}
func (conn *ConnPGClient) LocationFillIncludes(
	ctx context.Context,
	rec *Location,
	includes *include.Spec,
	opts ...pggen.IncludeOpt,
) error {
	return conn.impl.privateLocationBulkFillIncludes(ctx, []*Location{rec}, includes)
}

func (p *PGClient) LocationBulkFillIncludes(
	ctx context.Context,
	recs []*Location,
	includes *include.Spec,
	opts ...pggen.IncludeOpt,
) error {
	return p.impl.privateLocationBulkFillIncludes(ctx, recs, includes)
}
func (tx *TxPGClient) LocationBulkFillIncludes(
	ctx context.Context,
	recs []*Location,
	includes *include.Spec,
	opts ...pggen.IncludeOpt,
) error {
	return tx.impl.privateLocationBulkFillIncludes(ctx, recs, includes)
}
func (conn *ConnPGClient) LocationBulkFillIncludes(
	ctx context.Context,
	recs []*Location,
	includes *include.Spec,
	opts ...pggen.IncludeOpt,
) error {
	return conn.impl.privateLocationBulkFillIncludes(ctx, recs, includes)
}
func (p *pgClientImpl) privateLocationBulkFillIncludes(
	ctx context.Context,
	recs []*Location,
	includes *include.Spec,
	opts ...pggen.IncludeOpt,
) error {
	loadedRecordTab := map[string]interface{}{}

	return p.implLocationBulkFillIncludes(ctx, recs, includes, loadedRecordTab)
}

func (p *pgClientImpl) implLocationBulkFillIncludes(
	ctx context.Context,
	recs []*Location,
	includes *include.Spec,
	loadedRecordTab map[string]interface{},
) (err error) {
	if includes.TableName != `locations` {
		return p.client.errorConverter(fmt.Errorf(
			`expected includes for 'locations', got '%s'`,
			includes.TableName,
		))
	}

	loadedTab, inMap := loadedRecordTab[`locations`]
	if inMap {
		idToRecord := loadedTab.(map[int64]*Location)
		for _, r := range recs {
			_, alreadyLoaded := idToRecord[r.Id]
			if !alreadyLoaded {
				idToRecord[r.Id] = r
			}
		}
	} else {
		idToRecord := make(map[int64]*Location, len(recs))
		for _, r := range recs {
			idToRecord[r.Id] = r
		}
		loadedRecordTab[`locations`] = idToRecord
	}
	var subSpec *include.Spec
	var inIncludeSet bool
	// Fill in the Courses if it is in includes
	subSpec, inIncludeSet = includes.Includes[`courses`]
	if inIncludeSet {
		err = p.privateLocationFillCourses(ctx, loadedRecordTab)
		if err != nil {
			return p.client.errorConverter(err)
		}

		subRecs := make([]*Course, 0, len(recs))
		for _, outer := range recs {
			for i := range outer.Courses {
				if outer.Courses[i] == nil {
					continue
				}
				subRecs = append(subRecs, outer.Courses[i])
			}
		}

		err = p.implCourseBulkFillIncludes(ctx, subRecs, subSpec, loadedRecordTab)
		if err != nil {
			return p.client.errorConverter(err)
		}
	}

	return
}

// For a given set of Location, fill in all the Course
// connected to them using a single query.
func (p *pgClientImpl) privateLocationFillCourses(
	ctx context.Context,
	loadedRecordTab map[string]interface{},
) error {
	parentLoadedTab, inMap := loadedRecordTab[`locations`]
	if !inMap {
		return fmt.Errorf("internal pggen error: table not pre-loaded")
	}
	parentIDToRecord := parentLoadedTab.(map[int64]*Location)
	ids := make([]int64, 0, len(parentIDToRecord))
	for _, rec := range parentIDToRecord {
		ids = append(ids, rec.Id)
	}

	var childIDToRecord map[int64]*Course
	childLoadedTab, inMap := loadedRecordTab[`courses`]
	if inMap {
		childIDToRecord = childLoadedTab.(map[int64]*Course)
	} else {
		childIDToRecord = map[int64]*Course{}
	}

	rows, err := p.queryContext(
		ctx,
		`SELECT * FROM courses
		 WHERE "location_id" = ANY($1)
		 `,
		pgtypes.Array(ids),
	)
	if err != nil {
		return p.client.errorConverter(err)
	}
	defer rows.Close()

	// pull all the child records from the database and associate them with
	// the correct parent.
	for rows.Next() {
		var scannedChildRec Course
		err = scannedChildRec.Scan(ctx, p.client, rows)
		if err != nil {
			return p.client.errorConverter(err)
		}

		var childRec *Course

		preloadedChildRec, alreadyLoaded := childIDToRecord[scannedChildRec.Id]
		if alreadyLoaded {
			childRec = preloadedChildRec
		} else {
			childRec = &scannedChildRec
			childIDToRecord[scannedChildRec.Id] = &scannedChildRec
		}
		// we know that the foreign key can't be null because of the SQL query
		parentRec := parentIDToRecord[*childRec.LocationId]
		parentRec.Courses = append(parentRec.Courses, childRec)
	}

	loadedRecordTab[`courses`] = childIDToRecord

	return nil
}

func (p *PGClient) GetCourse(
	ctx context.Context,
	id int64,
	opts ...pggen.GetOpt,
) (*Course, error) {
	return p.impl.getCourse(ctx, id)
}
func (tx *TxPGClient) GetCourse(
	ctx context.Context,
	id int64,
	opts ...pggen.GetOpt,
) (*Course, error) {
	return tx.impl.getCourse(ctx, id)
}
func (conn *ConnPGClient) GetCourse(
	ctx context.Context,
	id int64,
	opts ...pggen.GetOpt,
) (*Course, error) {
	return conn.impl.getCourse(ctx, id)
}
func (p *pgClientImpl) getCourse(
	ctx context.Context,
	id int64,
	opts ...pggen.GetOpt,
) (*Course, error) {
	values, err := p.listCourse(ctx, []int64{id}, true /* isGet */)
	if err != nil {
		return nil, err
	}

	// ListCourse always returns the same number of records as were
	// requested, so this is safe.
	return &values[0], err
}

func (p *PGClient) ListCourse(
	ctx context.Context,
	ids []int64,
	opts ...pggen.ListOpt,
) (ret []Course, err error) {
	return p.impl.listCourse(ctx, ids, false /* isGet */, opts...)
}
func (tx *TxPGClient) ListCourse(
	ctx context.Context,
	ids []int64,
	opts ...pggen.ListOpt,
) (ret []Course, err error) {
	return tx.impl.listCourse(ctx, ids, false /* isGet */, opts...)
}
func (conn *ConnPGClient) ListCourse(
	ctx context.Context,
	ids []int64,
	opts ...pggen.ListOpt,
) (ret []Course, err error) {
	return conn.impl.listCourse(ctx, ids, false /* isGet */, opts...)
}
func (p *pgClientImpl) listCourse(
	ctx context.Context,
	ids []int64,
	isGet bool,
	opts ...pggen.ListOpt,
) (ret []Course, err error) {
	opt := pggen.ListOptions{}
	for _, o := range opts {
		o(&opt)
	}
	if len(ids) == 0 {
		return []Course{}, nil
	}

	rows, err := p.queryContext(
		ctx,
		`SELECT * FROM courses WHERE "id" = ANY($1)`,
		pgtypes.Array(ids),
	)
	if err != nil {
		return nil, p.client.errorConverter(err)
	}
	defer func() {
		if err == nil {
			err = rows.Close()
			if err != nil {
				ret = nil
				err = p.client.errorConverter(err)
			}
		} else {
			rowErr := rows.Close()
			if rowErr != nil {
				err = p.client.errorConverter(fmt.Errorf("%s AND %s", err.Error(), rowErr.Error()))
			}
		}
	}()

	ret = make([]Course, 0, len(ids))
	for rows.Next() {
		var value Course
		err = value.Scan(ctx, p.client, rows)
		if err != nil {
			return nil, p.client.errorConverter(err)
		}
		ret = append(ret, value)
	}

	if len(ret) != len(ids) {
		if isGet {
			return nil, p.client.errorConverter(&unstable.NotFoundError{
				Msg: "GetCourse: record not found",
			})
		} else if !opt.SucceedOnPartialResults {
			return nil, p.client.errorConverter(&unstable.NotFoundError{
				Msg: fmt.Sprintf(
					"ListCourse: asked for %d records, found %d",
					len(ids),
					len(ret),
				),
			})
		}
	}

	return ret, nil
}

// Insert a Course into the database. Returns the primary
// key of the inserted row.
func (p *PGClient) InsertCourse(
	ctx context.Context,
	value *Course,
	opts ...pggen.InsertOpt,
) (ret int64, err error) {
	return p.impl.insertCourse(ctx, value, opts...)
}

// Insert a Course into the database. Returns the primary
// key of the inserted row.
func (tx *TxPGClient) InsertCourse(
	ctx context.Context,
	value *Course,
	opts ...pggen.InsertOpt,
) (ret int64, err error) {
	return tx.impl.insertCourse(ctx, value, opts...)
}

// Insert a Course into the database. Returns the primary
// key of the inserted row.
func (conn *ConnPGClient) InsertCourse(
	ctx context.Context,
	value *Course,
	opts ...pggen.InsertOpt,
) (ret int64, err error) {
	return conn.impl.insertCourse(ctx, value, opts...)
}

// Insert a Course into the database. Returns the primary
// key of the inserted row.
func (p *pgClientImpl) insertCourse(
	ctx context.Context,
	value *Course,
	opts ...pggen.InsertOpt,
) (ret int64, err error) {
	var ids []int64
	ids, err = p.bulkInsertCourse(ctx, []Course{*value}, opts...)
	if err != nil {
		return ret, p.client.errorConverter(err)
	}

	if len(ids) != 1 {
		return ret, p.client.errorConverter(fmt.Errorf("inserting a Course: %d ids (expected 1)", len(ids)))
	}

	ret = ids[0]
	return
}

// Insert a list of Course. Returns a list of the primary keys of
// the inserted rows.
func (p *PGClient) BulkInsertCourse(
	ctx context.Context,
	values []Course,
	opts ...pggen.InsertOpt,
) ([]int64, error) {
	return p.impl.bulkInsertCourse(ctx, values, opts...)
}

// Insert a list of Course. Returns a list of the primary keys of
// the inserted rows.
func (tx *TxPGClient) BulkInsertCourse(
	ctx context.Context,
	values []Course,
	opts ...pggen.InsertOpt,
) ([]int64, error) {
	return tx.impl.bulkInsertCourse(ctx, values, opts...)
}

// Insert a list of Course. Returns a list of the primary keys of
// the inserted rows.
func (conn *ConnPGClient) BulkInsertCourse(
	ctx context.Context,
	values []Course,
	opts ...pggen.InsertOpt,
) ([]int64, error) {
	return conn.impl.bulkInsertCourse(ctx, values, opts...)
}

// Insert a list of Course. Returns a list of the primary keys of
// the inserted rows.
func (p *pgClientImpl) bulkInsertCourse(
	ctx context.Context,
	values []Course,
	opts ...pggen.InsertOpt,
) ([]int64, error) {
	if len(values) == 0 {
		return []int64{}, nil
	}

	opt := pggen.InsertOptions{}
	for _, o := range opts {
		o(&opt)
	}

	defaultFields := opt.DefaultFields.Intersection(defaultableColsForCourse)
	args := make([]interface{}, 0, 3*len(values))
	for _, v := range values {
		if opt.UsePkey && !defaultFields.Test(CourseIdFieldIndex) {
			args = append(args, v.Id)
		}
		if !defaultFields.Test(CourseLocationIdFieldIndex) {
			args = append(args, v.LocationId)
		}
		if !defaultFields.Test(CourseNameFieldIndex) {
			args = append(args, v.Name)
		}
	}

	bulkInsertQuery := genBulkInsertStmt(
		`courses`,
		fieldsForCourse,
		len(values),
		"id",
		opt.UsePkey,
		defaultFields,
	)

	rows, err := p.queryContext(ctx, bulkInsertQuery, args...)
	if err != nil {
		return nil, p.client.errorConverter(err)
	}
	defer rows.Close()

	ids := make([]int64, 0, len(values))
	for rows.Next() {
		var id int64
		err = rows.Scan(&(id))
		if err != nil {
			return nil, p.client.errorConverter(err)
		}
		ids = append(ids, id)
	}

	return ids, nil
}

// bit indicies for 'fieldMask' parameters
const (
	CourseIdFieldIndex         int = 0
	CourseLocationIdFieldIndex int = 1
	CourseNameFieldIndex       int = 2
	CourseMaxFieldIndex        int = (3 - 1)
)

// A field set saying that all fields in Course should be updated.
// For use as a 'fieldMask' parameter
var CourseAllFields pggen.FieldSet = pggen.NewFieldSetFilled(3)

var defaultableColsForCourse = func() pggen.FieldSet {
	fs := pggen.NewFieldSet(CourseMaxFieldIndex)
	fs.Set(CourseIdFieldIndex, true)
	return fs
}()

var fieldsForCourse []fieldNameAndIdx = []fieldNameAndIdx{
	{name: `id`, idx: CourseIdFieldIndex},
	{name: `location_id`, idx: CourseLocationIdFieldIndex},
	{name: `name`, idx: CourseNameFieldIndex},
}

// Update a Course. 'value' must at the least have
// a primary key set. The 'fieldMask' field set indicates which fields
// should be updated in the database.
//
// Returns the primary key of the updated row.
func (p *PGClient) UpdateCourse(
	ctx context.Context,
	value *Course,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpdateOpt,
) (ret int64, err error) {
	return p.impl.updateCourse(ctx, value, fieldMask, opts...)
}

// Update a Course. 'value' must at the least have
// a primary key set. The 'fieldMask' field set indicates which fields
// should be updated in the database.
//
// Returns the primary key of the updated row.
func (tx *TxPGClient) UpdateCourse(
	ctx context.Context,
	value *Course,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpdateOpt,
) (ret int64, err error) {
	return tx.impl.updateCourse(ctx, value, fieldMask, opts...)
}

// Update a Course. 'value' must at the least have
// a primary key set. The 'fieldMask' field set indicates which fields
// should be updated in the database.
//
// Returns the primary key of the updated row.
func (conn *ConnPGClient) UpdateCourse(
	ctx context.Context,
	value *Course,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpdateOpt,
) (ret int64, err error) {
	return conn.impl.updateCourse(ctx, value, fieldMask, opts...)
}
func (p *pgClientImpl) updateCourse(
	ctx context.Context,
	value *Course,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpdateOpt,
) (ret int64, err error) {
	opt := pggen.UpdateOptions{}
	for _, o := range opts {
		o(&opt)
	}

	if !fieldMask.Test(CourseIdFieldIndex) {
		return ret, p.client.errorConverter(fmt.Errorf(`primary key required for updates to 'courses'`))
	}

	updateStmt := genUpdateStmt(
		`courses`,
		"id",
		fieldsForCourse,
		fieldMask,
		"id",
	)

	args := make([]interface{}, 0, 3)
	if fieldMask.Test(CourseIdFieldIndex) {
		args = append(args, value.Id)
	}
	if fieldMask.Test(CourseLocationIdFieldIndex) {
		args = append(args, value.LocationId)
	}
	if fieldMask.Test(CourseNameFieldIndex) {
		args = append(args, value.Name)
	}

	// add the primary key arg for the WHERE condition
	args = append(args, value.Id)

	var id int64
	err = p.db.QueryRowContext(ctx, updateStmt, args...).
		Scan(&(id))
	if err != nil {
		return ret, p.client.errorConverter(err)
	}

	return id, nil
}

// Upsert a Course value. If the given value conflicts with
// an existing row in the database, use the provided value to update that row
// rather than inserting it. Only the fields specified by 'fieldMask' are
// actually updated. All other fields are left as-is.
func (p *PGClient) UpsertCourse(
	ctx context.Context,
	value *Course,
	constraintNames []string,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpsertOpt,
) (ret int64, err error) {
	var val []int64
	val, err = p.impl.bulkUpsertCourse(ctx, []Course{*value}, constraintNames, fieldMask, opts...)
	if err != nil {
		return
	}
	if len(val) == 1 {
		return val[0], nil
	}

	// only possible if no upsert fields were specified by the field mask
	return value.Id, nil
}

// Upsert a Course value. If the given value conflicts with
// an existing row in the database, use the provided value to update that row
// rather than inserting it. Only the fields specified by 'fieldMask' are
// actually updated. All other fields are left as-is.
func (tx *TxPGClient) UpsertCourse(
	ctx context.Context,
	value *Course,
	constraintNames []string,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpsertOpt,
) (ret int64, err error) {
	var val []int64
	val, err = tx.impl.bulkUpsertCourse(ctx, []Course{*value}, constraintNames, fieldMask, opts...)
	if err != nil {
		return
	}
	if len(val) == 1 {
		return val[0], nil
	}

	// only possible if no upsert fields were specified by the field mask
	return value.Id, nil
}

// Upsert a Course value. If the given value conflicts with
// an existing row in the database, use the provided value to update that row
// rather than inserting it. Only the fields specified by 'fieldMask' are
// actually updated. All other fields are left as-is.
func (conn *ConnPGClient) UpsertCourse(
	ctx context.Context,
	value *Course,
	constraintNames []string,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpsertOpt,
) (ret int64, err error) {
	var val []int64
	val, err = conn.impl.bulkUpsertCourse(ctx, []Course{*value}, constraintNames, fieldMask, opts...)
	if err != nil {
		return
	}
	if len(val) == 1 {
		return val[0], nil
	}

	// only possible if no upsert fields were specified by the field mask
	return value.Id, nil
}

// Upsert a set of Course values. If any of the given values conflict with
// existing rows in the database, use the provided values to update the rows which
// exist in the database rather than inserting them. Only the fields specified by
// 'fieldMask' are actually updated. All other fields are left as-is.
func (p *PGClient) BulkUpsertCourse(
	ctx context.Context,
	values []Course,
	constraintNames []string,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpsertOpt,
) (ret []int64, err error) {
	return p.impl.bulkUpsertCourse(ctx, values, constraintNames, fieldMask, opts...)
}

// Upsert a set of Course values. If any of the given values conflict with
// existing rows in the database, use the provided values to update the rows which
// exist in the database rather than inserting them. Only the fields specified by
// 'fieldMask' are actually updated. All other fields are left as-is.
func (tx *TxPGClient) BulkUpsertCourse(
	ctx context.Context,
	values []Course,
	constraintNames []string,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpsertOpt,
) (ret []int64, err error) {
	return tx.impl.bulkUpsertCourse(ctx, values, constraintNames, fieldMask, opts...)
}

// Upsert a set of Course values. If any of the given values conflict with
// existing rows in the database, use the provided values to update the rows which
// exist in the database rather than inserting them. Only the fields specified by
// 'fieldMask' are actually updated. All other fields are left as-is.
func (conn *ConnPGClient) BulkUpsertCourse(
	ctx context.Context,
	values []Course,
	constraintNames []string,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpsertOpt,
) (ret []int64, err error) {
	return conn.impl.bulkUpsertCourse(ctx, values, constraintNames, fieldMask, opts...)
}
func (p *pgClientImpl) bulkUpsertCourse(
	ctx context.Context,
	values []Course,
	constraintNames []string,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpsertOpt,
) ([]int64, error) {
	if len(values) == 0 {
		return []int64{}, nil
	}

	options := pggen.UpsertOptions{}
	for _, opt := range opts {
		opt(&options)
	}

	if constraintNames == nil || len(constraintNames) == 0 {
		constraintNames = []string{`id`}
	}

	defaultFields := options.DefaultFields.Intersection(defaultableColsForCourse)
	var stmt strings.Builder
	genInsertCommon(
		&stmt,
		`courses`,
		fieldsForCourse,
		len(values),
		`id`,
		options.UsePkey,
		defaultFields,
	)

	setBits := fieldMask.CountSetBits()
	hasConflictAction := setBits > 1 ||
		(setBits == 1 && fieldMask.Test(CourseIdFieldIndex) && options.UsePkey) ||
		(setBits == 1 && !fieldMask.Test(CourseIdFieldIndex))

	if hasConflictAction {
		stmt.WriteString("ON CONFLICT (")
		stmt.WriteString(strings.Join(constraintNames, ","))
		stmt.WriteString(") DO UPDATE SET ")

		updateCols := make([]string, 0, 3)
		updateExprs := make([]string, 0, 3)
		if options.UsePkey {
			updateCols = append(updateCols, `id`)
			updateExprs = append(updateExprs, `excluded.id`)
		}
		if fieldMask.Test(CourseLocationIdFieldIndex) {
			updateCols = append(updateCols, `location_id`)
			updateExprs = append(updateExprs, `excluded.location_id`)
		}
		if fieldMask.Test(CourseNameFieldIndex) {
			updateCols = append(updateCols, `name`)
			updateExprs = append(updateExprs, `excluded.name`)
		}
		if len(updateCols) > 1 {
			stmt.WriteRune('(')
		}
		stmt.WriteString(strings.Join(updateCols, ","))
		if len(updateCols) > 1 {
			stmt.WriteRune(')')
		}
		stmt.WriteString(" = ")
		if len(updateCols) > 1 {
			stmt.WriteRune('(')
		}
		stmt.WriteString(strings.Join(updateExprs, ","))
		if len(updateCols) > 1 {
			stmt.WriteRune(')')
		}
	} else {
		stmt.WriteString("ON CONFLICT DO NOTHING")
	}

	stmt.WriteString(` RETURNING "id"`)

	args := make([]interface{}, 0, 3*len(values))
	for _, v := range values {
		if options.UsePkey && !defaultFields.Test(CourseIdFieldIndex) {
			args = append(args, v.Id)
		}
		if !defaultFields.Test(CourseLocationIdFieldIndex) {
			args = append(args, v.LocationId)
		}
		if !defaultFields.Test(CourseNameFieldIndex) {
			args = append(args, v.Name)
		}
	}

	rows, err := p.queryContext(ctx, stmt.String(), args...)
	if err != nil {
		return nil, p.client.errorConverter(err)
	}
	defer rows.Close()

	ids := make([]int64, 0, len(values))
	for rows.Next() {
		var id int64
		err = rows.Scan(&(id))
		if err != nil {
			return nil, p.client.errorConverter(err)
		}
		ids = append(ids, id)
	}

	return ids, nil
}

func (p *PGClient) DeleteCourse(
	ctx context.Context,
	id int64,
	opts ...pggen.DeleteOpt,
) error {
	return p.impl.bulkDeleteCourse(ctx, []int64{id}, opts...)
}
func (tx *TxPGClient) DeleteCourse(
	ctx context.Context,
	id int64,
	opts ...pggen.DeleteOpt,
) error {
	return tx.impl.bulkDeleteCourse(ctx, []int64{id}, opts...)
}
func (conn *ConnPGClient) DeleteCourse(
	ctx context.Context,
	id int64,
	opts ...pggen.DeleteOpt,
) error {
	return conn.impl.bulkDeleteCourse(ctx, []int64{id}, opts...)
}

func (p *PGClient) BulkDeleteCourse(
	ctx context.Context,
	ids []int64,
	opts ...pggen.DeleteOpt,
) error {
	return p.impl.bulkDeleteCourse(ctx, ids, opts...)
}
func (tx *TxPGClient) BulkDeleteCourse(
	ctx context.Context,
	ids []int64,
	opts ...pggen.DeleteOpt,
) error {
	return tx.impl.bulkDeleteCourse(ctx, ids, opts...)
}
func (conn *ConnPGClient) BulkDeleteCourse(
	ctx context.Context,
	ids []int64,
	opts ...pggen.DeleteOpt,
) error {
	return conn.impl.bulkDeleteCourse(ctx, ids, opts...)
}
func (p *pgClientImpl) bulkDeleteCourse(
	ctx context.Context,
	ids []int64,
	opts ...pggen.DeleteOpt,
) error {
	if len(ids) == 0 {
		return nil
	}

	options := pggen.DeleteOptions{}
	for _, o := range opts {
		o(&options)
	}
	res, err := p.db.ExecContext(
		ctx,
		`DELETE FROM courses WHERE "id" = ANY($1)`,
		pgtypes.Array(ids),
	)
	if err != nil {
		return p.client.errorConverter(err)
	}

	nrows, err := res.RowsAffected()
	if err != nil {
		return p.client.errorConverter(err)
	}

	if nrows != int64(len(ids)) {
		return p.client.errorConverter(fmt.Errorf(
			"BulkDeleteCourse: %d rows deleted, expected %d",
			nrows,
			len(ids),
		))
	}

	return err
}

var CourseAllIncludes *include.Spec = include.Must(include.Parse(
	`courses.{holes.{courses,match_strokes.{accounts.{match_participants.{accounts,matches.{courses,match_participants,match_strokes}},match_strokes},holes,matches}},locations.courses,matches}`,
))

func (p *PGClient) CourseFillIncludes(
	ctx context.Context,
	rec *Course,
	includes *include.Spec,
	opts ...pggen.IncludeOpt,
) error {
	return p.impl.privateCourseBulkFillIncludes(ctx, []*Course{rec}, includes)
}
func (tx *TxPGClient) CourseFillIncludes(
	ctx context.Context,
	rec *Course,
	includes *include.Spec,
	opts ...pggen.IncludeOpt,
) error {
	return tx.impl.privateCourseBulkFillIncludes(ctx, []*Course{rec}, includes)
}
func (conn *ConnPGClient) CourseFillIncludes(
	ctx context.Context,
	rec *Course,
	includes *include.Spec,
	opts ...pggen.IncludeOpt,
) error {
	return conn.impl.privateCourseBulkFillIncludes(ctx, []*Course{rec}, includes)
}

func (p *PGClient) CourseBulkFillIncludes(
	ctx context.Context,
	recs []*Course,
	includes *include.Spec,
	opts ...pggen.IncludeOpt,
) error {
	return p.impl.privateCourseBulkFillIncludes(ctx, recs, includes)
}
func (tx *TxPGClient) CourseBulkFillIncludes(
	ctx context.Context,
	recs []*Course,
	includes *include.Spec,
	opts ...pggen.IncludeOpt,
) error {
	return tx.impl.privateCourseBulkFillIncludes(ctx, recs, includes)
}
func (conn *ConnPGClient) CourseBulkFillIncludes(
	ctx context.Context,
	recs []*Course,
	includes *include.Spec,
	opts ...pggen.IncludeOpt,
) error {
	return conn.impl.privateCourseBulkFillIncludes(ctx, recs, includes)
}
func (p *pgClientImpl) privateCourseBulkFillIncludes(
	ctx context.Context,
	recs []*Course,
	includes *include.Spec,
	opts ...pggen.IncludeOpt,
) error {
	loadedRecordTab := map[string]interface{}{}

	return p.implCourseBulkFillIncludes(ctx, recs, includes, loadedRecordTab)
}

func (p *pgClientImpl) implCourseBulkFillIncludes(
	ctx context.Context,
	recs []*Course,
	includes *include.Spec,
	loadedRecordTab map[string]interface{},
) (err error) {
	if includes.TableName != `courses` {
		return p.client.errorConverter(fmt.Errorf(
			`expected includes for 'courses', got '%s'`,
			includes.TableName,
		))
	}

	loadedTab, inMap := loadedRecordTab[`courses`]
	if inMap {
		idToRecord := loadedTab.(map[int64]*Course)
		for _, r := range recs {
			_, alreadyLoaded := idToRecord[r.Id]
			if !alreadyLoaded {
				idToRecord[r.Id] = r
			}
		}
	} else {
		idToRecord := make(map[int64]*Course, len(recs))
		for _, r := range recs {
			idToRecord[r.Id] = r
		}
		loadedRecordTab[`courses`] = idToRecord
	}
	var subSpec *include.Spec
	var inIncludeSet bool
	// Fill in the Holes if it is in includes
	subSpec, inIncludeSet = includes.Includes[`holes`]
	if inIncludeSet {
		err = p.privateCourseFillHoles(ctx, loadedRecordTab)
		if err != nil {
			return p.client.errorConverter(err)
		}

		subRecs := make([]*Hole, 0, len(recs))
		for _, outer := range recs {
			for i := range outer.Holes {
				if outer.Holes[i] == nil {
					continue
				}
				subRecs = append(subRecs, outer.Holes[i])
			}
		}

		err = p.implHoleBulkFillIncludes(ctx, subRecs, subSpec, loadedRecordTab)
		if err != nil {
			return p.client.errorConverter(err)
		}
	}
	// Fill in the Matches if it is in includes
	subSpec, inIncludeSet = includes.Includes[`matches`]
	if inIncludeSet {
		err = p.privateCourseFillMatches(ctx, loadedRecordTab)
		if err != nil {
			return p.client.errorConverter(err)
		}

		subRecs := make([]*Match, 0, len(recs))
		for _, outer := range recs {
			for i := range outer.Matches {
				if outer.Matches[i] == nil {
					continue
				}
				subRecs = append(subRecs, outer.Matches[i])
			}
		}

		err = p.implMatchBulkFillIncludes(ctx, subRecs, subSpec, loadedRecordTab)
		if err != nil {
			return p.client.errorConverter(err)
		}
	}
	subSpec, inIncludeSet = includes.Includes[`locations`]
	if inIncludeSet {
		err = p.privateCourseFillParentLocation(ctx, loadedRecordTab)
		if err != nil {
			return p.client.errorConverter(err)
		}

		subRecs := make([]*Location, 0, len(recs))
		for _, outer := range recs {
			if outer.Location != nil {
				subRecs = append(subRecs, outer.Location)
			}
		}

		err = p.implLocationBulkFillIncludes(ctx, subRecs, subSpec, loadedRecordTab)
		if err != nil {
			return p.client.errorConverter(err)
		}
	}

	return
}

// For a given set of Course, fill in all the Hole
// connected to them using a single query.
func (p *pgClientImpl) privateCourseFillHoles(
	ctx context.Context,
	loadedRecordTab map[string]interface{},
) error {
	parentLoadedTab, inMap := loadedRecordTab[`courses`]
	if !inMap {
		return fmt.Errorf("internal pggen error: table not pre-loaded")
	}
	parentIDToRecord := parentLoadedTab.(map[int64]*Course)
	ids := make([]int64, 0, len(parentIDToRecord))
	for _, rec := range parentIDToRecord {
		ids = append(ids, rec.Id)
	}

	var childIDToRecord map[int64]*Hole
	childLoadedTab, inMap := loadedRecordTab[`holes`]
	if inMap {
		childIDToRecord = childLoadedTab.(map[int64]*Hole)
	} else {
		childIDToRecord = map[int64]*Hole{}
	}

	rows, err := p.queryContext(
		ctx,
		`SELECT * FROM holes
		 WHERE "course_id" = ANY($1)
		 `,
		pgtypes.Array(ids),
	)
	if err != nil {
		return p.client.errorConverter(err)
	}
	defer rows.Close()

	// pull all the child records from the database and associate them with
	// the correct parent.
	for rows.Next() {
		var scannedChildRec Hole
		err = scannedChildRec.Scan(ctx, p.client, rows)
		if err != nil {
			return p.client.errorConverter(err)
		}

		var childRec *Hole

		preloadedChildRec, alreadyLoaded := childIDToRecord[scannedChildRec.Id]
		if alreadyLoaded {
			childRec = preloadedChildRec
		} else {
			childRec = &scannedChildRec
			childIDToRecord[scannedChildRec.Id] = &scannedChildRec
		}
		// we know that the foreign key can't be null because of the SQL query
		parentRec := parentIDToRecord[*childRec.CourseId]
		parentRec.Holes = append(parentRec.Holes, childRec)
	}

	loadedRecordTab[`holes`] = childIDToRecord

	return nil
}

// For a given set of Course, fill in all the Match
// connected to them using a single query.
func (p *pgClientImpl) privateCourseFillMatches(
	ctx context.Context,
	loadedRecordTab map[string]interface{},
) error {
	parentLoadedTab, inMap := loadedRecordTab[`courses`]
	if !inMap {
		return fmt.Errorf("internal pggen error: table not pre-loaded")
	}
	parentIDToRecord := parentLoadedTab.(map[int64]*Course)
	ids := make([]int64, 0, len(parentIDToRecord))
	for _, rec := range parentIDToRecord {
		ids = append(ids, rec.Id)
	}

	var childIDToRecord map[int64]*Match
	childLoadedTab, inMap := loadedRecordTab[`matches`]
	if inMap {
		childIDToRecord = childLoadedTab.(map[int64]*Match)
	} else {
		childIDToRecord = map[int64]*Match{}
	}

	rows, err := p.queryContext(
		ctx,
		`SELECT * FROM matches
		 WHERE "course_id" = ANY($1)
		 `,
		pgtypes.Array(ids),
	)
	if err != nil {
		return p.client.errorConverter(err)
	}
	defer rows.Close()

	// pull all the child records from the database and associate them with
	// the correct parent.
	for rows.Next() {
		var scannedChildRec Match
		err = scannedChildRec.Scan(ctx, p.client, rows)
		if err != nil {
			return p.client.errorConverter(err)
		}

		var childRec *Match

		preloadedChildRec, alreadyLoaded := childIDToRecord[scannedChildRec.Id]
		if alreadyLoaded {
			childRec = preloadedChildRec
		} else {
			childRec = &scannedChildRec
			childIDToRecord[scannedChildRec.Id] = &scannedChildRec
		}
		// we know that the foreign key can't be null because of the SQL query
		parentRec := parentIDToRecord[*childRec.CourseId]
		parentRec.Matches = append(parentRec.Matches, childRec)
	}

	loadedRecordTab[`matches`] = childIDToRecord

	return nil
}

// For a given set of Course, fill in all the Location
// connected to them using at most one query.
func (p *pgClientImpl) privateCourseFillParentLocation(
	ctx context.Context,
	loadedRecordTab map[string]interface{},
) error {
	// lookup the table of child records
	childLoadedTab, inMap := loadedRecordTab[`courses`]
	if !inMap {
		return p.client.errorConverter(fmt.Errorf("internal pggen error: table not pre-loaded"))
	}
	childIDToRecord := childLoadedTab.(map[int64]*Course)

	// lookup the table of parent records
	var parentIDToRecord map[int64]*Location
	parentLoadedTab, inMap := loadedRecordTab[`locations`]
	if inMap {
		parentIDToRecord = parentLoadedTab.(map[int64]*Location)
	} else {
		parentIDToRecord = map[int64]*Location{}
	}

	// partition the parents into those records which we have already loaded and those
	// which still need to be fetched from the db.
	ids := make([]int64, 0, len(childIDToRecord))
	for _, rec := range childIDToRecord {
		if rec.LocationId == nil {
			continue
		}
		parentID := *rec.LocationId

		parentRec, inMap := parentIDToRecord[parentID]
		if inMap {
			// already loaded, no need to hit the DB
			rec.Location = parentRec
		} else {
			ids = append(ids, parentID)
		}
	}

	// build a table mapping parent ids to lists of children which hold references to them
	parentIDToChildren := map[int64][]*Course{}
	for _, rec := range childIDToRecord {
		if rec.LocationId == nil {
			continue
		}
		parentID := *rec.LocationId

		childSlice, inMap := parentIDToChildren[parentID]
		if inMap {
			childSlice = append(childSlice, rec)
			parentIDToChildren[parentID] = childSlice
		} else {
			parentIDToChildren[parentID] = []*Course{rec}
		}
	}

	// fetch any outstanding parent records
	if len(ids) > 0 {
		rows, err := p.queryContext(
			ctx,
			`SELECT * FROM locations
			WHERE id = ANY($1)`,
			pgtypes.Array(ids),
		)
		if err != nil {
			return p.client.errorConverter(err)
		}
		defer rows.Close()

		for rows.Next() {
			var parentRec Location
			err = parentRec.Scan(ctx, p.client, rows)
			if err != nil {
				return p.client.errorConverter(fmt.Errorf("scanning parent record: %s", err.Error()))
			}

			childRecs := parentIDToChildren[parentRec.Id]
			for _, childRec := range childRecs {
				childRec.Location = &parentRec
			}
			parentIDToRecord[parentRec.Id] = &parentRec
		}
	}

	loadedRecordTab[`locations`] = parentIDToRecord

	return nil
}

func (p *PGClient) GetHole(
	ctx context.Context,
	id int64,
	opts ...pggen.GetOpt,
) (*Hole, error) {
	return p.impl.getHole(ctx, id)
}
func (tx *TxPGClient) GetHole(
	ctx context.Context,
	id int64,
	opts ...pggen.GetOpt,
) (*Hole, error) {
	return tx.impl.getHole(ctx, id)
}
func (conn *ConnPGClient) GetHole(
	ctx context.Context,
	id int64,
	opts ...pggen.GetOpt,
) (*Hole, error) {
	return conn.impl.getHole(ctx, id)
}
func (p *pgClientImpl) getHole(
	ctx context.Context,
	id int64,
	opts ...pggen.GetOpt,
) (*Hole, error) {
	values, err := p.listHole(ctx, []int64{id}, true /* isGet */)
	if err != nil {
		return nil, err
	}

	// ListHole always returns the same number of records as were
	// requested, so this is safe.
	return &values[0], err
}

func (p *PGClient) ListHole(
	ctx context.Context,
	ids []int64,
	opts ...pggen.ListOpt,
) (ret []Hole, err error) {
	return p.impl.listHole(ctx, ids, false /* isGet */, opts...)
}
func (tx *TxPGClient) ListHole(
	ctx context.Context,
	ids []int64,
	opts ...pggen.ListOpt,
) (ret []Hole, err error) {
	return tx.impl.listHole(ctx, ids, false /* isGet */, opts...)
}
func (conn *ConnPGClient) ListHole(
	ctx context.Context,
	ids []int64,
	opts ...pggen.ListOpt,
) (ret []Hole, err error) {
	return conn.impl.listHole(ctx, ids, false /* isGet */, opts...)
}
func (p *pgClientImpl) listHole(
	ctx context.Context,
	ids []int64,
	isGet bool,
	opts ...pggen.ListOpt,
) (ret []Hole, err error) {
	opt := pggen.ListOptions{}
	for _, o := range opts {
		o(&opt)
	}
	if len(ids) == 0 {
		return []Hole{}, nil
	}

	rows, err := p.queryContext(
		ctx,
		`SELECT * FROM holes WHERE "id" = ANY($1)`,
		pgtypes.Array(ids),
	)
	if err != nil {
		return nil, p.client.errorConverter(err)
	}
	defer func() {
		if err == nil {
			err = rows.Close()
			if err != nil {
				ret = nil
				err = p.client.errorConverter(err)
			}
		} else {
			rowErr := rows.Close()
			if rowErr != nil {
				err = p.client.errorConverter(fmt.Errorf("%s AND %s", err.Error(), rowErr.Error()))
			}
		}
	}()

	ret = make([]Hole, 0, len(ids))
	for rows.Next() {
		var value Hole
		err = value.Scan(ctx, p.client, rows)
		if err != nil {
			return nil, p.client.errorConverter(err)
		}
		ret = append(ret, value)
	}

	if len(ret) != len(ids) {
		if isGet {
			return nil, p.client.errorConverter(&unstable.NotFoundError{
				Msg: "GetHole: record not found",
			})
		} else if !opt.SucceedOnPartialResults {
			return nil, p.client.errorConverter(&unstable.NotFoundError{
				Msg: fmt.Sprintf(
					"ListHole: asked for %d records, found %d",
					len(ids),
					len(ret),
				),
			})
		}
	}

	return ret, nil
}

// Insert a Hole into the database. Returns the primary
// key of the inserted row.
func (p *PGClient) InsertHole(
	ctx context.Context,
	value *Hole,
	opts ...pggen.InsertOpt,
) (ret int64, err error) {
	return p.impl.insertHole(ctx, value, opts...)
}

// Insert a Hole into the database. Returns the primary
// key of the inserted row.
func (tx *TxPGClient) InsertHole(
	ctx context.Context,
	value *Hole,
	opts ...pggen.InsertOpt,
) (ret int64, err error) {
	return tx.impl.insertHole(ctx, value, opts...)
}

// Insert a Hole into the database. Returns the primary
// key of the inserted row.
func (conn *ConnPGClient) InsertHole(
	ctx context.Context,
	value *Hole,
	opts ...pggen.InsertOpt,
) (ret int64, err error) {
	return conn.impl.insertHole(ctx, value, opts...)
}

// Insert a Hole into the database. Returns the primary
// key of the inserted row.
func (p *pgClientImpl) insertHole(
	ctx context.Context,
	value *Hole,
	opts ...pggen.InsertOpt,
) (ret int64, err error) {
	var ids []int64
	ids, err = p.bulkInsertHole(ctx, []Hole{*value}, opts...)
	if err != nil {
		return ret, p.client.errorConverter(err)
	}

	if len(ids) != 1 {
		return ret, p.client.errorConverter(fmt.Errorf("inserting a Hole: %d ids (expected 1)", len(ids)))
	}

	ret = ids[0]
	return
}

// Insert a list of Hole. Returns a list of the primary keys of
// the inserted rows.
func (p *PGClient) BulkInsertHole(
	ctx context.Context,
	values []Hole,
	opts ...pggen.InsertOpt,
) ([]int64, error) {
	return p.impl.bulkInsertHole(ctx, values, opts...)
}

// Insert a list of Hole. Returns a list of the primary keys of
// the inserted rows.
func (tx *TxPGClient) BulkInsertHole(
	ctx context.Context,
	values []Hole,
	opts ...pggen.InsertOpt,
) ([]int64, error) {
	return tx.impl.bulkInsertHole(ctx, values, opts...)
}

// Insert a list of Hole. Returns a list of the primary keys of
// the inserted rows.
func (conn *ConnPGClient) BulkInsertHole(
	ctx context.Context,
	values []Hole,
	opts ...pggen.InsertOpt,
) ([]int64, error) {
	return conn.impl.bulkInsertHole(ctx, values, opts...)
}

// Insert a list of Hole. Returns a list of the primary keys of
// the inserted rows.
func (p *pgClientImpl) bulkInsertHole(
	ctx context.Context,
	values []Hole,
	opts ...pggen.InsertOpt,
) ([]int64, error) {
	if len(values) == 0 {
		return []int64{}, nil
	}

	opt := pggen.InsertOptions{}
	for _, o := range opts {
		o(&opt)
	}

	defaultFields := opt.DefaultFields.Intersection(defaultableColsForHole)
	args := make([]interface{}, 0, 4*len(values))
	for _, v := range values {
		if opt.UsePkey && !defaultFields.Test(HoleIdFieldIndex) {
			args = append(args, v.Id)
		}
		if !defaultFields.Test(HoleCourseIdFieldIndex) {
			args = append(args, v.CourseId)
		}
		if !defaultFields.Test(HoleCourseOrderFieldIndex) {
			args = append(args, v.CourseOrder)
		}
		if !defaultFields.Test(HoleParFieldIndex) {
			args = append(args, v.Par)
		}
	}

	bulkInsertQuery := genBulkInsertStmt(
		`holes`,
		fieldsForHole,
		len(values),
		"id",
		opt.UsePkey,
		defaultFields,
	)

	rows, err := p.queryContext(ctx, bulkInsertQuery, args...)
	if err != nil {
		return nil, p.client.errorConverter(err)
	}
	defer rows.Close()

	ids := make([]int64, 0, len(values))
	for rows.Next() {
		var id int64
		err = rows.Scan(&(id))
		if err != nil {
			return nil, p.client.errorConverter(err)
		}
		ids = append(ids, id)
	}

	return ids, nil
}

// bit indicies for 'fieldMask' parameters
const (
	HoleIdFieldIndex          int = 0
	HoleCourseIdFieldIndex    int = 1
	HoleCourseOrderFieldIndex int = 2
	HoleParFieldIndex         int = 3
	HoleMaxFieldIndex         int = (4 - 1)
)

// A field set saying that all fields in Hole should be updated.
// For use as a 'fieldMask' parameter
var HoleAllFields pggen.FieldSet = pggen.NewFieldSetFilled(4)

var defaultableColsForHole = func() pggen.FieldSet {
	fs := pggen.NewFieldSet(HoleMaxFieldIndex)
	fs.Set(HoleIdFieldIndex, true)
	return fs
}()

var fieldsForHole []fieldNameAndIdx = []fieldNameAndIdx{
	{name: `id`, idx: HoleIdFieldIndex},
	{name: `course_id`, idx: HoleCourseIdFieldIndex},
	{name: `course_order`, idx: HoleCourseOrderFieldIndex},
	{name: `par`, idx: HoleParFieldIndex},
}

// Update a Hole. 'value' must at the least have
// a primary key set. The 'fieldMask' field set indicates which fields
// should be updated in the database.
//
// Returns the primary key of the updated row.
func (p *PGClient) UpdateHole(
	ctx context.Context,
	value *Hole,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpdateOpt,
) (ret int64, err error) {
	return p.impl.updateHole(ctx, value, fieldMask, opts...)
}

// Update a Hole. 'value' must at the least have
// a primary key set. The 'fieldMask' field set indicates which fields
// should be updated in the database.
//
// Returns the primary key of the updated row.
func (tx *TxPGClient) UpdateHole(
	ctx context.Context,
	value *Hole,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpdateOpt,
) (ret int64, err error) {
	return tx.impl.updateHole(ctx, value, fieldMask, opts...)
}

// Update a Hole. 'value' must at the least have
// a primary key set. The 'fieldMask' field set indicates which fields
// should be updated in the database.
//
// Returns the primary key of the updated row.
func (conn *ConnPGClient) UpdateHole(
	ctx context.Context,
	value *Hole,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpdateOpt,
) (ret int64, err error) {
	return conn.impl.updateHole(ctx, value, fieldMask, opts...)
}
func (p *pgClientImpl) updateHole(
	ctx context.Context,
	value *Hole,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpdateOpt,
) (ret int64, err error) {
	opt := pggen.UpdateOptions{}
	for _, o := range opts {
		o(&opt)
	}

	if !fieldMask.Test(HoleIdFieldIndex) {
		return ret, p.client.errorConverter(fmt.Errorf(`primary key required for updates to 'holes'`))
	}

	updateStmt := genUpdateStmt(
		`holes`,
		"id",
		fieldsForHole,
		fieldMask,
		"id",
	)

	args := make([]interface{}, 0, 4)
	if fieldMask.Test(HoleIdFieldIndex) {
		args = append(args, value.Id)
	}
	if fieldMask.Test(HoleCourseIdFieldIndex) {
		args = append(args, value.CourseId)
	}
	if fieldMask.Test(HoleCourseOrderFieldIndex) {
		args = append(args, value.CourseOrder)
	}
	if fieldMask.Test(HoleParFieldIndex) {
		args = append(args, value.Par)
	}

	// add the primary key arg for the WHERE condition
	args = append(args, value.Id)

	var id int64
	err = p.db.QueryRowContext(ctx, updateStmt, args...).
		Scan(&(id))
	if err != nil {
		return ret, p.client.errorConverter(err)
	}

	return id, nil
}

// Upsert a Hole value. If the given value conflicts with
// an existing row in the database, use the provided value to update that row
// rather than inserting it. Only the fields specified by 'fieldMask' are
// actually updated. All other fields are left as-is.
func (p *PGClient) UpsertHole(
	ctx context.Context,
	value *Hole,
	constraintNames []string,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpsertOpt,
) (ret int64, err error) {
	var val []int64
	val, err = p.impl.bulkUpsertHole(ctx, []Hole{*value}, constraintNames, fieldMask, opts...)
	if err != nil {
		return
	}
	if len(val) == 1 {
		return val[0], nil
	}

	// only possible if no upsert fields were specified by the field mask
	return value.Id, nil
}

// Upsert a Hole value. If the given value conflicts with
// an existing row in the database, use the provided value to update that row
// rather than inserting it. Only the fields specified by 'fieldMask' are
// actually updated. All other fields are left as-is.
func (tx *TxPGClient) UpsertHole(
	ctx context.Context,
	value *Hole,
	constraintNames []string,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpsertOpt,
) (ret int64, err error) {
	var val []int64
	val, err = tx.impl.bulkUpsertHole(ctx, []Hole{*value}, constraintNames, fieldMask, opts...)
	if err != nil {
		return
	}
	if len(val) == 1 {
		return val[0], nil
	}

	// only possible if no upsert fields were specified by the field mask
	return value.Id, nil
}

// Upsert a Hole value. If the given value conflicts with
// an existing row in the database, use the provided value to update that row
// rather than inserting it. Only the fields specified by 'fieldMask' are
// actually updated. All other fields are left as-is.
func (conn *ConnPGClient) UpsertHole(
	ctx context.Context,
	value *Hole,
	constraintNames []string,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpsertOpt,
) (ret int64, err error) {
	var val []int64
	val, err = conn.impl.bulkUpsertHole(ctx, []Hole{*value}, constraintNames, fieldMask, opts...)
	if err != nil {
		return
	}
	if len(val) == 1 {
		return val[0], nil
	}

	// only possible if no upsert fields were specified by the field mask
	return value.Id, nil
}

// Upsert a set of Hole values. If any of the given values conflict with
// existing rows in the database, use the provided values to update the rows which
// exist in the database rather than inserting them. Only the fields specified by
// 'fieldMask' are actually updated. All other fields are left as-is.
func (p *PGClient) BulkUpsertHole(
	ctx context.Context,
	values []Hole,
	constraintNames []string,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpsertOpt,
) (ret []int64, err error) {
	return p.impl.bulkUpsertHole(ctx, values, constraintNames, fieldMask, opts...)
}

// Upsert a set of Hole values. If any of the given values conflict with
// existing rows in the database, use the provided values to update the rows which
// exist in the database rather than inserting them. Only the fields specified by
// 'fieldMask' are actually updated. All other fields are left as-is.
func (tx *TxPGClient) BulkUpsertHole(
	ctx context.Context,
	values []Hole,
	constraintNames []string,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpsertOpt,
) (ret []int64, err error) {
	return tx.impl.bulkUpsertHole(ctx, values, constraintNames, fieldMask, opts...)
}

// Upsert a set of Hole values. If any of the given values conflict with
// existing rows in the database, use the provided values to update the rows which
// exist in the database rather than inserting them. Only the fields specified by
// 'fieldMask' are actually updated. All other fields are left as-is.
func (conn *ConnPGClient) BulkUpsertHole(
	ctx context.Context,
	values []Hole,
	constraintNames []string,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpsertOpt,
) (ret []int64, err error) {
	return conn.impl.bulkUpsertHole(ctx, values, constraintNames, fieldMask, opts...)
}
func (p *pgClientImpl) bulkUpsertHole(
	ctx context.Context,
	values []Hole,
	constraintNames []string,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpsertOpt,
) ([]int64, error) {
	if len(values) == 0 {
		return []int64{}, nil
	}

	options := pggen.UpsertOptions{}
	for _, opt := range opts {
		opt(&options)
	}

	if constraintNames == nil || len(constraintNames) == 0 {
		constraintNames = []string{`id`}
	}

	defaultFields := options.DefaultFields.Intersection(defaultableColsForHole)
	var stmt strings.Builder
	genInsertCommon(
		&stmt,
		`holes`,
		fieldsForHole,
		len(values),
		`id`,
		options.UsePkey,
		defaultFields,
	)

	setBits := fieldMask.CountSetBits()
	hasConflictAction := setBits > 1 ||
		(setBits == 1 && fieldMask.Test(HoleIdFieldIndex) && options.UsePkey) ||
		(setBits == 1 && !fieldMask.Test(HoleIdFieldIndex))

	if hasConflictAction {
		stmt.WriteString("ON CONFLICT (")
		stmt.WriteString(strings.Join(constraintNames, ","))
		stmt.WriteString(") DO UPDATE SET ")

		updateCols := make([]string, 0, 4)
		updateExprs := make([]string, 0, 4)
		if options.UsePkey {
			updateCols = append(updateCols, `id`)
			updateExprs = append(updateExprs, `excluded.id`)
		}
		if fieldMask.Test(HoleCourseIdFieldIndex) {
			updateCols = append(updateCols, `course_id`)
			updateExprs = append(updateExprs, `excluded.course_id`)
		}
		if fieldMask.Test(HoleCourseOrderFieldIndex) {
			updateCols = append(updateCols, `course_order`)
			updateExprs = append(updateExprs, `excluded.course_order`)
		}
		if fieldMask.Test(HoleParFieldIndex) {
			updateCols = append(updateCols, `par`)
			updateExprs = append(updateExprs, `excluded.par`)
		}
		if len(updateCols) > 1 {
			stmt.WriteRune('(')
		}
		stmt.WriteString(strings.Join(updateCols, ","))
		if len(updateCols) > 1 {
			stmt.WriteRune(')')
		}
		stmt.WriteString(" = ")
		if len(updateCols) > 1 {
			stmt.WriteRune('(')
		}
		stmt.WriteString(strings.Join(updateExprs, ","))
		if len(updateCols) > 1 {
			stmt.WriteRune(')')
		}
	} else {
		stmt.WriteString("ON CONFLICT DO NOTHING")
	}

	stmt.WriteString(` RETURNING "id"`)

	args := make([]interface{}, 0, 4*len(values))
	for _, v := range values {
		if options.UsePkey && !defaultFields.Test(HoleIdFieldIndex) {
			args = append(args, v.Id)
		}
		if !defaultFields.Test(HoleCourseIdFieldIndex) {
			args = append(args, v.CourseId)
		}
		if !defaultFields.Test(HoleCourseOrderFieldIndex) {
			args = append(args, v.CourseOrder)
		}
		if !defaultFields.Test(HoleParFieldIndex) {
			args = append(args, v.Par)
		}
	}

	rows, err := p.queryContext(ctx, stmt.String(), args...)
	if err != nil {
		return nil, p.client.errorConverter(err)
	}
	defer rows.Close()

	ids := make([]int64, 0, len(values))
	for rows.Next() {
		var id int64
		err = rows.Scan(&(id))
		if err != nil {
			return nil, p.client.errorConverter(err)
		}
		ids = append(ids, id)
	}

	return ids, nil
}

func (p *PGClient) DeleteHole(
	ctx context.Context,
	id int64,
	opts ...pggen.DeleteOpt,
) error {
	return p.impl.bulkDeleteHole(ctx, []int64{id}, opts...)
}
func (tx *TxPGClient) DeleteHole(
	ctx context.Context,
	id int64,
	opts ...pggen.DeleteOpt,
) error {
	return tx.impl.bulkDeleteHole(ctx, []int64{id}, opts...)
}
func (conn *ConnPGClient) DeleteHole(
	ctx context.Context,
	id int64,
	opts ...pggen.DeleteOpt,
) error {
	return conn.impl.bulkDeleteHole(ctx, []int64{id}, opts...)
}

func (p *PGClient) BulkDeleteHole(
	ctx context.Context,
	ids []int64,
	opts ...pggen.DeleteOpt,
) error {
	return p.impl.bulkDeleteHole(ctx, ids, opts...)
}
func (tx *TxPGClient) BulkDeleteHole(
	ctx context.Context,
	ids []int64,
	opts ...pggen.DeleteOpt,
) error {
	return tx.impl.bulkDeleteHole(ctx, ids, opts...)
}
func (conn *ConnPGClient) BulkDeleteHole(
	ctx context.Context,
	ids []int64,
	opts ...pggen.DeleteOpt,
) error {
	return conn.impl.bulkDeleteHole(ctx, ids, opts...)
}
func (p *pgClientImpl) bulkDeleteHole(
	ctx context.Context,
	ids []int64,
	opts ...pggen.DeleteOpt,
) error {
	if len(ids) == 0 {
		return nil
	}

	options := pggen.DeleteOptions{}
	for _, o := range opts {
		o(&options)
	}
	res, err := p.db.ExecContext(
		ctx,
		`DELETE FROM holes WHERE "id" = ANY($1)`,
		pgtypes.Array(ids),
	)
	if err != nil {
		return p.client.errorConverter(err)
	}

	nrows, err := res.RowsAffected()
	if err != nil {
		return p.client.errorConverter(err)
	}

	if nrows != int64(len(ids)) {
		return p.client.errorConverter(fmt.Errorf(
			"BulkDeleteHole: %d rows deleted, expected %d",
			nrows,
			len(ids),
		))
	}

	return err
}

var HoleAllIncludes *include.Spec = include.Must(include.Parse(
	`holes.{courses.{holes,locations.courses,matches.{courses,match_participants.{accounts.{match_participants,match_strokes.{accounts,holes,matches}},matches},match_strokes}},match_strokes}`,
))

func (p *PGClient) HoleFillIncludes(
	ctx context.Context,
	rec *Hole,
	includes *include.Spec,
	opts ...pggen.IncludeOpt,
) error {
	return p.impl.privateHoleBulkFillIncludes(ctx, []*Hole{rec}, includes)
}
func (tx *TxPGClient) HoleFillIncludes(
	ctx context.Context,
	rec *Hole,
	includes *include.Spec,
	opts ...pggen.IncludeOpt,
) error {
	return tx.impl.privateHoleBulkFillIncludes(ctx, []*Hole{rec}, includes)
}
func (conn *ConnPGClient) HoleFillIncludes(
	ctx context.Context,
	rec *Hole,
	includes *include.Spec,
	opts ...pggen.IncludeOpt,
) error {
	return conn.impl.privateHoleBulkFillIncludes(ctx, []*Hole{rec}, includes)
}

func (p *PGClient) HoleBulkFillIncludes(
	ctx context.Context,
	recs []*Hole,
	includes *include.Spec,
	opts ...pggen.IncludeOpt,
) error {
	return p.impl.privateHoleBulkFillIncludes(ctx, recs, includes)
}
func (tx *TxPGClient) HoleBulkFillIncludes(
	ctx context.Context,
	recs []*Hole,
	includes *include.Spec,
	opts ...pggen.IncludeOpt,
) error {
	return tx.impl.privateHoleBulkFillIncludes(ctx, recs, includes)
}
func (conn *ConnPGClient) HoleBulkFillIncludes(
	ctx context.Context,
	recs []*Hole,
	includes *include.Spec,
	opts ...pggen.IncludeOpt,
) error {
	return conn.impl.privateHoleBulkFillIncludes(ctx, recs, includes)
}
func (p *pgClientImpl) privateHoleBulkFillIncludes(
	ctx context.Context,
	recs []*Hole,
	includes *include.Spec,
	opts ...pggen.IncludeOpt,
) error {
	loadedRecordTab := map[string]interface{}{}

	return p.implHoleBulkFillIncludes(ctx, recs, includes, loadedRecordTab)
}

func (p *pgClientImpl) implHoleBulkFillIncludes(
	ctx context.Context,
	recs []*Hole,
	includes *include.Spec,
	loadedRecordTab map[string]interface{},
) (err error) {
	if includes.TableName != `holes` {
		return p.client.errorConverter(fmt.Errorf(
			`expected includes for 'holes', got '%s'`,
			includes.TableName,
		))
	}

	loadedTab, inMap := loadedRecordTab[`holes`]
	if inMap {
		idToRecord := loadedTab.(map[int64]*Hole)
		for _, r := range recs {
			_, alreadyLoaded := idToRecord[r.Id]
			if !alreadyLoaded {
				idToRecord[r.Id] = r
			}
		}
	} else {
		idToRecord := make(map[int64]*Hole, len(recs))
		for _, r := range recs {
			idToRecord[r.Id] = r
		}
		loadedRecordTab[`holes`] = idToRecord
	}
	var subSpec *include.Spec
	var inIncludeSet bool
	// Fill in the MatchStrokes if it is in includes
	subSpec, inIncludeSet = includes.Includes[`match_strokes`]
	if inIncludeSet {
		err = p.privateHoleFillMatchStrokes(ctx, loadedRecordTab)
		if err != nil {
			return p.client.errorConverter(err)
		}

		subRecs := make([]*MatchStroke, 0, len(recs))
		for _, outer := range recs {
			for i := range outer.MatchStrokes {
				subRecs = append(subRecs, outer.MatchStrokes[i])
			}
		}

		err = p.implMatchStrokeBulkFillIncludes(ctx, subRecs, subSpec, loadedRecordTab)
		if err != nil {
			return p.client.errorConverter(err)
		}
	}
	subSpec, inIncludeSet = includes.Includes[`courses`]
	if inIncludeSet {
		err = p.privateHoleFillParentCourse(ctx, loadedRecordTab)
		if err != nil {
			return p.client.errorConverter(err)
		}

		subRecs := make([]*Course, 0, len(recs))
		for _, outer := range recs {
			if outer.Course != nil {
				subRecs = append(subRecs, outer.Course)
			}
		}

		err = p.implCourseBulkFillIncludes(ctx, subRecs, subSpec, loadedRecordTab)
		if err != nil {
			return p.client.errorConverter(err)
		}
	}

	return
}

// For a given set of Hole, fill in all the MatchStroke
// connected to them using a single query.
func (p *pgClientImpl) privateHoleFillMatchStrokes(
	ctx context.Context,
	loadedRecordTab map[string]interface{},
) error {
	parentLoadedTab, inMap := loadedRecordTab[`holes`]
	if !inMap {
		return fmt.Errorf("internal pggen error: table not pre-loaded")
	}
	parentIDToRecord := parentLoadedTab.(map[int64]*Hole)
	ids := make([]int64, 0, len(parentIDToRecord))
	for _, rec := range parentIDToRecord {
		ids = append(ids, rec.Id)
	}

	var childIDToRecord map[int64]*MatchStroke
	childLoadedTab, inMap := loadedRecordTab[`match_strokes`]
	if inMap {
		childIDToRecord = childLoadedTab.(map[int64]*MatchStroke)
	} else {
		childIDToRecord = map[int64]*MatchStroke{}
	}

	rows, err := p.queryContext(
		ctx,
		`SELECT * FROM match_strokes
		 WHERE "hole_id" = ANY($1)
		 `,
		pgtypes.Array(ids),
	)
	if err != nil {
		return p.client.errorConverter(err)
	}
	defer rows.Close()

	// pull all the child records from the database and associate them with
	// the correct parent.
	for rows.Next() {
		var scannedChildRec MatchStroke
		err = scannedChildRec.Scan(ctx, p.client, rows)
		if err != nil {
			return p.client.errorConverter(err)
		}

		var childRec *MatchStroke

		preloadedChildRec, alreadyLoaded := childIDToRecord[scannedChildRec.Id]
		if alreadyLoaded {
			childRec = preloadedChildRec
		} else {
			childRec = &scannedChildRec
			childIDToRecord[scannedChildRec.Id] = &scannedChildRec
		}
		parentRec := parentIDToRecord[childRec.HoleId]
		parentRec.MatchStrokes = append(parentRec.MatchStrokes, childRec)
	}

	loadedRecordTab[`match_strokes`] = childIDToRecord

	return nil
}

// For a given set of Hole, fill in all the Course
// connected to them using at most one query.
func (p *pgClientImpl) privateHoleFillParentCourse(
	ctx context.Context,
	loadedRecordTab map[string]interface{},
) error {
	// lookup the table of child records
	childLoadedTab, inMap := loadedRecordTab[`holes`]
	if !inMap {
		return p.client.errorConverter(fmt.Errorf("internal pggen error: table not pre-loaded"))
	}
	childIDToRecord := childLoadedTab.(map[int64]*Hole)

	// lookup the table of parent records
	var parentIDToRecord map[int64]*Course
	parentLoadedTab, inMap := loadedRecordTab[`courses`]
	if inMap {
		parentIDToRecord = parentLoadedTab.(map[int64]*Course)
	} else {
		parentIDToRecord = map[int64]*Course{}
	}

	// partition the parents into those records which we have already loaded and those
	// which still need to be fetched from the db.
	ids := make([]int64, 0, len(childIDToRecord))
	for _, rec := range childIDToRecord {
		if rec.CourseId == nil {
			continue
		}
		parentID := *rec.CourseId

		parentRec, inMap := parentIDToRecord[parentID]
		if inMap {
			// already loaded, no need to hit the DB
			rec.Course = parentRec
		} else {
			ids = append(ids, parentID)
		}
	}

	// build a table mapping parent ids to lists of children which hold references to them
	parentIDToChildren := map[int64][]*Hole{}
	for _, rec := range childIDToRecord {
		if rec.CourseId == nil {
			continue
		}
		parentID := *rec.CourseId

		childSlice, inMap := parentIDToChildren[parentID]
		if inMap {
			childSlice = append(childSlice, rec)
			parentIDToChildren[parentID] = childSlice
		} else {
			parentIDToChildren[parentID] = []*Hole{rec}
		}
	}

	// fetch any outstanding parent records
	if len(ids) > 0 {
		rows, err := p.queryContext(
			ctx,
			`SELECT * FROM courses
			WHERE id = ANY($1)`,
			pgtypes.Array(ids),
		)
		if err != nil {
			return p.client.errorConverter(err)
		}
		defer rows.Close()

		for rows.Next() {
			var parentRec Course
			err = parentRec.Scan(ctx, p.client, rows)
			if err != nil {
				return p.client.errorConverter(fmt.Errorf("scanning parent record: %s", err.Error()))
			}

			childRecs := parentIDToChildren[parentRec.Id]
			for _, childRec := range childRecs {
				childRec.Course = &parentRec
			}
			parentIDToRecord[parentRec.Id] = &parentRec
		}
	}

	loadedRecordTab[`courses`] = parentIDToRecord

	return nil
}

func (p *PGClient) GetMatch(
	ctx context.Context,
	id int64,
	opts ...pggen.GetOpt,
) (*Match, error) {
	return p.impl.getMatch(ctx, id)
}
func (tx *TxPGClient) GetMatch(
	ctx context.Context,
	id int64,
	opts ...pggen.GetOpt,
) (*Match, error) {
	return tx.impl.getMatch(ctx, id)
}
func (conn *ConnPGClient) GetMatch(
	ctx context.Context,
	id int64,
	opts ...pggen.GetOpt,
) (*Match, error) {
	return conn.impl.getMatch(ctx, id)
}
func (p *pgClientImpl) getMatch(
	ctx context.Context,
	id int64,
	opts ...pggen.GetOpt,
) (*Match, error) {
	values, err := p.listMatch(ctx, []int64{id}, true /* isGet */)
	if err != nil {
		return nil, err
	}

	// ListMatch always returns the same number of records as were
	// requested, so this is safe.
	return &values[0], err
}

func (p *PGClient) ListMatch(
	ctx context.Context,
	ids []int64,
	opts ...pggen.ListOpt,
) (ret []Match, err error) {
	return p.impl.listMatch(ctx, ids, false /* isGet */, opts...)
}
func (tx *TxPGClient) ListMatch(
	ctx context.Context,
	ids []int64,
	opts ...pggen.ListOpt,
) (ret []Match, err error) {
	return tx.impl.listMatch(ctx, ids, false /* isGet */, opts...)
}
func (conn *ConnPGClient) ListMatch(
	ctx context.Context,
	ids []int64,
	opts ...pggen.ListOpt,
) (ret []Match, err error) {
	return conn.impl.listMatch(ctx, ids, false /* isGet */, opts...)
}
func (p *pgClientImpl) listMatch(
	ctx context.Context,
	ids []int64,
	isGet bool,
	opts ...pggen.ListOpt,
) (ret []Match, err error) {
	opt := pggen.ListOptions{}
	for _, o := range opts {
		o(&opt)
	}
	if len(ids) == 0 {
		return []Match{}, nil
	}

	rows, err := p.queryContext(
		ctx,
		`SELECT * FROM matches WHERE "id" = ANY($1)`,
		pgtypes.Array(ids),
	)
	if err != nil {
		return nil, p.client.errorConverter(err)
	}
	defer func() {
		if err == nil {
			err = rows.Close()
			if err != nil {
				ret = nil
				err = p.client.errorConverter(err)
			}
		} else {
			rowErr := rows.Close()
			if rowErr != nil {
				err = p.client.errorConverter(fmt.Errorf("%s AND %s", err.Error(), rowErr.Error()))
			}
		}
	}()

	ret = make([]Match, 0, len(ids))
	for rows.Next() {
		var value Match
		err = value.Scan(ctx, p.client, rows)
		if err != nil {
			return nil, p.client.errorConverter(err)
		}
		ret = append(ret, value)
	}

	if len(ret) != len(ids) {
		if isGet {
			return nil, p.client.errorConverter(&unstable.NotFoundError{
				Msg: "GetMatch: record not found",
			})
		} else if !opt.SucceedOnPartialResults {
			return nil, p.client.errorConverter(&unstable.NotFoundError{
				Msg: fmt.Sprintf(
					"ListMatch: asked for %d records, found %d",
					len(ids),
					len(ret),
				),
			})
		}
	}

	return ret, nil
}

// Insert a Match into the database. Returns the primary
// key of the inserted row.
func (p *PGClient) InsertMatch(
	ctx context.Context,
	value *Match,
	opts ...pggen.InsertOpt,
) (ret int64, err error) {
	return p.impl.insertMatch(ctx, value, opts...)
}

// Insert a Match into the database. Returns the primary
// key of the inserted row.
func (tx *TxPGClient) InsertMatch(
	ctx context.Context,
	value *Match,
	opts ...pggen.InsertOpt,
) (ret int64, err error) {
	return tx.impl.insertMatch(ctx, value, opts...)
}

// Insert a Match into the database. Returns the primary
// key of the inserted row.
func (conn *ConnPGClient) InsertMatch(
	ctx context.Context,
	value *Match,
	opts ...pggen.InsertOpt,
) (ret int64, err error) {
	return conn.impl.insertMatch(ctx, value, opts...)
}

// Insert a Match into the database. Returns the primary
// key of the inserted row.
func (p *pgClientImpl) insertMatch(
	ctx context.Context,
	value *Match,
	opts ...pggen.InsertOpt,
) (ret int64, err error) {
	var ids []int64
	ids, err = p.bulkInsertMatch(ctx, []Match{*value}, opts...)
	if err != nil {
		return ret, p.client.errorConverter(err)
	}

	if len(ids) != 1 {
		return ret, p.client.errorConverter(fmt.Errorf("inserting a Match: %d ids (expected 1)", len(ids)))
	}

	ret = ids[0]
	return
}

// Insert a list of Match. Returns a list of the primary keys of
// the inserted rows.
func (p *PGClient) BulkInsertMatch(
	ctx context.Context,
	values []Match,
	opts ...pggen.InsertOpt,
) ([]int64, error) {
	return p.impl.bulkInsertMatch(ctx, values, opts...)
}

// Insert a list of Match. Returns a list of the primary keys of
// the inserted rows.
func (tx *TxPGClient) BulkInsertMatch(
	ctx context.Context,
	values []Match,
	opts ...pggen.InsertOpt,
) ([]int64, error) {
	return tx.impl.bulkInsertMatch(ctx, values, opts...)
}

// Insert a list of Match. Returns a list of the primary keys of
// the inserted rows.
func (conn *ConnPGClient) BulkInsertMatch(
	ctx context.Context,
	values []Match,
	opts ...pggen.InsertOpt,
) ([]int64, error) {
	return conn.impl.bulkInsertMatch(ctx, values, opts...)
}

// Insert a list of Match. Returns a list of the primary keys of
// the inserted rows.
func (p *pgClientImpl) bulkInsertMatch(
	ctx context.Context,
	values []Match,
	opts ...pggen.InsertOpt,
) ([]int64, error) {
	if len(values) == 0 {
		return []int64{}, nil
	}

	opt := pggen.InsertOptions{}
	for _, o := range opts {
		o(&opt)
	}

	defaultFields := opt.DefaultFields.Intersection(defaultableColsForMatch)
	args := make([]interface{}, 0, 2*len(values))
	for _, v := range values {
		if opt.UsePkey && !defaultFields.Test(MatchIdFieldIndex) {
			args = append(args, v.Id)
		}
		if !defaultFields.Test(MatchCourseIdFieldIndex) {
			args = append(args, v.CourseId)
		}
	}

	bulkInsertQuery := genBulkInsertStmt(
		`matches`,
		fieldsForMatch,
		len(values),
		"id",
		opt.UsePkey,
		defaultFields,
	)

	rows, err := p.queryContext(ctx, bulkInsertQuery, args...)
	if err != nil {
		return nil, p.client.errorConverter(err)
	}
	defer rows.Close()

	ids := make([]int64, 0, len(values))
	for rows.Next() {
		var id int64
		err = rows.Scan(&(id))
		if err != nil {
			return nil, p.client.errorConverter(err)
		}
		ids = append(ids, id)
	}

	return ids, nil
}

// bit indicies for 'fieldMask' parameters
const (
	MatchIdFieldIndex       int = 0
	MatchCourseIdFieldIndex int = 1
	MatchMaxFieldIndex      int = (2 - 1)
)

// A field set saying that all fields in Match should be updated.
// For use as a 'fieldMask' parameter
var MatchAllFields pggen.FieldSet = pggen.NewFieldSetFilled(2)

var defaultableColsForMatch = func() pggen.FieldSet {
	fs := pggen.NewFieldSet(MatchMaxFieldIndex)
	fs.Set(MatchIdFieldIndex, true)
	return fs
}()

var fieldsForMatch []fieldNameAndIdx = []fieldNameAndIdx{
	{name: `id`, idx: MatchIdFieldIndex},
	{name: `course_id`, idx: MatchCourseIdFieldIndex},
}

// Update a Match. 'value' must at the least have
// a primary key set. The 'fieldMask' field set indicates which fields
// should be updated in the database.
//
// Returns the primary key of the updated row.
func (p *PGClient) UpdateMatch(
	ctx context.Context,
	value *Match,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpdateOpt,
) (ret int64, err error) {
	return p.impl.updateMatch(ctx, value, fieldMask, opts...)
}

// Update a Match. 'value' must at the least have
// a primary key set. The 'fieldMask' field set indicates which fields
// should be updated in the database.
//
// Returns the primary key of the updated row.
func (tx *TxPGClient) UpdateMatch(
	ctx context.Context,
	value *Match,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpdateOpt,
) (ret int64, err error) {
	return tx.impl.updateMatch(ctx, value, fieldMask, opts...)
}

// Update a Match. 'value' must at the least have
// a primary key set. The 'fieldMask' field set indicates which fields
// should be updated in the database.
//
// Returns the primary key of the updated row.
func (conn *ConnPGClient) UpdateMatch(
	ctx context.Context,
	value *Match,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpdateOpt,
) (ret int64, err error) {
	return conn.impl.updateMatch(ctx, value, fieldMask, opts...)
}
func (p *pgClientImpl) updateMatch(
	ctx context.Context,
	value *Match,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpdateOpt,
) (ret int64, err error) {
	opt := pggen.UpdateOptions{}
	for _, o := range opts {
		o(&opt)
	}

	if !fieldMask.Test(MatchIdFieldIndex) {
		return ret, p.client.errorConverter(fmt.Errorf(`primary key required for updates to 'matches'`))
	}

	updateStmt := genUpdateStmt(
		`matches`,
		"id",
		fieldsForMatch,
		fieldMask,
		"id",
	)

	args := make([]interface{}, 0, 2)
	if fieldMask.Test(MatchIdFieldIndex) {
		args = append(args, value.Id)
	}
	if fieldMask.Test(MatchCourseIdFieldIndex) {
		args = append(args, value.CourseId)
	}

	// add the primary key arg for the WHERE condition
	args = append(args, value.Id)

	var id int64
	err = p.db.QueryRowContext(ctx, updateStmt, args...).
		Scan(&(id))
	if err != nil {
		return ret, p.client.errorConverter(err)
	}

	return id, nil
}

// Upsert a Match value. If the given value conflicts with
// an existing row in the database, use the provided value to update that row
// rather than inserting it. Only the fields specified by 'fieldMask' are
// actually updated. All other fields are left as-is.
func (p *PGClient) UpsertMatch(
	ctx context.Context,
	value *Match,
	constraintNames []string,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpsertOpt,
) (ret int64, err error) {
	var val []int64
	val, err = p.impl.bulkUpsertMatch(ctx, []Match{*value}, constraintNames, fieldMask, opts...)
	if err != nil {
		return
	}
	if len(val) == 1 {
		return val[0], nil
	}

	// only possible if no upsert fields were specified by the field mask
	return value.Id, nil
}

// Upsert a Match value. If the given value conflicts with
// an existing row in the database, use the provided value to update that row
// rather than inserting it. Only the fields specified by 'fieldMask' are
// actually updated. All other fields are left as-is.
func (tx *TxPGClient) UpsertMatch(
	ctx context.Context,
	value *Match,
	constraintNames []string,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpsertOpt,
) (ret int64, err error) {
	var val []int64
	val, err = tx.impl.bulkUpsertMatch(ctx, []Match{*value}, constraintNames, fieldMask, opts...)
	if err != nil {
		return
	}
	if len(val) == 1 {
		return val[0], nil
	}

	// only possible if no upsert fields were specified by the field mask
	return value.Id, nil
}

// Upsert a Match value. If the given value conflicts with
// an existing row in the database, use the provided value to update that row
// rather than inserting it. Only the fields specified by 'fieldMask' are
// actually updated. All other fields are left as-is.
func (conn *ConnPGClient) UpsertMatch(
	ctx context.Context,
	value *Match,
	constraintNames []string,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpsertOpt,
) (ret int64, err error) {
	var val []int64
	val, err = conn.impl.bulkUpsertMatch(ctx, []Match{*value}, constraintNames, fieldMask, opts...)
	if err != nil {
		return
	}
	if len(val) == 1 {
		return val[0], nil
	}

	// only possible if no upsert fields were specified by the field mask
	return value.Id, nil
}

// Upsert a set of Match values. If any of the given values conflict with
// existing rows in the database, use the provided values to update the rows which
// exist in the database rather than inserting them. Only the fields specified by
// 'fieldMask' are actually updated. All other fields are left as-is.
func (p *PGClient) BulkUpsertMatch(
	ctx context.Context,
	values []Match,
	constraintNames []string,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpsertOpt,
) (ret []int64, err error) {
	return p.impl.bulkUpsertMatch(ctx, values, constraintNames, fieldMask, opts...)
}

// Upsert a set of Match values. If any of the given values conflict with
// existing rows in the database, use the provided values to update the rows which
// exist in the database rather than inserting them. Only the fields specified by
// 'fieldMask' are actually updated. All other fields are left as-is.
func (tx *TxPGClient) BulkUpsertMatch(
	ctx context.Context,
	values []Match,
	constraintNames []string,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpsertOpt,
) (ret []int64, err error) {
	return tx.impl.bulkUpsertMatch(ctx, values, constraintNames, fieldMask, opts...)
}

// Upsert a set of Match values. If any of the given values conflict with
// existing rows in the database, use the provided values to update the rows which
// exist in the database rather than inserting them. Only the fields specified by
// 'fieldMask' are actually updated. All other fields are left as-is.
func (conn *ConnPGClient) BulkUpsertMatch(
	ctx context.Context,
	values []Match,
	constraintNames []string,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpsertOpt,
) (ret []int64, err error) {
	return conn.impl.bulkUpsertMatch(ctx, values, constraintNames, fieldMask, opts...)
}
func (p *pgClientImpl) bulkUpsertMatch(
	ctx context.Context,
	values []Match,
	constraintNames []string,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpsertOpt,
) ([]int64, error) {
	if len(values) == 0 {
		return []int64{}, nil
	}

	options := pggen.UpsertOptions{}
	for _, opt := range opts {
		opt(&options)
	}

	if constraintNames == nil || len(constraintNames) == 0 {
		constraintNames = []string{`id`}
	}

	defaultFields := options.DefaultFields.Intersection(defaultableColsForMatch)
	var stmt strings.Builder
	genInsertCommon(
		&stmt,
		`matches`,
		fieldsForMatch,
		len(values),
		`id`,
		options.UsePkey,
		defaultFields,
	)

	setBits := fieldMask.CountSetBits()
	hasConflictAction := setBits > 1 ||
		(setBits == 1 && fieldMask.Test(MatchIdFieldIndex) && options.UsePkey) ||
		(setBits == 1 && !fieldMask.Test(MatchIdFieldIndex))

	if hasConflictAction {
		stmt.WriteString("ON CONFLICT (")
		stmt.WriteString(strings.Join(constraintNames, ","))
		stmt.WriteString(") DO UPDATE SET ")

		updateCols := make([]string, 0, 2)
		updateExprs := make([]string, 0, 2)
		if options.UsePkey {
			updateCols = append(updateCols, `id`)
			updateExprs = append(updateExprs, `excluded.id`)
		}
		if fieldMask.Test(MatchCourseIdFieldIndex) {
			updateCols = append(updateCols, `course_id`)
			updateExprs = append(updateExprs, `excluded.course_id`)
		}
		if len(updateCols) > 1 {
			stmt.WriteRune('(')
		}
		stmt.WriteString(strings.Join(updateCols, ","))
		if len(updateCols) > 1 {
			stmt.WriteRune(')')
		}
		stmt.WriteString(" = ")
		if len(updateCols) > 1 {
			stmt.WriteRune('(')
		}
		stmt.WriteString(strings.Join(updateExprs, ","))
		if len(updateCols) > 1 {
			stmt.WriteRune(')')
		}
	} else {
		stmt.WriteString("ON CONFLICT DO NOTHING")
	}

	stmt.WriteString(` RETURNING "id"`)

	args := make([]interface{}, 0, 2*len(values))
	for _, v := range values {
		if options.UsePkey && !defaultFields.Test(MatchIdFieldIndex) {
			args = append(args, v.Id)
		}
		if !defaultFields.Test(MatchCourseIdFieldIndex) {
			args = append(args, v.CourseId)
		}
	}

	rows, err := p.queryContext(ctx, stmt.String(), args...)
	if err != nil {
		return nil, p.client.errorConverter(err)
	}
	defer rows.Close()

	ids := make([]int64, 0, len(values))
	for rows.Next() {
		var id int64
		err = rows.Scan(&(id))
		if err != nil {
			return nil, p.client.errorConverter(err)
		}
		ids = append(ids, id)
	}

	return ids, nil
}

func (p *PGClient) DeleteMatch(
	ctx context.Context,
	id int64,
	opts ...pggen.DeleteOpt,
) error {
	return p.impl.bulkDeleteMatch(ctx, []int64{id}, opts...)
}
func (tx *TxPGClient) DeleteMatch(
	ctx context.Context,
	id int64,
	opts ...pggen.DeleteOpt,
) error {
	return tx.impl.bulkDeleteMatch(ctx, []int64{id}, opts...)
}
func (conn *ConnPGClient) DeleteMatch(
	ctx context.Context,
	id int64,
	opts ...pggen.DeleteOpt,
) error {
	return conn.impl.bulkDeleteMatch(ctx, []int64{id}, opts...)
}

func (p *PGClient) BulkDeleteMatch(
	ctx context.Context,
	ids []int64,
	opts ...pggen.DeleteOpt,
) error {
	return p.impl.bulkDeleteMatch(ctx, ids, opts...)
}
func (tx *TxPGClient) BulkDeleteMatch(
	ctx context.Context,
	ids []int64,
	opts ...pggen.DeleteOpt,
) error {
	return tx.impl.bulkDeleteMatch(ctx, ids, opts...)
}
func (conn *ConnPGClient) BulkDeleteMatch(
	ctx context.Context,
	ids []int64,
	opts ...pggen.DeleteOpt,
) error {
	return conn.impl.bulkDeleteMatch(ctx, ids, opts...)
}
func (p *pgClientImpl) bulkDeleteMatch(
	ctx context.Context,
	ids []int64,
	opts ...pggen.DeleteOpt,
) error {
	if len(ids) == 0 {
		return nil
	}

	options := pggen.DeleteOptions{}
	for _, o := range opts {
		o(&options)
	}
	res, err := p.db.ExecContext(
		ctx,
		`DELETE FROM matches WHERE "id" = ANY($1)`,
		pgtypes.Array(ids),
	)
	if err != nil {
		return p.client.errorConverter(err)
	}

	nrows, err := res.RowsAffected()
	if err != nil {
		return p.client.errorConverter(err)
	}

	if nrows != int64(len(ids)) {
		return p.client.errorConverter(fmt.Errorf(
			"BulkDeleteMatch: %d rows deleted, expected %d",
			nrows,
			len(ids),
		))
	}

	return err
}

var MatchAllIncludes *include.Spec = include.Must(include.Parse(
	`matches.{courses.{holes.{courses,match_strokes.{accounts.{match_participants.{accounts,matches},match_strokes},holes,matches}},locations.courses,matches},match_participants,match_strokes}`,
))

func (p *PGClient) MatchFillIncludes(
	ctx context.Context,
	rec *Match,
	includes *include.Spec,
	opts ...pggen.IncludeOpt,
) error {
	return p.impl.privateMatchBulkFillIncludes(ctx, []*Match{rec}, includes)
}
func (tx *TxPGClient) MatchFillIncludes(
	ctx context.Context,
	rec *Match,
	includes *include.Spec,
	opts ...pggen.IncludeOpt,
) error {
	return tx.impl.privateMatchBulkFillIncludes(ctx, []*Match{rec}, includes)
}
func (conn *ConnPGClient) MatchFillIncludes(
	ctx context.Context,
	rec *Match,
	includes *include.Spec,
	opts ...pggen.IncludeOpt,
) error {
	return conn.impl.privateMatchBulkFillIncludes(ctx, []*Match{rec}, includes)
}

func (p *PGClient) MatchBulkFillIncludes(
	ctx context.Context,
	recs []*Match,
	includes *include.Spec,
	opts ...pggen.IncludeOpt,
) error {
	return p.impl.privateMatchBulkFillIncludes(ctx, recs, includes)
}
func (tx *TxPGClient) MatchBulkFillIncludes(
	ctx context.Context,
	recs []*Match,
	includes *include.Spec,
	opts ...pggen.IncludeOpt,
) error {
	return tx.impl.privateMatchBulkFillIncludes(ctx, recs, includes)
}
func (conn *ConnPGClient) MatchBulkFillIncludes(
	ctx context.Context,
	recs []*Match,
	includes *include.Spec,
	opts ...pggen.IncludeOpt,
) error {
	return conn.impl.privateMatchBulkFillIncludes(ctx, recs, includes)
}
func (p *pgClientImpl) privateMatchBulkFillIncludes(
	ctx context.Context,
	recs []*Match,
	includes *include.Spec,
	opts ...pggen.IncludeOpt,
) error {
	loadedRecordTab := map[string]interface{}{}

	return p.implMatchBulkFillIncludes(ctx, recs, includes, loadedRecordTab)
}

func (p *pgClientImpl) implMatchBulkFillIncludes(
	ctx context.Context,
	recs []*Match,
	includes *include.Spec,
	loadedRecordTab map[string]interface{},
) (err error) {
	if includes.TableName != `matches` {
		return p.client.errorConverter(fmt.Errorf(
			`expected includes for 'matches', got '%s'`,
			includes.TableName,
		))
	}

	loadedTab, inMap := loadedRecordTab[`matches`]
	if inMap {
		idToRecord := loadedTab.(map[int64]*Match)
		for _, r := range recs {
			_, alreadyLoaded := idToRecord[r.Id]
			if !alreadyLoaded {
				idToRecord[r.Id] = r
			}
		}
	} else {
		idToRecord := make(map[int64]*Match, len(recs))
		for _, r := range recs {
			idToRecord[r.Id] = r
		}
		loadedRecordTab[`matches`] = idToRecord
	}
	var subSpec *include.Spec
	var inIncludeSet bool
	// Fill in the MatchParticipants if it is in includes
	subSpec, inIncludeSet = includes.Includes[`match_participants`]
	if inIncludeSet {
		err = p.privateMatchFillMatchParticipants(ctx, loadedRecordTab)
		if err != nil {
			return p.client.errorConverter(err)
		}

		subRecs := make([]*MatchParticipant, 0, len(recs))
		for _, outer := range recs {
			for i := range outer.MatchParticipants {
				subRecs = append(subRecs, outer.MatchParticipants[i])
			}
		}

		err = p.implMatchParticipantBulkFillIncludes(ctx, subRecs, subSpec, loadedRecordTab)
		if err != nil {
			return p.client.errorConverter(err)
		}
	}
	// Fill in the MatchStrokes if it is in includes
	subSpec, inIncludeSet = includes.Includes[`match_strokes`]
	if inIncludeSet {
		err = p.privateMatchFillMatchStrokes(ctx, loadedRecordTab)
		if err != nil {
			return p.client.errorConverter(err)
		}

		subRecs := make([]*MatchStroke, 0, len(recs))
		for _, outer := range recs {
			for i := range outer.MatchStrokes {
				subRecs = append(subRecs, outer.MatchStrokes[i])
			}
		}

		err = p.implMatchStrokeBulkFillIncludes(ctx, subRecs, subSpec, loadedRecordTab)
		if err != nil {
			return p.client.errorConverter(err)
		}
	}
	subSpec, inIncludeSet = includes.Includes[`courses`]
	if inIncludeSet {
		err = p.privateMatchFillParentCourse(ctx, loadedRecordTab)
		if err != nil {
			return p.client.errorConverter(err)
		}

		subRecs := make([]*Course, 0, len(recs))
		for _, outer := range recs {
			if outer.Course != nil {
				subRecs = append(subRecs, outer.Course)
			}
		}

		err = p.implCourseBulkFillIncludes(ctx, subRecs, subSpec, loadedRecordTab)
		if err != nil {
			return p.client.errorConverter(err)
		}
	}

	return
}

// For a given set of Match, fill in all the MatchParticipant
// connected to them using a single query.
func (p *pgClientImpl) privateMatchFillMatchParticipants(
	ctx context.Context,
	loadedRecordTab map[string]interface{},
) error {
	parentLoadedTab, inMap := loadedRecordTab[`matches`]
	if !inMap {
		return fmt.Errorf("internal pggen error: table not pre-loaded")
	}
	parentIDToRecord := parentLoadedTab.(map[int64]*Match)
	ids := make([]int64, 0, len(parentIDToRecord))
	for _, rec := range parentIDToRecord {
		ids = append(ids, rec.Id)
	}

	var childIDToRecord map[int64]*MatchParticipant
	childLoadedTab, inMap := loadedRecordTab[`match_participants`]
	if inMap {
		childIDToRecord = childLoadedTab.(map[int64]*MatchParticipant)
	} else {
		childIDToRecord = map[int64]*MatchParticipant{}
	}

	rows, err := p.queryContext(
		ctx,
		`SELECT * FROM match_participants
		 WHERE "match_id" = ANY($1)
		 `,
		pgtypes.Array(ids),
	)
	if err != nil {
		return p.client.errorConverter(err)
	}
	defer rows.Close()

	// pull all the child records from the database and associate them with
	// the correct parent.
	for rows.Next() {
		var scannedChildRec MatchParticipant
		err = scannedChildRec.Scan(ctx, p.client, rows)
		if err != nil {
			return p.client.errorConverter(err)
		}

		var childRec *MatchParticipant

		preloadedChildRec, alreadyLoaded := childIDToRecord[scannedChildRec.Id]
		if alreadyLoaded {
			childRec = preloadedChildRec
		} else {
			childRec = &scannedChildRec
			childIDToRecord[scannedChildRec.Id] = &scannedChildRec
		}
		parentRec := parentIDToRecord[childRec.MatchId]
		parentRec.MatchParticipants = append(parentRec.MatchParticipants, childRec)
	}

	loadedRecordTab[`match_participants`] = childIDToRecord

	return nil
}

// For a given set of Match, fill in all the MatchStroke
// connected to them using a single query.
func (p *pgClientImpl) privateMatchFillMatchStrokes(
	ctx context.Context,
	loadedRecordTab map[string]interface{},
) error {
	parentLoadedTab, inMap := loadedRecordTab[`matches`]
	if !inMap {
		return fmt.Errorf("internal pggen error: table not pre-loaded")
	}
	parentIDToRecord := parentLoadedTab.(map[int64]*Match)
	ids := make([]int64, 0, len(parentIDToRecord))
	for _, rec := range parentIDToRecord {
		ids = append(ids, rec.Id)
	}

	var childIDToRecord map[int64]*MatchStroke
	childLoadedTab, inMap := loadedRecordTab[`match_strokes`]
	if inMap {
		childIDToRecord = childLoadedTab.(map[int64]*MatchStroke)
	} else {
		childIDToRecord = map[int64]*MatchStroke{}
	}

	rows, err := p.queryContext(
		ctx,
		`SELECT * FROM match_strokes
		 WHERE "match_id" = ANY($1)
		 `,
		pgtypes.Array(ids),
	)
	if err != nil {
		return p.client.errorConverter(err)
	}
	defer rows.Close()

	// pull all the child records from the database and associate them with
	// the correct parent.
	for rows.Next() {
		var scannedChildRec MatchStroke
		err = scannedChildRec.Scan(ctx, p.client, rows)
		if err != nil {
			return p.client.errorConverter(err)
		}

		var childRec *MatchStroke

		preloadedChildRec, alreadyLoaded := childIDToRecord[scannedChildRec.Id]
		if alreadyLoaded {
			childRec = preloadedChildRec
		} else {
			childRec = &scannedChildRec
			childIDToRecord[scannedChildRec.Id] = &scannedChildRec
		}
		parentRec := parentIDToRecord[childRec.MatchId]
		parentRec.MatchStrokes = append(parentRec.MatchStrokes, childRec)
	}

	loadedRecordTab[`match_strokes`] = childIDToRecord

	return nil
}

// For a given set of Match, fill in all the Course
// connected to them using at most one query.
func (p *pgClientImpl) privateMatchFillParentCourse(
	ctx context.Context,
	loadedRecordTab map[string]interface{},
) error {
	// lookup the table of child records
	childLoadedTab, inMap := loadedRecordTab[`matches`]
	if !inMap {
		return p.client.errorConverter(fmt.Errorf("internal pggen error: table not pre-loaded"))
	}
	childIDToRecord := childLoadedTab.(map[int64]*Match)

	// lookup the table of parent records
	var parentIDToRecord map[int64]*Course
	parentLoadedTab, inMap := loadedRecordTab[`courses`]
	if inMap {
		parentIDToRecord = parentLoadedTab.(map[int64]*Course)
	} else {
		parentIDToRecord = map[int64]*Course{}
	}

	// partition the parents into those records which we have already loaded and those
	// which still need to be fetched from the db.
	ids := make([]int64, 0, len(childIDToRecord))
	for _, rec := range childIDToRecord {
		if rec.CourseId == nil {
			continue
		}
		parentID := *rec.CourseId

		parentRec, inMap := parentIDToRecord[parentID]
		if inMap {
			// already loaded, no need to hit the DB
			rec.Course = parentRec
		} else {
			ids = append(ids, parentID)
		}
	}

	// build a table mapping parent ids to lists of children which hold references to them
	parentIDToChildren := map[int64][]*Match{}
	for _, rec := range childIDToRecord {
		if rec.CourseId == nil {
			continue
		}
		parentID := *rec.CourseId

		childSlice, inMap := parentIDToChildren[parentID]
		if inMap {
			childSlice = append(childSlice, rec)
			parentIDToChildren[parentID] = childSlice
		} else {
			parentIDToChildren[parentID] = []*Match{rec}
		}
	}

	// fetch any outstanding parent records
	if len(ids) > 0 {
		rows, err := p.queryContext(
			ctx,
			`SELECT * FROM courses
			WHERE id = ANY($1)`,
			pgtypes.Array(ids),
		)
		if err != nil {
			return p.client.errorConverter(err)
		}
		defer rows.Close()

		for rows.Next() {
			var parentRec Course
			err = parentRec.Scan(ctx, p.client, rows)
			if err != nil {
				return p.client.errorConverter(fmt.Errorf("scanning parent record: %s", err.Error()))
			}

			childRecs := parentIDToChildren[parentRec.Id]
			for _, childRec := range childRecs {
				childRec.Course = &parentRec
			}
			parentIDToRecord[parentRec.Id] = &parentRec
		}
	}

	loadedRecordTab[`courses`] = parentIDToRecord

	return nil
}

func (p *PGClient) GetMatchParticipant(
	ctx context.Context,
	id int64,
	opts ...pggen.GetOpt,
) (*MatchParticipant, error) {
	return p.impl.getMatchParticipant(ctx, id)
}
func (tx *TxPGClient) GetMatchParticipant(
	ctx context.Context,
	id int64,
	opts ...pggen.GetOpt,
) (*MatchParticipant, error) {
	return tx.impl.getMatchParticipant(ctx, id)
}
func (conn *ConnPGClient) GetMatchParticipant(
	ctx context.Context,
	id int64,
	opts ...pggen.GetOpt,
) (*MatchParticipant, error) {
	return conn.impl.getMatchParticipant(ctx, id)
}
func (p *pgClientImpl) getMatchParticipant(
	ctx context.Context,
	id int64,
	opts ...pggen.GetOpt,
) (*MatchParticipant, error) {
	values, err := p.listMatchParticipant(ctx, []int64{id}, true /* isGet */)
	if err != nil {
		return nil, err
	}

	// ListMatchParticipant always returns the same number of records as were
	// requested, so this is safe.
	return &values[0], err
}

func (p *PGClient) ListMatchParticipant(
	ctx context.Context,
	ids []int64,
	opts ...pggen.ListOpt,
) (ret []MatchParticipant, err error) {
	return p.impl.listMatchParticipant(ctx, ids, false /* isGet */, opts...)
}
func (tx *TxPGClient) ListMatchParticipant(
	ctx context.Context,
	ids []int64,
	opts ...pggen.ListOpt,
) (ret []MatchParticipant, err error) {
	return tx.impl.listMatchParticipant(ctx, ids, false /* isGet */, opts...)
}
func (conn *ConnPGClient) ListMatchParticipant(
	ctx context.Context,
	ids []int64,
	opts ...pggen.ListOpt,
) (ret []MatchParticipant, err error) {
	return conn.impl.listMatchParticipant(ctx, ids, false /* isGet */, opts...)
}
func (p *pgClientImpl) listMatchParticipant(
	ctx context.Context,
	ids []int64,
	isGet bool,
	opts ...pggen.ListOpt,
) (ret []MatchParticipant, err error) {
	opt := pggen.ListOptions{}
	for _, o := range opts {
		o(&opt)
	}
	if len(ids) == 0 {
		return []MatchParticipant{}, nil
	}

	rows, err := p.queryContext(
		ctx,
		`SELECT * FROM match_participants WHERE "id" = ANY($1)`,
		pgtypes.Array(ids),
	)
	if err != nil {
		return nil, p.client.errorConverter(err)
	}
	defer func() {
		if err == nil {
			err = rows.Close()
			if err != nil {
				ret = nil
				err = p.client.errorConverter(err)
			}
		} else {
			rowErr := rows.Close()
			if rowErr != nil {
				err = p.client.errorConverter(fmt.Errorf("%s AND %s", err.Error(), rowErr.Error()))
			}
		}
	}()

	ret = make([]MatchParticipant, 0, len(ids))
	for rows.Next() {
		var value MatchParticipant
		err = value.Scan(ctx, p.client, rows)
		if err != nil {
			return nil, p.client.errorConverter(err)
		}
		ret = append(ret, value)
	}

	if len(ret) != len(ids) {
		if isGet {
			return nil, p.client.errorConverter(&unstable.NotFoundError{
				Msg: "GetMatchParticipant: record not found",
			})
		} else if !opt.SucceedOnPartialResults {
			return nil, p.client.errorConverter(&unstable.NotFoundError{
				Msg: fmt.Sprintf(
					"ListMatchParticipant: asked for %d records, found %d",
					len(ids),
					len(ret),
				),
			})
		}
	}

	return ret, nil
}

// Insert a MatchParticipant into the database. Returns the primary
// key of the inserted row.
func (p *PGClient) InsertMatchParticipant(
	ctx context.Context,
	value *MatchParticipant,
	opts ...pggen.InsertOpt,
) (ret int64, err error) {
	return p.impl.insertMatchParticipant(ctx, value, opts...)
}

// Insert a MatchParticipant into the database. Returns the primary
// key of the inserted row.
func (tx *TxPGClient) InsertMatchParticipant(
	ctx context.Context,
	value *MatchParticipant,
	opts ...pggen.InsertOpt,
) (ret int64, err error) {
	return tx.impl.insertMatchParticipant(ctx, value, opts...)
}

// Insert a MatchParticipant into the database. Returns the primary
// key of the inserted row.
func (conn *ConnPGClient) InsertMatchParticipant(
	ctx context.Context,
	value *MatchParticipant,
	opts ...pggen.InsertOpt,
) (ret int64, err error) {
	return conn.impl.insertMatchParticipant(ctx, value, opts...)
}

// Insert a MatchParticipant into the database. Returns the primary
// key of the inserted row.
func (p *pgClientImpl) insertMatchParticipant(
	ctx context.Context,
	value *MatchParticipant,
	opts ...pggen.InsertOpt,
) (ret int64, err error) {
	var ids []int64
	ids, err = p.bulkInsertMatchParticipant(ctx, []MatchParticipant{*value}, opts...)
	if err != nil {
		return ret, p.client.errorConverter(err)
	}

	if len(ids) != 1 {
		return ret, p.client.errorConverter(fmt.Errorf("inserting a MatchParticipant: %d ids (expected 1)", len(ids)))
	}

	ret = ids[0]
	return
}

// Insert a list of MatchParticipant. Returns a list of the primary keys of
// the inserted rows.
func (p *PGClient) BulkInsertMatchParticipant(
	ctx context.Context,
	values []MatchParticipant,
	opts ...pggen.InsertOpt,
) ([]int64, error) {
	return p.impl.bulkInsertMatchParticipant(ctx, values, opts...)
}

// Insert a list of MatchParticipant. Returns a list of the primary keys of
// the inserted rows.
func (tx *TxPGClient) BulkInsertMatchParticipant(
	ctx context.Context,
	values []MatchParticipant,
	opts ...pggen.InsertOpt,
) ([]int64, error) {
	return tx.impl.bulkInsertMatchParticipant(ctx, values, opts...)
}

// Insert a list of MatchParticipant. Returns a list of the primary keys of
// the inserted rows.
func (conn *ConnPGClient) BulkInsertMatchParticipant(
	ctx context.Context,
	values []MatchParticipant,
	opts ...pggen.InsertOpt,
) ([]int64, error) {
	return conn.impl.bulkInsertMatchParticipant(ctx, values, opts...)
}

// Insert a list of MatchParticipant. Returns a list of the primary keys of
// the inserted rows.
func (p *pgClientImpl) bulkInsertMatchParticipant(
	ctx context.Context,
	values []MatchParticipant,
	opts ...pggen.InsertOpt,
) ([]int64, error) {
	if len(values) == 0 {
		return []int64{}, nil
	}

	opt := pggen.InsertOptions{}
	for _, o := range opts {
		o(&opt)
	}

	defaultFields := opt.DefaultFields.Intersection(defaultableColsForMatchParticipant)
	args := make([]interface{}, 0, 3*len(values))
	for _, v := range values {
		if opt.UsePkey && !defaultFields.Test(MatchParticipantIdFieldIndex) {
			args = append(args, v.Id)
		}
		if !defaultFields.Test(MatchParticipantAccountIdFieldIndex) {
			args = append(args, v.AccountId)
		}
		if !defaultFields.Test(MatchParticipantMatchIdFieldIndex) {
			args = append(args, v.MatchId)
		}
	}

	bulkInsertQuery := genBulkInsertStmt(
		`match_participants`,
		fieldsForMatchParticipant,
		len(values),
		"id",
		opt.UsePkey,
		defaultFields,
	)

	rows, err := p.queryContext(ctx, bulkInsertQuery, args...)
	if err != nil {
		return nil, p.client.errorConverter(err)
	}
	defer rows.Close()

	ids := make([]int64, 0, len(values))
	for rows.Next() {
		var id int64
		err = rows.Scan(&(id))
		if err != nil {
			return nil, p.client.errorConverter(err)
		}
		ids = append(ids, id)
	}

	return ids, nil
}

// bit indicies for 'fieldMask' parameters
const (
	MatchParticipantIdFieldIndex        int = 0
	MatchParticipantAccountIdFieldIndex int = 1
	MatchParticipantMatchIdFieldIndex   int = 2
	MatchParticipantMaxFieldIndex       int = (3 - 1)
)

// A field set saying that all fields in MatchParticipant should be updated.
// For use as a 'fieldMask' parameter
var MatchParticipantAllFields pggen.FieldSet = pggen.NewFieldSetFilled(3)

var defaultableColsForMatchParticipant = func() pggen.FieldSet {
	fs := pggen.NewFieldSet(MatchParticipantMaxFieldIndex)
	fs.Set(MatchParticipantIdFieldIndex, true)
	return fs
}()

var fieldsForMatchParticipant []fieldNameAndIdx = []fieldNameAndIdx{
	{name: `id`, idx: MatchParticipantIdFieldIndex},
	{name: `account_id`, idx: MatchParticipantAccountIdFieldIndex},
	{name: `match_id`, idx: MatchParticipantMatchIdFieldIndex},
}

// Update a MatchParticipant. 'value' must at the least have
// a primary key set. The 'fieldMask' field set indicates which fields
// should be updated in the database.
//
// Returns the primary key of the updated row.
func (p *PGClient) UpdateMatchParticipant(
	ctx context.Context,
	value *MatchParticipant,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpdateOpt,
) (ret int64, err error) {
	return p.impl.updateMatchParticipant(ctx, value, fieldMask, opts...)
}

// Update a MatchParticipant. 'value' must at the least have
// a primary key set. The 'fieldMask' field set indicates which fields
// should be updated in the database.
//
// Returns the primary key of the updated row.
func (tx *TxPGClient) UpdateMatchParticipant(
	ctx context.Context,
	value *MatchParticipant,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpdateOpt,
) (ret int64, err error) {
	return tx.impl.updateMatchParticipant(ctx, value, fieldMask, opts...)
}

// Update a MatchParticipant. 'value' must at the least have
// a primary key set. The 'fieldMask' field set indicates which fields
// should be updated in the database.
//
// Returns the primary key of the updated row.
func (conn *ConnPGClient) UpdateMatchParticipant(
	ctx context.Context,
	value *MatchParticipant,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpdateOpt,
) (ret int64, err error) {
	return conn.impl.updateMatchParticipant(ctx, value, fieldMask, opts...)
}
func (p *pgClientImpl) updateMatchParticipant(
	ctx context.Context,
	value *MatchParticipant,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpdateOpt,
) (ret int64, err error) {
	opt := pggen.UpdateOptions{}
	for _, o := range opts {
		o(&opt)
	}

	if !fieldMask.Test(MatchParticipantIdFieldIndex) {
		return ret, p.client.errorConverter(fmt.Errorf(`primary key required for updates to 'match_participants'`))
	}

	updateStmt := genUpdateStmt(
		`match_participants`,
		"id",
		fieldsForMatchParticipant,
		fieldMask,
		"id",
	)

	args := make([]interface{}, 0, 3)
	if fieldMask.Test(MatchParticipantIdFieldIndex) {
		args = append(args, value.Id)
	}
	if fieldMask.Test(MatchParticipantAccountIdFieldIndex) {
		args = append(args, value.AccountId)
	}
	if fieldMask.Test(MatchParticipantMatchIdFieldIndex) {
		args = append(args, value.MatchId)
	}

	// add the primary key arg for the WHERE condition
	args = append(args, value.Id)

	var id int64
	err = p.db.QueryRowContext(ctx, updateStmt, args...).
		Scan(&(id))
	if err != nil {
		return ret, p.client.errorConverter(err)
	}

	return id, nil
}

// Upsert a MatchParticipant value. If the given value conflicts with
// an existing row in the database, use the provided value to update that row
// rather than inserting it. Only the fields specified by 'fieldMask' are
// actually updated. All other fields are left as-is.
func (p *PGClient) UpsertMatchParticipant(
	ctx context.Context,
	value *MatchParticipant,
	constraintNames []string,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpsertOpt,
) (ret int64, err error) {
	var val []int64
	val, err = p.impl.bulkUpsertMatchParticipant(ctx, []MatchParticipant{*value}, constraintNames, fieldMask, opts...)
	if err != nil {
		return
	}
	if len(val) == 1 {
		return val[0], nil
	}

	// only possible if no upsert fields were specified by the field mask
	return value.Id, nil
}

// Upsert a MatchParticipant value. If the given value conflicts with
// an existing row in the database, use the provided value to update that row
// rather than inserting it. Only the fields specified by 'fieldMask' are
// actually updated. All other fields are left as-is.
func (tx *TxPGClient) UpsertMatchParticipant(
	ctx context.Context,
	value *MatchParticipant,
	constraintNames []string,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpsertOpt,
) (ret int64, err error) {
	var val []int64
	val, err = tx.impl.bulkUpsertMatchParticipant(ctx, []MatchParticipant{*value}, constraintNames, fieldMask, opts...)
	if err != nil {
		return
	}
	if len(val) == 1 {
		return val[0], nil
	}

	// only possible if no upsert fields were specified by the field mask
	return value.Id, nil
}

// Upsert a MatchParticipant value. If the given value conflicts with
// an existing row in the database, use the provided value to update that row
// rather than inserting it. Only the fields specified by 'fieldMask' are
// actually updated. All other fields are left as-is.
func (conn *ConnPGClient) UpsertMatchParticipant(
	ctx context.Context,
	value *MatchParticipant,
	constraintNames []string,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpsertOpt,
) (ret int64, err error) {
	var val []int64
	val, err = conn.impl.bulkUpsertMatchParticipant(ctx, []MatchParticipant{*value}, constraintNames, fieldMask, opts...)
	if err != nil {
		return
	}
	if len(val) == 1 {
		return val[0], nil
	}

	// only possible if no upsert fields were specified by the field mask
	return value.Id, nil
}

// Upsert a set of MatchParticipant values. If any of the given values conflict with
// existing rows in the database, use the provided values to update the rows which
// exist in the database rather than inserting them. Only the fields specified by
// 'fieldMask' are actually updated. All other fields are left as-is.
func (p *PGClient) BulkUpsertMatchParticipant(
	ctx context.Context,
	values []MatchParticipant,
	constraintNames []string,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpsertOpt,
) (ret []int64, err error) {
	return p.impl.bulkUpsertMatchParticipant(ctx, values, constraintNames, fieldMask, opts...)
}

// Upsert a set of MatchParticipant values. If any of the given values conflict with
// existing rows in the database, use the provided values to update the rows which
// exist in the database rather than inserting them. Only the fields specified by
// 'fieldMask' are actually updated. All other fields are left as-is.
func (tx *TxPGClient) BulkUpsertMatchParticipant(
	ctx context.Context,
	values []MatchParticipant,
	constraintNames []string,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpsertOpt,
) (ret []int64, err error) {
	return tx.impl.bulkUpsertMatchParticipant(ctx, values, constraintNames, fieldMask, opts...)
}

// Upsert a set of MatchParticipant values. If any of the given values conflict with
// existing rows in the database, use the provided values to update the rows which
// exist in the database rather than inserting them. Only the fields specified by
// 'fieldMask' are actually updated. All other fields are left as-is.
func (conn *ConnPGClient) BulkUpsertMatchParticipant(
	ctx context.Context,
	values []MatchParticipant,
	constraintNames []string,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpsertOpt,
) (ret []int64, err error) {
	return conn.impl.bulkUpsertMatchParticipant(ctx, values, constraintNames, fieldMask, opts...)
}
func (p *pgClientImpl) bulkUpsertMatchParticipant(
	ctx context.Context,
	values []MatchParticipant,
	constraintNames []string,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpsertOpt,
) ([]int64, error) {
	if len(values) == 0 {
		return []int64{}, nil
	}

	options := pggen.UpsertOptions{}
	for _, opt := range opts {
		opt(&options)
	}

	if constraintNames == nil || len(constraintNames) == 0 {
		constraintNames = []string{`id`}
	}

	defaultFields := options.DefaultFields.Intersection(defaultableColsForMatchParticipant)
	var stmt strings.Builder
	genInsertCommon(
		&stmt,
		`match_participants`,
		fieldsForMatchParticipant,
		len(values),
		`id`,
		options.UsePkey,
		defaultFields,
	)

	setBits := fieldMask.CountSetBits()
	hasConflictAction := setBits > 1 ||
		(setBits == 1 && fieldMask.Test(MatchParticipantIdFieldIndex) && options.UsePkey) ||
		(setBits == 1 && !fieldMask.Test(MatchParticipantIdFieldIndex))

	if hasConflictAction {
		stmt.WriteString("ON CONFLICT (")
		stmt.WriteString(strings.Join(constraintNames, ","))
		stmt.WriteString(") DO UPDATE SET ")

		updateCols := make([]string, 0, 3)
		updateExprs := make([]string, 0, 3)
		if options.UsePkey {
			updateCols = append(updateCols, `id`)
			updateExprs = append(updateExprs, `excluded.id`)
		}
		if fieldMask.Test(MatchParticipantAccountIdFieldIndex) {
			updateCols = append(updateCols, `account_id`)
			updateExprs = append(updateExprs, `excluded.account_id`)
		}
		if fieldMask.Test(MatchParticipantMatchIdFieldIndex) {
			updateCols = append(updateCols, `match_id`)
			updateExprs = append(updateExprs, `excluded.match_id`)
		}
		if len(updateCols) > 1 {
			stmt.WriteRune('(')
		}
		stmt.WriteString(strings.Join(updateCols, ","))
		if len(updateCols) > 1 {
			stmt.WriteRune(')')
		}
		stmt.WriteString(" = ")
		if len(updateCols) > 1 {
			stmt.WriteRune('(')
		}
		stmt.WriteString(strings.Join(updateExprs, ","))
		if len(updateCols) > 1 {
			stmt.WriteRune(')')
		}
	} else {
		stmt.WriteString("ON CONFLICT DO NOTHING")
	}

	stmt.WriteString(` RETURNING "id"`)

	args := make([]interface{}, 0, 3*len(values))
	for _, v := range values {
		if options.UsePkey && !defaultFields.Test(MatchParticipantIdFieldIndex) {
			args = append(args, v.Id)
		}
		if !defaultFields.Test(MatchParticipantAccountIdFieldIndex) {
			args = append(args, v.AccountId)
		}
		if !defaultFields.Test(MatchParticipantMatchIdFieldIndex) {
			args = append(args, v.MatchId)
		}
	}

	rows, err := p.queryContext(ctx, stmt.String(), args...)
	if err != nil {
		return nil, p.client.errorConverter(err)
	}
	defer rows.Close()

	ids := make([]int64, 0, len(values))
	for rows.Next() {
		var id int64
		err = rows.Scan(&(id))
		if err != nil {
			return nil, p.client.errorConverter(err)
		}
		ids = append(ids, id)
	}

	return ids, nil
}

func (p *PGClient) DeleteMatchParticipant(
	ctx context.Context,
	id int64,
	opts ...pggen.DeleteOpt,
) error {
	return p.impl.bulkDeleteMatchParticipant(ctx, []int64{id}, opts...)
}
func (tx *TxPGClient) DeleteMatchParticipant(
	ctx context.Context,
	id int64,
	opts ...pggen.DeleteOpt,
) error {
	return tx.impl.bulkDeleteMatchParticipant(ctx, []int64{id}, opts...)
}
func (conn *ConnPGClient) DeleteMatchParticipant(
	ctx context.Context,
	id int64,
	opts ...pggen.DeleteOpt,
) error {
	return conn.impl.bulkDeleteMatchParticipant(ctx, []int64{id}, opts...)
}

func (p *PGClient) BulkDeleteMatchParticipant(
	ctx context.Context,
	ids []int64,
	opts ...pggen.DeleteOpt,
) error {
	return p.impl.bulkDeleteMatchParticipant(ctx, ids, opts...)
}
func (tx *TxPGClient) BulkDeleteMatchParticipant(
	ctx context.Context,
	ids []int64,
	opts ...pggen.DeleteOpt,
) error {
	return tx.impl.bulkDeleteMatchParticipant(ctx, ids, opts...)
}
func (conn *ConnPGClient) BulkDeleteMatchParticipant(
	ctx context.Context,
	ids []int64,
	opts ...pggen.DeleteOpt,
) error {
	return conn.impl.bulkDeleteMatchParticipant(ctx, ids, opts...)
}
func (p *pgClientImpl) bulkDeleteMatchParticipant(
	ctx context.Context,
	ids []int64,
	opts ...pggen.DeleteOpt,
) error {
	if len(ids) == 0 {
		return nil
	}

	options := pggen.DeleteOptions{}
	for _, o := range opts {
		o(&options)
	}
	res, err := p.db.ExecContext(
		ctx,
		`DELETE FROM match_participants WHERE "id" = ANY($1)`,
		pgtypes.Array(ids),
	)
	if err != nil {
		return p.client.errorConverter(err)
	}

	nrows, err := res.RowsAffected()
	if err != nil {
		return p.client.errorConverter(err)
	}

	if nrows != int64(len(ids)) {
		return p.client.errorConverter(fmt.Errorf(
			"BulkDeleteMatchParticipant: %d rows deleted, expected %d",
			nrows,
			len(ids),
		))
	}

	return err
}

var MatchParticipantAllIncludes *include.Spec = include.Must(include.Parse(
	`match_participants.{accounts.{match_participants,match_strokes.{accounts,holes.{courses.{holes,locations.courses,matches.{courses,match_participants,match_strokes}},match_strokes},matches}},matches}`,
))

func (p *PGClient) MatchParticipantFillIncludes(
	ctx context.Context,
	rec *MatchParticipant,
	includes *include.Spec,
	opts ...pggen.IncludeOpt,
) error {
	return p.impl.privateMatchParticipantBulkFillIncludes(ctx, []*MatchParticipant{rec}, includes)
}
func (tx *TxPGClient) MatchParticipantFillIncludes(
	ctx context.Context,
	rec *MatchParticipant,
	includes *include.Spec,
	opts ...pggen.IncludeOpt,
) error {
	return tx.impl.privateMatchParticipantBulkFillIncludes(ctx, []*MatchParticipant{rec}, includes)
}
func (conn *ConnPGClient) MatchParticipantFillIncludes(
	ctx context.Context,
	rec *MatchParticipant,
	includes *include.Spec,
	opts ...pggen.IncludeOpt,
) error {
	return conn.impl.privateMatchParticipantBulkFillIncludes(ctx, []*MatchParticipant{rec}, includes)
}

func (p *PGClient) MatchParticipantBulkFillIncludes(
	ctx context.Context,
	recs []*MatchParticipant,
	includes *include.Spec,
	opts ...pggen.IncludeOpt,
) error {
	return p.impl.privateMatchParticipantBulkFillIncludes(ctx, recs, includes)
}
func (tx *TxPGClient) MatchParticipantBulkFillIncludes(
	ctx context.Context,
	recs []*MatchParticipant,
	includes *include.Spec,
	opts ...pggen.IncludeOpt,
) error {
	return tx.impl.privateMatchParticipantBulkFillIncludes(ctx, recs, includes)
}
func (conn *ConnPGClient) MatchParticipantBulkFillIncludes(
	ctx context.Context,
	recs []*MatchParticipant,
	includes *include.Spec,
	opts ...pggen.IncludeOpt,
) error {
	return conn.impl.privateMatchParticipantBulkFillIncludes(ctx, recs, includes)
}
func (p *pgClientImpl) privateMatchParticipantBulkFillIncludes(
	ctx context.Context,
	recs []*MatchParticipant,
	includes *include.Spec,
	opts ...pggen.IncludeOpt,
) error {
	loadedRecordTab := map[string]interface{}{}

	return p.implMatchParticipantBulkFillIncludes(ctx, recs, includes, loadedRecordTab)
}

func (p *pgClientImpl) implMatchParticipantBulkFillIncludes(
	ctx context.Context,
	recs []*MatchParticipant,
	includes *include.Spec,
	loadedRecordTab map[string]interface{},
) (err error) {
	if includes.TableName != `match_participants` {
		return p.client.errorConverter(fmt.Errorf(
			`expected includes for 'match_participants', got '%s'`,
			includes.TableName,
		))
	}

	loadedTab, inMap := loadedRecordTab[`match_participants`]
	if inMap {
		idToRecord := loadedTab.(map[int64]*MatchParticipant)
		for _, r := range recs {
			_, alreadyLoaded := idToRecord[r.Id]
			if !alreadyLoaded {
				idToRecord[r.Id] = r
			}
		}
	} else {
		idToRecord := make(map[int64]*MatchParticipant, len(recs))
		for _, r := range recs {
			idToRecord[r.Id] = r
		}
		loadedRecordTab[`match_participants`] = idToRecord
	}
	var subSpec *include.Spec
	var inIncludeSet bool
	subSpec, inIncludeSet = includes.Includes[`matches`]
	if inIncludeSet {
		err = p.privateMatchParticipantFillParentMatch(ctx, loadedRecordTab)
		if err != nil {
			return p.client.errorConverter(err)
		}

		subRecs := make([]*Match, 0, len(recs))
		for _, outer := range recs {
			if outer.Match != nil {
				subRecs = append(subRecs, outer.Match)
			}
		}

		err = p.implMatchBulkFillIncludes(ctx, subRecs, subSpec, loadedRecordTab)
		if err != nil {
			return p.client.errorConverter(err)
		}
	}
	subSpec, inIncludeSet = includes.Includes[`accounts`]
	if inIncludeSet {
		err = p.privateMatchParticipantFillParentAccount(ctx, loadedRecordTab)
		if err != nil {
			return p.client.errorConverter(err)
		}

		subRecs := make([]*Account, 0, len(recs))
		for _, outer := range recs {
			if outer.Account != nil {
				subRecs = append(subRecs, outer.Account)
			}
		}

		err = p.implAccountBulkFillIncludes(ctx, subRecs, subSpec, loadedRecordTab)
		if err != nil {
			return p.client.errorConverter(err)
		}
	}

	return
}

// For a given set of MatchParticipant, fill in all the Match
// connected to them using at most one query.
func (p *pgClientImpl) privateMatchParticipantFillParentMatch(
	ctx context.Context,
	loadedRecordTab map[string]interface{},
) error {
	// lookup the table of child records
	childLoadedTab, inMap := loadedRecordTab[`match_participants`]
	if !inMap {
		return p.client.errorConverter(fmt.Errorf("internal pggen error: table not pre-loaded"))
	}
	childIDToRecord := childLoadedTab.(map[int64]*MatchParticipant)

	// lookup the table of parent records
	var parentIDToRecord map[int64]*Match
	parentLoadedTab, inMap := loadedRecordTab[`matches`]
	if inMap {
		parentIDToRecord = parentLoadedTab.(map[int64]*Match)
	} else {
		parentIDToRecord = map[int64]*Match{}
	}

	// partition the parents into those records which we have already loaded and those
	// which still need to be fetched from the db.
	ids := make([]int64, 0, len(childIDToRecord))
	for _, rec := range childIDToRecord {
		parentID := rec.MatchId

		parentRec, inMap := parentIDToRecord[parentID]
		if inMap {
			// already loaded, no need to hit the DB
			rec.Match = parentRec
		} else {
			ids = append(ids, parentID)
		}
	}

	// build a table mapping parent ids to lists of children which hold references to them
	parentIDToChildren := map[int64][]*MatchParticipant{}
	for _, rec := range childIDToRecord {
		parentID := rec.MatchId

		childSlice, inMap := parentIDToChildren[parentID]
		if inMap {
			childSlice = append(childSlice, rec)
			parentIDToChildren[parentID] = childSlice
		} else {
			parentIDToChildren[parentID] = []*MatchParticipant{rec}
		}
	}

	// fetch any outstanding parent records
	if len(ids) > 0 {
		rows, err := p.queryContext(
			ctx,
			`SELECT * FROM matches
			WHERE id = ANY($1)`,
			pgtypes.Array(ids),
		)
		if err != nil {
			return p.client.errorConverter(err)
		}
		defer rows.Close()

		for rows.Next() {
			var parentRec Match
			err = parentRec.Scan(ctx, p.client, rows)
			if err != nil {
				return p.client.errorConverter(fmt.Errorf("scanning parent record: %s", err.Error()))
			}

			childRecs := parentIDToChildren[parentRec.Id]
			for _, childRec := range childRecs {
				childRec.Match = &parentRec
			}
			parentIDToRecord[parentRec.Id] = &parentRec
		}
	}

	loadedRecordTab[`matches`] = parentIDToRecord

	return nil
}

// For a given set of MatchParticipant, fill in all the Account
// connected to them using at most one query.
func (p *pgClientImpl) privateMatchParticipantFillParentAccount(
	ctx context.Context,
	loadedRecordTab map[string]interface{},
) error {
	// lookup the table of child records
	childLoadedTab, inMap := loadedRecordTab[`match_participants`]
	if !inMap {
		return p.client.errorConverter(fmt.Errorf("internal pggen error: table not pre-loaded"))
	}
	childIDToRecord := childLoadedTab.(map[int64]*MatchParticipant)

	// lookup the table of parent records
	var parentIDToRecord map[int64]*Account
	parentLoadedTab, inMap := loadedRecordTab[`accounts`]
	if inMap {
		parentIDToRecord = parentLoadedTab.(map[int64]*Account)
	} else {
		parentIDToRecord = map[int64]*Account{}
	}

	// partition the parents into those records which we have already loaded and those
	// which still need to be fetched from the db.
	ids := make([]int64, 0, len(childIDToRecord))
	for _, rec := range childIDToRecord {
		parentID := rec.AccountId

		parentRec, inMap := parentIDToRecord[parentID]
		if inMap {
			// already loaded, no need to hit the DB
			rec.Account = parentRec
		} else {
			ids = append(ids, parentID)
		}
	}

	// build a table mapping parent ids to lists of children which hold references to them
	parentIDToChildren := map[int64][]*MatchParticipant{}
	for _, rec := range childIDToRecord {
		parentID := rec.AccountId

		childSlice, inMap := parentIDToChildren[parentID]
		if inMap {
			childSlice = append(childSlice, rec)
			parentIDToChildren[parentID] = childSlice
		} else {
			parentIDToChildren[parentID] = []*MatchParticipant{rec}
		}
	}

	// fetch any outstanding parent records
	if len(ids) > 0 {
		rows, err := p.queryContext(
			ctx,
			`SELECT * FROM accounts
			WHERE id = ANY($1)`,
			pgtypes.Array(ids),
		)
		if err != nil {
			return p.client.errorConverter(err)
		}
		defer rows.Close()

		for rows.Next() {
			var parentRec Account
			err = parentRec.Scan(ctx, p.client, rows)
			if err != nil {
				return p.client.errorConverter(fmt.Errorf("scanning parent record: %s", err.Error()))
			}

			childRecs := parentIDToChildren[parentRec.Id]
			for _, childRec := range childRecs {
				childRec.Account = &parentRec
			}
			parentIDToRecord[parentRec.Id] = &parentRec
		}
	}

	loadedRecordTab[`accounts`] = parentIDToRecord

	return nil
}

func (p *PGClient) GetMatchStroke(
	ctx context.Context,
	id int64,
	opts ...pggen.GetOpt,
) (*MatchStroke, error) {
	return p.impl.getMatchStroke(ctx, id)
}
func (tx *TxPGClient) GetMatchStroke(
	ctx context.Context,
	id int64,
	opts ...pggen.GetOpt,
) (*MatchStroke, error) {
	return tx.impl.getMatchStroke(ctx, id)
}
func (conn *ConnPGClient) GetMatchStroke(
	ctx context.Context,
	id int64,
	opts ...pggen.GetOpt,
) (*MatchStroke, error) {
	return conn.impl.getMatchStroke(ctx, id)
}
func (p *pgClientImpl) getMatchStroke(
	ctx context.Context,
	id int64,
	opts ...pggen.GetOpt,
) (*MatchStroke, error) {
	values, err := p.listMatchStroke(ctx, []int64{id}, true /* isGet */)
	if err != nil {
		return nil, err
	}

	// ListMatchStroke always returns the same number of records as were
	// requested, so this is safe.
	return &values[0], err
}

func (p *PGClient) ListMatchStroke(
	ctx context.Context,
	ids []int64,
	opts ...pggen.ListOpt,
) (ret []MatchStroke, err error) {
	return p.impl.listMatchStroke(ctx, ids, false /* isGet */, opts...)
}
func (tx *TxPGClient) ListMatchStroke(
	ctx context.Context,
	ids []int64,
	opts ...pggen.ListOpt,
) (ret []MatchStroke, err error) {
	return tx.impl.listMatchStroke(ctx, ids, false /* isGet */, opts...)
}
func (conn *ConnPGClient) ListMatchStroke(
	ctx context.Context,
	ids []int64,
	opts ...pggen.ListOpt,
) (ret []MatchStroke, err error) {
	return conn.impl.listMatchStroke(ctx, ids, false /* isGet */, opts...)
}
func (p *pgClientImpl) listMatchStroke(
	ctx context.Context,
	ids []int64,
	isGet bool,
	opts ...pggen.ListOpt,
) (ret []MatchStroke, err error) {
	opt := pggen.ListOptions{}
	for _, o := range opts {
		o(&opt)
	}
	if len(ids) == 0 {
		return []MatchStroke{}, nil
	}

	rows, err := p.queryContext(
		ctx,
		`SELECT * FROM match_strokes WHERE "id" = ANY($1)`,
		pgtypes.Array(ids),
	)
	if err != nil {
		return nil, p.client.errorConverter(err)
	}
	defer func() {
		if err == nil {
			err = rows.Close()
			if err != nil {
				ret = nil
				err = p.client.errorConverter(err)
			}
		} else {
			rowErr := rows.Close()
			if rowErr != nil {
				err = p.client.errorConverter(fmt.Errorf("%s AND %s", err.Error(), rowErr.Error()))
			}
		}
	}()

	ret = make([]MatchStroke, 0, len(ids))
	for rows.Next() {
		var value MatchStroke
		err = value.Scan(ctx, p.client, rows)
		if err != nil {
			return nil, p.client.errorConverter(err)
		}
		ret = append(ret, value)
	}

	if len(ret) != len(ids) {
		if isGet {
			return nil, p.client.errorConverter(&unstable.NotFoundError{
				Msg: "GetMatchStroke: record not found",
			})
		} else if !opt.SucceedOnPartialResults {
			return nil, p.client.errorConverter(&unstable.NotFoundError{
				Msg: fmt.Sprintf(
					"ListMatchStroke: asked for %d records, found %d",
					len(ids),
					len(ret),
				),
			})
		}
	}

	return ret, nil
}

// Insert a MatchStroke into the database. Returns the primary
// key of the inserted row.
func (p *PGClient) InsertMatchStroke(
	ctx context.Context,
	value *MatchStroke,
	opts ...pggen.InsertOpt,
) (ret int64, err error) {
	return p.impl.insertMatchStroke(ctx, value, opts...)
}

// Insert a MatchStroke into the database. Returns the primary
// key of the inserted row.
func (tx *TxPGClient) InsertMatchStroke(
	ctx context.Context,
	value *MatchStroke,
	opts ...pggen.InsertOpt,
) (ret int64, err error) {
	return tx.impl.insertMatchStroke(ctx, value, opts...)
}

// Insert a MatchStroke into the database. Returns the primary
// key of the inserted row.
func (conn *ConnPGClient) InsertMatchStroke(
	ctx context.Context,
	value *MatchStroke,
	opts ...pggen.InsertOpt,
) (ret int64, err error) {
	return conn.impl.insertMatchStroke(ctx, value, opts...)
}

// Insert a MatchStroke into the database. Returns the primary
// key of the inserted row.
func (p *pgClientImpl) insertMatchStroke(
	ctx context.Context,
	value *MatchStroke,
	opts ...pggen.InsertOpt,
) (ret int64, err error) {
	var ids []int64
	ids, err = p.bulkInsertMatchStroke(ctx, []MatchStroke{*value}, opts...)
	if err != nil {
		return ret, p.client.errorConverter(err)
	}

	if len(ids) != 1 {
		return ret, p.client.errorConverter(fmt.Errorf("inserting a MatchStroke: %d ids (expected 1)", len(ids)))
	}

	ret = ids[0]
	return
}

// Insert a list of MatchStroke. Returns a list of the primary keys of
// the inserted rows.
func (p *PGClient) BulkInsertMatchStroke(
	ctx context.Context,
	values []MatchStroke,
	opts ...pggen.InsertOpt,
) ([]int64, error) {
	return p.impl.bulkInsertMatchStroke(ctx, values, opts...)
}

// Insert a list of MatchStroke. Returns a list of the primary keys of
// the inserted rows.
func (tx *TxPGClient) BulkInsertMatchStroke(
	ctx context.Context,
	values []MatchStroke,
	opts ...pggen.InsertOpt,
) ([]int64, error) {
	return tx.impl.bulkInsertMatchStroke(ctx, values, opts...)
}

// Insert a list of MatchStroke. Returns a list of the primary keys of
// the inserted rows.
func (conn *ConnPGClient) BulkInsertMatchStroke(
	ctx context.Context,
	values []MatchStroke,
	opts ...pggen.InsertOpt,
) ([]int64, error) {
	return conn.impl.bulkInsertMatchStroke(ctx, values, opts...)
}

// Insert a list of MatchStroke. Returns a list of the primary keys of
// the inserted rows.
func (p *pgClientImpl) bulkInsertMatchStroke(
	ctx context.Context,
	values []MatchStroke,
	opts ...pggen.InsertOpt,
) ([]int64, error) {
	if len(values) == 0 {
		return []int64{}, nil
	}

	opt := pggen.InsertOptions{}
	for _, o := range opts {
		o(&opt)
	}

	defaultFields := opt.DefaultFields.Intersection(defaultableColsForMatchStroke)
	args := make([]interface{}, 0, 6*len(values))
	for _, v := range values {
		if opt.UsePkey && !defaultFields.Test(MatchStrokeIdFieldIndex) {
			args = append(args, v.Id)
		}
		if !defaultFields.Test(MatchStrokeAccountIdFieldIndex) {
			args = append(args, v.AccountId)
		}
		if !defaultFields.Test(MatchStrokeMatchIdFieldIndex) {
			args = append(args, v.MatchId)
		}
		if !defaultFields.Test(MatchStrokeHoleIdFieldIndex) {
			args = append(args, v.HoleId)
		}
		if !defaultFields.Test(MatchStrokeMatchOrderFieldIndex) {
			args = append(args, v.MatchOrder)
		}
		if !defaultFields.Test(MatchStrokeStrokesFieldIndex) {
			args = append(args, v.Strokes)
		}
	}

	bulkInsertQuery := genBulkInsertStmt(
		`match_strokes`,
		fieldsForMatchStroke,
		len(values),
		"id",
		opt.UsePkey,
		defaultFields,
	)

	rows, err := p.queryContext(ctx, bulkInsertQuery, args...)
	if err != nil {
		return nil, p.client.errorConverter(err)
	}
	defer rows.Close()

	ids := make([]int64, 0, len(values))
	for rows.Next() {
		var id int64
		err = rows.Scan(&(id))
		if err != nil {
			return nil, p.client.errorConverter(err)
		}
		ids = append(ids, id)
	}

	return ids, nil
}

// bit indicies for 'fieldMask' parameters
const (
	MatchStrokeIdFieldIndex         int = 0
	MatchStrokeAccountIdFieldIndex  int = 1
	MatchStrokeMatchIdFieldIndex    int = 2
	MatchStrokeHoleIdFieldIndex     int = 3
	MatchStrokeMatchOrderFieldIndex int = 4
	MatchStrokeStrokesFieldIndex    int = 5
	MatchStrokeMaxFieldIndex        int = (6 - 1)
)

// A field set saying that all fields in MatchStroke should be updated.
// For use as a 'fieldMask' parameter
var MatchStrokeAllFields pggen.FieldSet = pggen.NewFieldSetFilled(6)

var defaultableColsForMatchStroke = func() pggen.FieldSet {
	fs := pggen.NewFieldSet(MatchStrokeMaxFieldIndex)
	fs.Set(MatchStrokeIdFieldIndex, true)
	fs.Set(MatchStrokeStrokesFieldIndex, true)
	return fs
}()

var fieldsForMatchStroke []fieldNameAndIdx = []fieldNameAndIdx{
	{name: `id`, idx: MatchStrokeIdFieldIndex},
	{name: `account_id`, idx: MatchStrokeAccountIdFieldIndex},
	{name: `match_id`, idx: MatchStrokeMatchIdFieldIndex},
	{name: `hole_id`, idx: MatchStrokeHoleIdFieldIndex},
	{name: `match_order`, idx: MatchStrokeMatchOrderFieldIndex},
	{name: `strokes`, idx: MatchStrokeStrokesFieldIndex},
}

// Update a MatchStroke. 'value' must at the least have
// a primary key set. The 'fieldMask' field set indicates which fields
// should be updated in the database.
//
// Returns the primary key of the updated row.
func (p *PGClient) UpdateMatchStroke(
	ctx context.Context,
	value *MatchStroke,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpdateOpt,
) (ret int64, err error) {
	return p.impl.updateMatchStroke(ctx, value, fieldMask, opts...)
}

// Update a MatchStroke. 'value' must at the least have
// a primary key set. The 'fieldMask' field set indicates which fields
// should be updated in the database.
//
// Returns the primary key of the updated row.
func (tx *TxPGClient) UpdateMatchStroke(
	ctx context.Context,
	value *MatchStroke,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpdateOpt,
) (ret int64, err error) {
	return tx.impl.updateMatchStroke(ctx, value, fieldMask, opts...)
}

// Update a MatchStroke. 'value' must at the least have
// a primary key set. The 'fieldMask' field set indicates which fields
// should be updated in the database.
//
// Returns the primary key of the updated row.
func (conn *ConnPGClient) UpdateMatchStroke(
	ctx context.Context,
	value *MatchStroke,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpdateOpt,
) (ret int64, err error) {
	return conn.impl.updateMatchStroke(ctx, value, fieldMask, opts...)
}
func (p *pgClientImpl) updateMatchStroke(
	ctx context.Context,
	value *MatchStroke,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpdateOpt,
) (ret int64, err error) {
	opt := pggen.UpdateOptions{}
	for _, o := range opts {
		o(&opt)
	}

	if !fieldMask.Test(MatchStrokeIdFieldIndex) {
		return ret, p.client.errorConverter(fmt.Errorf(`primary key required for updates to 'match_strokes'`))
	}

	updateStmt := genUpdateStmt(
		`match_strokes`,
		"id",
		fieldsForMatchStroke,
		fieldMask,
		"id",
	)

	args := make([]interface{}, 0, 6)
	if fieldMask.Test(MatchStrokeIdFieldIndex) {
		args = append(args, value.Id)
	}
	if fieldMask.Test(MatchStrokeAccountIdFieldIndex) {
		args = append(args, value.AccountId)
	}
	if fieldMask.Test(MatchStrokeMatchIdFieldIndex) {
		args = append(args, value.MatchId)
	}
	if fieldMask.Test(MatchStrokeHoleIdFieldIndex) {
		args = append(args, value.HoleId)
	}
	if fieldMask.Test(MatchStrokeMatchOrderFieldIndex) {
		args = append(args, value.MatchOrder)
	}
	if fieldMask.Test(MatchStrokeStrokesFieldIndex) {
		args = append(args, value.Strokes)
	}

	// add the primary key arg for the WHERE condition
	args = append(args, value.Id)

	var id int64
	err = p.db.QueryRowContext(ctx, updateStmt, args...).
		Scan(&(id))
	if err != nil {
		return ret, p.client.errorConverter(err)
	}

	return id, nil
}

// Upsert a MatchStroke value. If the given value conflicts with
// an existing row in the database, use the provided value to update that row
// rather than inserting it. Only the fields specified by 'fieldMask' are
// actually updated. All other fields are left as-is.
func (p *PGClient) UpsertMatchStroke(
	ctx context.Context,
	value *MatchStroke,
	constraintNames []string,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpsertOpt,
) (ret int64, err error) {
	var val []int64
	val, err = p.impl.bulkUpsertMatchStroke(ctx, []MatchStroke{*value}, constraintNames, fieldMask, opts...)
	if err != nil {
		return
	}
	if len(val) == 1 {
		return val[0], nil
	}

	// only possible if no upsert fields were specified by the field mask
	return value.Id, nil
}

// Upsert a MatchStroke value. If the given value conflicts with
// an existing row in the database, use the provided value to update that row
// rather than inserting it. Only the fields specified by 'fieldMask' are
// actually updated. All other fields are left as-is.
func (tx *TxPGClient) UpsertMatchStroke(
	ctx context.Context,
	value *MatchStroke,
	constraintNames []string,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpsertOpt,
) (ret int64, err error) {
	var val []int64
	val, err = tx.impl.bulkUpsertMatchStroke(ctx, []MatchStroke{*value}, constraintNames, fieldMask, opts...)
	if err != nil {
		return
	}
	if len(val) == 1 {
		return val[0], nil
	}

	// only possible if no upsert fields were specified by the field mask
	return value.Id, nil
}

// Upsert a MatchStroke value. If the given value conflicts with
// an existing row in the database, use the provided value to update that row
// rather than inserting it. Only the fields specified by 'fieldMask' are
// actually updated. All other fields are left as-is.
func (conn *ConnPGClient) UpsertMatchStroke(
	ctx context.Context,
	value *MatchStroke,
	constraintNames []string,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpsertOpt,
) (ret int64, err error) {
	var val []int64
	val, err = conn.impl.bulkUpsertMatchStroke(ctx, []MatchStroke{*value}, constraintNames, fieldMask, opts...)
	if err != nil {
		return
	}
	if len(val) == 1 {
		return val[0], nil
	}

	// only possible if no upsert fields were specified by the field mask
	return value.Id, nil
}

// Upsert a set of MatchStroke values. If any of the given values conflict with
// existing rows in the database, use the provided values to update the rows which
// exist in the database rather than inserting them. Only the fields specified by
// 'fieldMask' are actually updated. All other fields are left as-is.
func (p *PGClient) BulkUpsertMatchStroke(
	ctx context.Context,
	values []MatchStroke,
	constraintNames []string,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpsertOpt,
) (ret []int64, err error) {
	return p.impl.bulkUpsertMatchStroke(ctx, values, constraintNames, fieldMask, opts...)
}

// Upsert a set of MatchStroke values. If any of the given values conflict with
// existing rows in the database, use the provided values to update the rows which
// exist in the database rather than inserting them. Only the fields specified by
// 'fieldMask' are actually updated. All other fields are left as-is.
func (tx *TxPGClient) BulkUpsertMatchStroke(
	ctx context.Context,
	values []MatchStroke,
	constraintNames []string,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpsertOpt,
) (ret []int64, err error) {
	return tx.impl.bulkUpsertMatchStroke(ctx, values, constraintNames, fieldMask, opts...)
}

// Upsert a set of MatchStroke values. If any of the given values conflict with
// existing rows in the database, use the provided values to update the rows which
// exist in the database rather than inserting them. Only the fields specified by
// 'fieldMask' are actually updated. All other fields are left as-is.
func (conn *ConnPGClient) BulkUpsertMatchStroke(
	ctx context.Context,
	values []MatchStroke,
	constraintNames []string,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpsertOpt,
) (ret []int64, err error) {
	return conn.impl.bulkUpsertMatchStroke(ctx, values, constraintNames, fieldMask, opts...)
}
func (p *pgClientImpl) bulkUpsertMatchStroke(
	ctx context.Context,
	values []MatchStroke,
	constraintNames []string,
	fieldMask pggen.FieldSet,
	opts ...pggen.UpsertOpt,
) ([]int64, error) {
	if len(values) == 0 {
		return []int64{}, nil
	}

	options := pggen.UpsertOptions{}
	for _, opt := range opts {
		opt(&options)
	}

	if constraintNames == nil || len(constraintNames) == 0 {
		constraintNames = []string{`id`}
	}

	defaultFields := options.DefaultFields.Intersection(defaultableColsForMatchStroke)
	var stmt strings.Builder
	genInsertCommon(
		&stmt,
		`match_strokes`,
		fieldsForMatchStroke,
		len(values),
		`id`,
		options.UsePkey,
		defaultFields,
	)

	setBits := fieldMask.CountSetBits()
	hasConflictAction := setBits > 1 ||
		(setBits == 1 && fieldMask.Test(MatchStrokeIdFieldIndex) && options.UsePkey) ||
		(setBits == 1 && !fieldMask.Test(MatchStrokeIdFieldIndex))

	if hasConflictAction {
		stmt.WriteString("ON CONFLICT (")
		stmt.WriteString(strings.Join(constraintNames, ","))
		stmt.WriteString(") DO UPDATE SET ")

		updateCols := make([]string, 0, 6)
		updateExprs := make([]string, 0, 6)
		if options.UsePkey {
			updateCols = append(updateCols, `id`)
			updateExprs = append(updateExprs, `excluded.id`)
		}
		if fieldMask.Test(MatchStrokeAccountIdFieldIndex) {
			updateCols = append(updateCols, `account_id`)
			updateExprs = append(updateExprs, `excluded.account_id`)
		}
		if fieldMask.Test(MatchStrokeMatchIdFieldIndex) {
			updateCols = append(updateCols, `match_id`)
			updateExprs = append(updateExprs, `excluded.match_id`)
		}
		if fieldMask.Test(MatchStrokeHoleIdFieldIndex) {
			updateCols = append(updateCols, `hole_id`)
			updateExprs = append(updateExprs, `excluded.hole_id`)
		}
		if fieldMask.Test(MatchStrokeMatchOrderFieldIndex) {
			updateCols = append(updateCols, `match_order`)
			updateExprs = append(updateExprs, `excluded.match_order`)
		}
		if fieldMask.Test(MatchStrokeStrokesFieldIndex) {
			updateCols = append(updateCols, `strokes`)
			updateExprs = append(updateExprs, `excluded.strokes`)
		}
		if len(updateCols) > 1 {
			stmt.WriteRune('(')
		}
		stmt.WriteString(strings.Join(updateCols, ","))
		if len(updateCols) > 1 {
			stmt.WriteRune(')')
		}
		stmt.WriteString(" = ")
		if len(updateCols) > 1 {
			stmt.WriteRune('(')
		}
		stmt.WriteString(strings.Join(updateExprs, ","))
		if len(updateCols) > 1 {
			stmt.WriteRune(')')
		}
	} else {
		stmt.WriteString("ON CONFLICT DO NOTHING")
	}

	stmt.WriteString(` RETURNING "id"`)

	args := make([]interface{}, 0, 6*len(values))
	for _, v := range values {
		if options.UsePkey && !defaultFields.Test(MatchStrokeIdFieldIndex) {
			args = append(args, v.Id)
		}
		if !defaultFields.Test(MatchStrokeAccountIdFieldIndex) {
			args = append(args, v.AccountId)
		}
		if !defaultFields.Test(MatchStrokeMatchIdFieldIndex) {
			args = append(args, v.MatchId)
		}
		if !defaultFields.Test(MatchStrokeHoleIdFieldIndex) {
			args = append(args, v.HoleId)
		}
		if !defaultFields.Test(MatchStrokeMatchOrderFieldIndex) {
			args = append(args, v.MatchOrder)
		}
		if !defaultFields.Test(MatchStrokeStrokesFieldIndex) {
			args = append(args, v.Strokes)
		}
	}

	rows, err := p.queryContext(ctx, stmt.String(), args...)
	if err != nil {
		return nil, p.client.errorConverter(err)
	}
	defer rows.Close()

	ids := make([]int64, 0, len(values))
	for rows.Next() {
		var id int64
		err = rows.Scan(&(id))
		if err != nil {
			return nil, p.client.errorConverter(err)
		}
		ids = append(ids, id)
	}

	return ids, nil
}

func (p *PGClient) DeleteMatchStroke(
	ctx context.Context,
	id int64,
	opts ...pggen.DeleteOpt,
) error {
	return p.impl.bulkDeleteMatchStroke(ctx, []int64{id}, opts...)
}
func (tx *TxPGClient) DeleteMatchStroke(
	ctx context.Context,
	id int64,
	opts ...pggen.DeleteOpt,
) error {
	return tx.impl.bulkDeleteMatchStroke(ctx, []int64{id}, opts...)
}
func (conn *ConnPGClient) DeleteMatchStroke(
	ctx context.Context,
	id int64,
	opts ...pggen.DeleteOpt,
) error {
	return conn.impl.bulkDeleteMatchStroke(ctx, []int64{id}, opts...)
}

func (p *PGClient) BulkDeleteMatchStroke(
	ctx context.Context,
	ids []int64,
	opts ...pggen.DeleteOpt,
) error {
	return p.impl.bulkDeleteMatchStroke(ctx, ids, opts...)
}
func (tx *TxPGClient) BulkDeleteMatchStroke(
	ctx context.Context,
	ids []int64,
	opts ...pggen.DeleteOpt,
) error {
	return tx.impl.bulkDeleteMatchStroke(ctx, ids, opts...)
}
func (conn *ConnPGClient) BulkDeleteMatchStroke(
	ctx context.Context,
	ids []int64,
	opts ...pggen.DeleteOpt,
) error {
	return conn.impl.bulkDeleteMatchStroke(ctx, ids, opts...)
}
func (p *pgClientImpl) bulkDeleteMatchStroke(
	ctx context.Context,
	ids []int64,
	opts ...pggen.DeleteOpt,
) error {
	if len(ids) == 0 {
		return nil
	}

	options := pggen.DeleteOptions{}
	for _, o := range opts {
		o(&options)
	}
	res, err := p.db.ExecContext(
		ctx,
		`DELETE FROM match_strokes WHERE "id" = ANY($1)`,
		pgtypes.Array(ids),
	)
	if err != nil {
		return p.client.errorConverter(err)
	}

	nrows, err := res.RowsAffected()
	if err != nil {
		return p.client.errorConverter(err)
	}

	if nrows != int64(len(ids)) {
		return p.client.errorConverter(fmt.Errorf(
			"BulkDeleteMatchStroke: %d rows deleted, expected %d",
			nrows,
			len(ids),
		))
	}

	return err
}

var MatchStrokeAllIncludes *include.Spec = include.Must(include.Parse(
	`match_strokes.{accounts.{match_participants.{accounts,matches.{courses.{holes.{courses,match_strokes},locations.courses,matches},match_participants,match_strokes}},match_strokes},holes,matches}`,
))

func (p *PGClient) MatchStrokeFillIncludes(
	ctx context.Context,
	rec *MatchStroke,
	includes *include.Spec,
	opts ...pggen.IncludeOpt,
) error {
	return p.impl.privateMatchStrokeBulkFillIncludes(ctx, []*MatchStroke{rec}, includes)
}
func (tx *TxPGClient) MatchStrokeFillIncludes(
	ctx context.Context,
	rec *MatchStroke,
	includes *include.Spec,
	opts ...pggen.IncludeOpt,
) error {
	return tx.impl.privateMatchStrokeBulkFillIncludes(ctx, []*MatchStroke{rec}, includes)
}
func (conn *ConnPGClient) MatchStrokeFillIncludes(
	ctx context.Context,
	rec *MatchStroke,
	includes *include.Spec,
	opts ...pggen.IncludeOpt,
) error {
	return conn.impl.privateMatchStrokeBulkFillIncludes(ctx, []*MatchStroke{rec}, includes)
}

func (p *PGClient) MatchStrokeBulkFillIncludes(
	ctx context.Context,
	recs []*MatchStroke,
	includes *include.Spec,
	opts ...pggen.IncludeOpt,
) error {
	return p.impl.privateMatchStrokeBulkFillIncludes(ctx, recs, includes)
}
func (tx *TxPGClient) MatchStrokeBulkFillIncludes(
	ctx context.Context,
	recs []*MatchStroke,
	includes *include.Spec,
	opts ...pggen.IncludeOpt,
) error {
	return tx.impl.privateMatchStrokeBulkFillIncludes(ctx, recs, includes)
}
func (conn *ConnPGClient) MatchStrokeBulkFillIncludes(
	ctx context.Context,
	recs []*MatchStroke,
	includes *include.Spec,
	opts ...pggen.IncludeOpt,
) error {
	return conn.impl.privateMatchStrokeBulkFillIncludes(ctx, recs, includes)
}
func (p *pgClientImpl) privateMatchStrokeBulkFillIncludes(
	ctx context.Context,
	recs []*MatchStroke,
	includes *include.Spec,
	opts ...pggen.IncludeOpt,
) error {
	loadedRecordTab := map[string]interface{}{}

	return p.implMatchStrokeBulkFillIncludes(ctx, recs, includes, loadedRecordTab)
}

func (p *pgClientImpl) implMatchStrokeBulkFillIncludes(
	ctx context.Context,
	recs []*MatchStroke,
	includes *include.Spec,
	loadedRecordTab map[string]interface{},
) (err error) {
	if includes.TableName != `match_strokes` {
		return p.client.errorConverter(fmt.Errorf(
			`expected includes for 'match_strokes', got '%s'`,
			includes.TableName,
		))
	}

	loadedTab, inMap := loadedRecordTab[`match_strokes`]
	if inMap {
		idToRecord := loadedTab.(map[int64]*MatchStroke)
		for _, r := range recs {
			_, alreadyLoaded := idToRecord[r.Id]
			if !alreadyLoaded {
				idToRecord[r.Id] = r
			}
		}
	} else {
		idToRecord := make(map[int64]*MatchStroke, len(recs))
		for _, r := range recs {
			idToRecord[r.Id] = r
		}
		loadedRecordTab[`match_strokes`] = idToRecord
	}
	var subSpec *include.Spec
	var inIncludeSet bool
	subSpec, inIncludeSet = includes.Includes[`holes`]
	if inIncludeSet {
		err = p.privateMatchStrokeFillParentHole(ctx, loadedRecordTab)
		if err != nil {
			return p.client.errorConverter(err)
		}

		subRecs := make([]*Hole, 0, len(recs))
		for _, outer := range recs {
			if outer.Hole != nil {
				subRecs = append(subRecs, outer.Hole)
			}
		}

		err = p.implHoleBulkFillIncludes(ctx, subRecs, subSpec, loadedRecordTab)
		if err != nil {
			return p.client.errorConverter(err)
		}
	}
	subSpec, inIncludeSet = includes.Includes[`matches`]
	if inIncludeSet {
		err = p.privateMatchStrokeFillParentMatch(ctx, loadedRecordTab)
		if err != nil {
			return p.client.errorConverter(err)
		}

		subRecs := make([]*Match, 0, len(recs))
		for _, outer := range recs {
			if outer.Match != nil {
				subRecs = append(subRecs, outer.Match)
			}
		}

		err = p.implMatchBulkFillIncludes(ctx, subRecs, subSpec, loadedRecordTab)
		if err != nil {
			return p.client.errorConverter(err)
		}
	}
	subSpec, inIncludeSet = includes.Includes[`accounts`]
	if inIncludeSet {
		err = p.privateMatchStrokeFillParentAccount(ctx, loadedRecordTab)
		if err != nil {
			return p.client.errorConverter(err)
		}

		subRecs := make([]*Account, 0, len(recs))
		for _, outer := range recs {
			if outer.Account != nil {
				subRecs = append(subRecs, outer.Account)
			}
		}

		err = p.implAccountBulkFillIncludes(ctx, subRecs, subSpec, loadedRecordTab)
		if err != nil {
			return p.client.errorConverter(err)
		}
	}

	return
}

// For a given set of MatchStroke, fill in all the Hole
// connected to them using at most one query.
func (p *pgClientImpl) privateMatchStrokeFillParentHole(
	ctx context.Context,
	loadedRecordTab map[string]interface{},
) error {
	// lookup the table of child records
	childLoadedTab, inMap := loadedRecordTab[`match_strokes`]
	if !inMap {
		return p.client.errorConverter(fmt.Errorf("internal pggen error: table not pre-loaded"))
	}
	childIDToRecord := childLoadedTab.(map[int64]*MatchStroke)

	// lookup the table of parent records
	var parentIDToRecord map[int64]*Hole
	parentLoadedTab, inMap := loadedRecordTab[`holes`]
	if inMap {
		parentIDToRecord = parentLoadedTab.(map[int64]*Hole)
	} else {
		parentIDToRecord = map[int64]*Hole{}
	}

	// partition the parents into those records which we have already loaded and those
	// which still need to be fetched from the db.
	ids := make([]int64, 0, len(childIDToRecord))
	for _, rec := range childIDToRecord {
		parentID := rec.HoleId

		parentRec, inMap := parentIDToRecord[parentID]
		if inMap {
			// already loaded, no need to hit the DB
			rec.Hole = parentRec
		} else {
			ids = append(ids, parentID)
		}
	}

	// build a table mapping parent ids to lists of children which hold references to them
	parentIDToChildren := map[int64][]*MatchStroke{}
	for _, rec := range childIDToRecord {
		parentID := rec.HoleId

		childSlice, inMap := parentIDToChildren[parentID]
		if inMap {
			childSlice = append(childSlice, rec)
			parentIDToChildren[parentID] = childSlice
		} else {
			parentIDToChildren[parentID] = []*MatchStroke{rec}
		}
	}

	// fetch any outstanding parent records
	if len(ids) > 0 {
		rows, err := p.queryContext(
			ctx,
			`SELECT * FROM holes
			WHERE id = ANY($1)`,
			pgtypes.Array(ids),
		)
		if err != nil {
			return p.client.errorConverter(err)
		}
		defer rows.Close()

		for rows.Next() {
			var parentRec Hole
			err = parentRec.Scan(ctx, p.client, rows)
			if err != nil {
				return p.client.errorConverter(fmt.Errorf("scanning parent record: %s", err.Error()))
			}

			childRecs := parentIDToChildren[parentRec.Id]
			for _, childRec := range childRecs {
				childRec.Hole = &parentRec
			}
			parentIDToRecord[parentRec.Id] = &parentRec
		}
	}

	loadedRecordTab[`holes`] = parentIDToRecord

	return nil
}

// For a given set of MatchStroke, fill in all the Match
// connected to them using at most one query.
func (p *pgClientImpl) privateMatchStrokeFillParentMatch(
	ctx context.Context,
	loadedRecordTab map[string]interface{},
) error {
	// lookup the table of child records
	childLoadedTab, inMap := loadedRecordTab[`match_strokes`]
	if !inMap {
		return p.client.errorConverter(fmt.Errorf("internal pggen error: table not pre-loaded"))
	}
	childIDToRecord := childLoadedTab.(map[int64]*MatchStroke)

	// lookup the table of parent records
	var parentIDToRecord map[int64]*Match
	parentLoadedTab, inMap := loadedRecordTab[`matches`]
	if inMap {
		parentIDToRecord = parentLoadedTab.(map[int64]*Match)
	} else {
		parentIDToRecord = map[int64]*Match{}
	}

	// partition the parents into those records which we have already loaded and those
	// which still need to be fetched from the db.
	ids := make([]int64, 0, len(childIDToRecord))
	for _, rec := range childIDToRecord {
		parentID := rec.MatchId

		parentRec, inMap := parentIDToRecord[parentID]
		if inMap {
			// already loaded, no need to hit the DB
			rec.Match = parentRec
		} else {
			ids = append(ids, parentID)
		}
	}

	// build a table mapping parent ids to lists of children which hold references to them
	parentIDToChildren := map[int64][]*MatchStroke{}
	for _, rec := range childIDToRecord {
		parentID := rec.MatchId

		childSlice, inMap := parentIDToChildren[parentID]
		if inMap {
			childSlice = append(childSlice, rec)
			parentIDToChildren[parentID] = childSlice
		} else {
			parentIDToChildren[parentID] = []*MatchStroke{rec}
		}
	}

	// fetch any outstanding parent records
	if len(ids) > 0 {
		rows, err := p.queryContext(
			ctx,
			`SELECT * FROM matches
			WHERE id = ANY($1)`,
			pgtypes.Array(ids),
		)
		if err != nil {
			return p.client.errorConverter(err)
		}
		defer rows.Close()

		for rows.Next() {
			var parentRec Match
			err = parentRec.Scan(ctx, p.client, rows)
			if err != nil {
				return p.client.errorConverter(fmt.Errorf("scanning parent record: %s", err.Error()))
			}

			childRecs := parentIDToChildren[parentRec.Id]
			for _, childRec := range childRecs {
				childRec.Match = &parentRec
			}
			parentIDToRecord[parentRec.Id] = &parentRec
		}
	}

	loadedRecordTab[`matches`] = parentIDToRecord

	return nil
}

// For a given set of MatchStroke, fill in all the Account
// connected to them using at most one query.
func (p *pgClientImpl) privateMatchStrokeFillParentAccount(
	ctx context.Context,
	loadedRecordTab map[string]interface{},
) error {
	// lookup the table of child records
	childLoadedTab, inMap := loadedRecordTab[`match_strokes`]
	if !inMap {
		return p.client.errorConverter(fmt.Errorf("internal pggen error: table not pre-loaded"))
	}
	childIDToRecord := childLoadedTab.(map[int64]*MatchStroke)

	// lookup the table of parent records
	var parentIDToRecord map[int64]*Account
	parentLoadedTab, inMap := loadedRecordTab[`accounts`]
	if inMap {
		parentIDToRecord = parentLoadedTab.(map[int64]*Account)
	} else {
		parentIDToRecord = map[int64]*Account{}
	}

	// partition the parents into those records which we have already loaded and those
	// which still need to be fetched from the db.
	ids := make([]int64, 0, len(childIDToRecord))
	for _, rec := range childIDToRecord {
		parentID := rec.AccountId

		parentRec, inMap := parentIDToRecord[parentID]
		if inMap {
			// already loaded, no need to hit the DB
			rec.Account = parentRec
		} else {
			ids = append(ids, parentID)
		}
	}

	// build a table mapping parent ids to lists of children which hold references to them
	parentIDToChildren := map[int64][]*MatchStroke{}
	for _, rec := range childIDToRecord {
		parentID := rec.AccountId

		childSlice, inMap := parentIDToChildren[parentID]
		if inMap {
			childSlice = append(childSlice, rec)
			parentIDToChildren[parentID] = childSlice
		} else {
			parentIDToChildren[parentID] = []*MatchStroke{rec}
		}
	}

	// fetch any outstanding parent records
	if len(ids) > 0 {
		rows, err := p.queryContext(
			ctx,
			`SELECT * FROM accounts
			WHERE id = ANY($1)`,
			pgtypes.Array(ids),
		)
		if err != nil {
			return p.client.errorConverter(err)
		}
		defer rows.Close()

		for rows.Next() {
			var parentRec Account
			err = parentRec.Scan(ctx, p.client, rows)
			if err != nil {
				return p.client.errorConverter(fmt.Errorf("scanning parent record: %s", err.Error()))
			}

			childRecs := parentIDToChildren[parentRec.Id]
			for _, childRec := range childRecs {
				childRec.Account = &parentRec
			}
			parentIDToRecord[parentRec.Id] = &parentRec
		}
	}

	loadedRecordTab[`accounts`] = parentIDToRecord

	return nil
}

func (p *PGClient) GetAllLocations(
	ctx context.Context,
) (ret []Location, err error) {
	return p.impl.GetAllLocations(
		ctx,
	)
}

func (tx *TxPGClient) GetAllLocations(
	ctx context.Context,
) (ret []Location, err error) {
	return tx.impl.GetAllLocations(
		ctx,
	)
}

func (conn *ConnPGClient) GetAllLocations(
	ctx context.Context,
) (ret []Location, err error) {
	return conn.impl.GetAllLocations(
		ctx,
	)
}
func (p *pgClientImpl) GetAllLocations(
	ctx context.Context,
) (ret []Location, err error) {
	ret = []Location{}

	var rows *sql.Rows
	rows, err = p.GetAllLocationsQuery(
		ctx,
	)
	if err != nil {
		return nil, p.client.errorConverter(err)
	}
	defer func() {
		if err == nil {
			err = rows.Close()
			if err != nil {
				ret = nil
				err = p.client.errorConverter(err)
			}
		} else {
			rowErr := rows.Close()
			if rowErr != nil {
				err = p.client.errorConverter(fmt.Errorf("%s AND %s", err.Error(), rowErr.Error()))
			}
		}
	}()

	for rows.Next() {
		var row Location
		err = row.Scan(ctx, p.client, rows)
		ret = append(ret, row)
	}

	return
}

func (p *PGClient) GetAllLocationsQuery(
	ctx context.Context,
) (*sql.Rows, error) {
	return p.impl.GetAllLocationsQuery(
		ctx,
	)
}

func (tx *TxPGClient) GetAllLocationsQuery(
	ctx context.Context,
) (*sql.Rows, error) {
	return tx.impl.GetAllLocationsQuery(
		ctx,
	)
}

func (conn *ConnPGClient) GetAllLocationsQuery(
	ctx context.Context,
) (*sql.Rows, error) {
	return conn.impl.GetAllLocationsQuery(
		ctx,
	)
}
func (p *pgClientImpl) GetAllLocationsQuery(
	ctx context.Context,
) (*sql.Rows, error) {
	return p.queryContext(
		ctx,
		`SELECT * FROM locations;`,
	)
}

func (p *PGClient) GetCoursesAtLocation(
	ctx context.Context,
	locationId int64,
) (ret []Course, err error) {
	return p.impl.GetCoursesAtLocation(
		ctx,
		locationId,
	)
}

func (tx *TxPGClient) GetCoursesAtLocation(
	ctx context.Context,
	locationId int64,
) (ret []Course, err error) {
	return tx.impl.GetCoursesAtLocation(
		ctx,
		locationId,
	)
}

func (conn *ConnPGClient) GetCoursesAtLocation(
	ctx context.Context,
	locationId int64,
) (ret []Course, err error) {
	return conn.impl.GetCoursesAtLocation(
		ctx,
		locationId,
	)
}
func (p *pgClientImpl) GetCoursesAtLocation(
	ctx context.Context,
	locationId int64,
) (ret []Course, err error) {
	ret = []Course{}

	var rows *sql.Rows
	rows, err = p.GetCoursesAtLocationQuery(
		ctx,
		locationId,
	)
	if err != nil {
		return nil, p.client.errorConverter(err)
	}
	defer func() {
		if err == nil {
			err = rows.Close()
			if err != nil {
				ret = nil
				err = p.client.errorConverter(err)
			}
		} else {
			rowErr := rows.Close()
			if rowErr != nil {
				err = p.client.errorConverter(fmt.Errorf("%s AND %s", err.Error(), rowErr.Error()))
			}
		}
	}()

	for rows.Next() {
		var row Course
		err = row.Scan(ctx, p.client, rows)
		ret = append(ret, row)
	}

	return
}

func (p *PGClient) GetCoursesAtLocationQuery(
	ctx context.Context,
	locationId int64,
) (*sql.Rows, error) {
	return p.impl.GetCoursesAtLocationQuery(
		ctx,
		locationId,
	)
}

func (tx *TxPGClient) GetCoursesAtLocationQuery(
	ctx context.Context,
	locationId int64,
) (*sql.Rows, error) {
	return tx.impl.GetCoursesAtLocationQuery(
		ctx,
		locationId,
	)
}

func (conn *ConnPGClient) GetCoursesAtLocationQuery(
	ctx context.Context,
	locationId int64,
) (*sql.Rows, error) {
	return conn.impl.GetCoursesAtLocationQuery(
		ctx,
		locationId,
	)
}
func (p *pgClientImpl) GetCoursesAtLocationQuery(
	ctx context.Context,
	locationId int64,
) (*sql.Rows, error) {
	return p.queryContext(
		ctx,
		`SELECT * FROM courses
	WHERE location_id = $1;`,
		locationId,
	)
}

func (p *PGClient) GetHolesAtCourse(
	ctx context.Context,
	courseId int64,
) (ret []Hole, err error) {
	return p.impl.GetHolesAtCourse(
		ctx,
		courseId,
	)
}

func (tx *TxPGClient) GetHolesAtCourse(
	ctx context.Context,
	courseId int64,
) (ret []Hole, err error) {
	return tx.impl.GetHolesAtCourse(
		ctx,
		courseId,
	)
}

func (conn *ConnPGClient) GetHolesAtCourse(
	ctx context.Context,
	courseId int64,
) (ret []Hole, err error) {
	return conn.impl.GetHolesAtCourse(
		ctx,
		courseId,
	)
}
func (p *pgClientImpl) GetHolesAtCourse(
	ctx context.Context,
	courseId int64,
) (ret []Hole, err error) {
	ret = []Hole{}

	var rows *sql.Rows
	rows, err = p.GetHolesAtCourseQuery(
		ctx,
		courseId,
	)
	if err != nil {
		return nil, p.client.errorConverter(err)
	}
	defer func() {
		if err == nil {
			err = rows.Close()
			if err != nil {
				ret = nil
				err = p.client.errorConverter(err)
			}
		} else {
			rowErr := rows.Close()
			if rowErr != nil {
				err = p.client.errorConverter(fmt.Errorf("%s AND %s", err.Error(), rowErr.Error()))
			}
		}
	}()

	for rows.Next() {
		var row Hole
		err = row.Scan(ctx, p.client, rows)
		ret = append(ret, row)
	}

	return
}

func (p *PGClient) GetHolesAtCourseQuery(
	ctx context.Context,
	courseId int64,
) (*sql.Rows, error) {
	return p.impl.GetHolesAtCourseQuery(
		ctx,
		courseId,
	)
}

func (tx *TxPGClient) GetHolesAtCourseQuery(
	ctx context.Context,
	courseId int64,
) (*sql.Rows, error) {
	return tx.impl.GetHolesAtCourseQuery(
		ctx,
		courseId,
	)
}

func (conn *ConnPGClient) GetHolesAtCourseQuery(
	ctx context.Context,
	courseId int64,
) (*sql.Rows, error) {
	return conn.impl.GetHolesAtCourseQuery(
		ctx,
		courseId,
	)
}
func (p *pgClientImpl) GetHolesAtCourseQuery(
	ctx context.Context,
	courseId int64,
) (*sql.Rows, error) {
	return p.queryContext(
		ctx,
		`SELECT * FROM holes
	WHERE course_id = $1;`,
		courseId,
	)
}

type DBQueries interface {
	//
	// automatic CRUD methods
	//

	// Account methods
	GetAccount(ctx context.Context, id int64, opts ...pggen.GetOpt) (*Account, error)
	ListAccount(ctx context.Context, ids []int64, opts ...pggen.ListOpt) ([]Account, error)
	InsertAccount(ctx context.Context, value *Account, opts ...pggen.InsertOpt) (int64, error)
	BulkInsertAccount(ctx context.Context, values []Account, opts ...pggen.InsertOpt) ([]int64, error)
	UpdateAccount(ctx context.Context, value *Account, fieldMask pggen.FieldSet, opts ...pggen.UpdateOpt) (ret int64, err error)
	UpsertAccount(ctx context.Context, value *Account, constraintNames []string, fieldMask pggen.FieldSet, opts ...pggen.UpsertOpt) (int64, error)
	BulkUpsertAccount(ctx context.Context, values []Account, constraintNames []string, fieldMask pggen.FieldSet, opts ...pggen.UpsertOpt) ([]int64, error)
	DeleteAccount(ctx context.Context, id int64, opts ...pggen.DeleteOpt) error
	BulkDeleteAccount(ctx context.Context, ids []int64, opts ...pggen.DeleteOpt) error
	AccountFillIncludes(ctx context.Context, rec *Account, includes *include.Spec, opts ...pggen.IncludeOpt) error
	AccountBulkFillIncludes(ctx context.Context, recs []*Account, includes *include.Spec, opts ...pggen.IncludeOpt) error

	// Location methods
	GetLocation(ctx context.Context, id int64, opts ...pggen.GetOpt) (*Location, error)
	ListLocation(ctx context.Context, ids []int64, opts ...pggen.ListOpt) ([]Location, error)
	InsertLocation(ctx context.Context, value *Location, opts ...pggen.InsertOpt) (int64, error)
	BulkInsertLocation(ctx context.Context, values []Location, opts ...pggen.InsertOpt) ([]int64, error)
	UpdateLocation(ctx context.Context, value *Location, fieldMask pggen.FieldSet, opts ...pggen.UpdateOpt) (ret int64, err error)
	UpsertLocation(ctx context.Context, value *Location, constraintNames []string, fieldMask pggen.FieldSet, opts ...pggen.UpsertOpt) (int64, error)
	BulkUpsertLocation(ctx context.Context, values []Location, constraintNames []string, fieldMask pggen.FieldSet, opts ...pggen.UpsertOpt) ([]int64, error)
	DeleteLocation(ctx context.Context, id int64, opts ...pggen.DeleteOpt) error
	BulkDeleteLocation(ctx context.Context, ids []int64, opts ...pggen.DeleteOpt) error
	LocationFillIncludes(ctx context.Context, rec *Location, includes *include.Spec, opts ...pggen.IncludeOpt) error
	LocationBulkFillIncludes(ctx context.Context, recs []*Location, includes *include.Spec, opts ...pggen.IncludeOpt) error

	// Course methods
	GetCourse(ctx context.Context, id int64, opts ...pggen.GetOpt) (*Course, error)
	ListCourse(ctx context.Context, ids []int64, opts ...pggen.ListOpt) ([]Course, error)
	InsertCourse(ctx context.Context, value *Course, opts ...pggen.InsertOpt) (int64, error)
	BulkInsertCourse(ctx context.Context, values []Course, opts ...pggen.InsertOpt) ([]int64, error)
	UpdateCourse(ctx context.Context, value *Course, fieldMask pggen.FieldSet, opts ...pggen.UpdateOpt) (ret int64, err error)
	UpsertCourse(ctx context.Context, value *Course, constraintNames []string, fieldMask pggen.FieldSet, opts ...pggen.UpsertOpt) (int64, error)
	BulkUpsertCourse(ctx context.Context, values []Course, constraintNames []string, fieldMask pggen.FieldSet, opts ...pggen.UpsertOpt) ([]int64, error)
	DeleteCourse(ctx context.Context, id int64, opts ...pggen.DeleteOpt) error
	BulkDeleteCourse(ctx context.Context, ids []int64, opts ...pggen.DeleteOpt) error
	CourseFillIncludes(ctx context.Context, rec *Course, includes *include.Spec, opts ...pggen.IncludeOpt) error
	CourseBulkFillIncludes(ctx context.Context, recs []*Course, includes *include.Spec, opts ...pggen.IncludeOpt) error

	// Hole methods
	GetHole(ctx context.Context, id int64, opts ...pggen.GetOpt) (*Hole, error)
	ListHole(ctx context.Context, ids []int64, opts ...pggen.ListOpt) ([]Hole, error)
	InsertHole(ctx context.Context, value *Hole, opts ...pggen.InsertOpt) (int64, error)
	BulkInsertHole(ctx context.Context, values []Hole, opts ...pggen.InsertOpt) ([]int64, error)
	UpdateHole(ctx context.Context, value *Hole, fieldMask pggen.FieldSet, opts ...pggen.UpdateOpt) (ret int64, err error)
	UpsertHole(ctx context.Context, value *Hole, constraintNames []string, fieldMask pggen.FieldSet, opts ...pggen.UpsertOpt) (int64, error)
	BulkUpsertHole(ctx context.Context, values []Hole, constraintNames []string, fieldMask pggen.FieldSet, opts ...pggen.UpsertOpt) ([]int64, error)
	DeleteHole(ctx context.Context, id int64, opts ...pggen.DeleteOpt) error
	BulkDeleteHole(ctx context.Context, ids []int64, opts ...pggen.DeleteOpt) error
	HoleFillIncludes(ctx context.Context, rec *Hole, includes *include.Spec, opts ...pggen.IncludeOpt) error
	HoleBulkFillIncludes(ctx context.Context, recs []*Hole, includes *include.Spec, opts ...pggen.IncludeOpt) error

	// Match methods
	GetMatch(ctx context.Context, id int64, opts ...pggen.GetOpt) (*Match, error)
	ListMatch(ctx context.Context, ids []int64, opts ...pggen.ListOpt) ([]Match, error)
	InsertMatch(ctx context.Context, value *Match, opts ...pggen.InsertOpt) (int64, error)
	BulkInsertMatch(ctx context.Context, values []Match, opts ...pggen.InsertOpt) ([]int64, error)
	UpdateMatch(ctx context.Context, value *Match, fieldMask pggen.FieldSet, opts ...pggen.UpdateOpt) (ret int64, err error)
	UpsertMatch(ctx context.Context, value *Match, constraintNames []string, fieldMask pggen.FieldSet, opts ...pggen.UpsertOpt) (int64, error)
	BulkUpsertMatch(ctx context.Context, values []Match, constraintNames []string, fieldMask pggen.FieldSet, opts ...pggen.UpsertOpt) ([]int64, error)
	DeleteMatch(ctx context.Context, id int64, opts ...pggen.DeleteOpt) error
	BulkDeleteMatch(ctx context.Context, ids []int64, opts ...pggen.DeleteOpt) error
	MatchFillIncludes(ctx context.Context, rec *Match, includes *include.Spec, opts ...pggen.IncludeOpt) error
	MatchBulkFillIncludes(ctx context.Context, recs []*Match, includes *include.Spec, opts ...pggen.IncludeOpt) error

	// MatchParticipant methods
	GetMatchParticipant(ctx context.Context, id int64, opts ...pggen.GetOpt) (*MatchParticipant, error)
	ListMatchParticipant(ctx context.Context, ids []int64, opts ...pggen.ListOpt) ([]MatchParticipant, error)
	InsertMatchParticipant(ctx context.Context, value *MatchParticipant, opts ...pggen.InsertOpt) (int64, error)
	BulkInsertMatchParticipant(ctx context.Context, values []MatchParticipant, opts ...pggen.InsertOpt) ([]int64, error)
	UpdateMatchParticipant(ctx context.Context, value *MatchParticipant, fieldMask pggen.FieldSet, opts ...pggen.UpdateOpt) (ret int64, err error)
	UpsertMatchParticipant(ctx context.Context, value *MatchParticipant, constraintNames []string, fieldMask pggen.FieldSet, opts ...pggen.UpsertOpt) (int64, error)
	BulkUpsertMatchParticipant(ctx context.Context, values []MatchParticipant, constraintNames []string, fieldMask pggen.FieldSet, opts ...pggen.UpsertOpt) ([]int64, error)
	DeleteMatchParticipant(ctx context.Context, id int64, opts ...pggen.DeleteOpt) error
	BulkDeleteMatchParticipant(ctx context.Context, ids []int64, opts ...pggen.DeleteOpt) error
	MatchParticipantFillIncludes(ctx context.Context, rec *MatchParticipant, includes *include.Spec, opts ...pggen.IncludeOpt) error
	MatchParticipantBulkFillIncludes(ctx context.Context, recs []*MatchParticipant, includes *include.Spec, opts ...pggen.IncludeOpt) error

	// MatchStroke methods
	GetMatchStroke(ctx context.Context, id int64, opts ...pggen.GetOpt) (*MatchStroke, error)
	ListMatchStroke(ctx context.Context, ids []int64, opts ...pggen.ListOpt) ([]MatchStroke, error)
	InsertMatchStroke(ctx context.Context, value *MatchStroke, opts ...pggen.InsertOpt) (int64, error)
	BulkInsertMatchStroke(ctx context.Context, values []MatchStroke, opts ...pggen.InsertOpt) ([]int64, error)
	UpdateMatchStroke(ctx context.Context, value *MatchStroke, fieldMask pggen.FieldSet, opts ...pggen.UpdateOpt) (ret int64, err error)
	UpsertMatchStroke(ctx context.Context, value *MatchStroke, constraintNames []string, fieldMask pggen.FieldSet, opts ...pggen.UpsertOpt) (int64, error)
	BulkUpsertMatchStroke(ctx context.Context, values []MatchStroke, constraintNames []string, fieldMask pggen.FieldSet, opts ...pggen.UpsertOpt) ([]int64, error)
	DeleteMatchStroke(ctx context.Context, id int64, opts ...pggen.DeleteOpt) error
	BulkDeleteMatchStroke(ctx context.Context, ids []int64, opts ...pggen.DeleteOpt) error
	MatchStrokeFillIncludes(ctx context.Context, rec *MatchStroke, includes *include.Spec, opts ...pggen.IncludeOpt) error
	MatchStrokeBulkFillIncludes(ctx context.Context, recs []*MatchStroke, includes *include.Spec, opts ...pggen.IncludeOpt) error

	//
	// query methods
	//

	// GetAllLocations query
	GetAllLocations(
		ctx context.Context,
	) ([]Location, error)
	GetAllLocationsQuery(
		ctx context.Context,
	) (*sql.Rows, error)

	// GetCoursesAtLocation query
	GetCoursesAtLocation(
		ctx context.Context,
		locationId int64,
	) ([]Course, error)
	GetCoursesAtLocationQuery(
		ctx context.Context,
		locationId int64,
	) (*sql.Rows, error)

	// GetHolesAtCourse query
	GetHolesAtCourse(
		ctx context.Context,
		courseId int64,
	) ([]Hole, error)
	GetHolesAtCourseQuery(
		ctx context.Context,
		courseId int64,
	) (*sql.Rows, error)

	//
	// stored function methods
	//

	//
	// stmt methods
	//

}

type MatchParticipant struct {
	Id        int64 `gorm:"column:id;is_primary"`
	AccountId int64 `gorm:"column:account_id"`
	MatchId   int64 `gorm:"column:match_id"`
	Match     *Match
	Account   *Account
}

func (r *MatchParticipant) Scan(ctx context.Context, client *PGClient, rs *sql.Rows) error {
	client.rwlockForMatchParticipant.RLock()
	if client.colIdxTabForMatchParticipant == nil {
		client.rwlockForMatchParticipant.RUnlock() // release the lock to allow the write lock to be aquired
		err := client.fillColPosTab(
			ctx,
			genTimeColIdxTabForMatchParticipant,
			&client.rwlockForMatchParticipant,
			rs,
			&client.colIdxTabForMatchParticipant,
		)
		if err != nil {
			return err
		}
		client.rwlockForMatchParticipant.RLock() // get the lock back for the rest of the routine
	}

	var nullableTgts nullableScanTgtsForMatchParticipant

	scanTgts := make([]interface{}, len(client.colIdxTabForMatchParticipant))
	for runIdx, genIdx := range client.colIdxTabForMatchParticipant {
		if genIdx == -1 {
			scanTgts[runIdx] = &pggenSinkScanner{}
		} else {
			scanTgts[runIdx] = scannerTabForMatchParticipant[genIdx](r, &nullableTgts)
		}
	}
	client.rwlockForMatchParticipant.RUnlock() // we are now done referencing the idx tab in the happy path

	err := rs.Scan(scanTgts...)
	if err != nil {
		// The database schema may have been changed out from under us, let's
		// check to see if we just need to update our column index tables and retry.
		colNames, colsErr := rs.Columns()
		if colsErr != nil {
			return fmt.Errorf("pggen: checking column names: %s", colsErr.Error())
		}
		client.rwlockForMatchParticipant.RLock()
		if len(client.colIdxTabForMatchParticipant) != len(colNames) {
			client.rwlockForMatchParticipant.RUnlock() // release the lock to allow the write lock to be aquired
			err = client.fillColPosTab(
				ctx,
				genTimeColIdxTabForMatchParticipant,
				&client.rwlockForMatchParticipant,
				rs,
				&client.colIdxTabForMatchParticipant,
			)
			if err != nil {
				return err
			}

			return r.Scan(ctx, client, rs)
		} else {
			client.rwlockForMatchParticipant.RUnlock()
			return err
		}
	}

	return nil
}

type nullableScanTgtsForMatchParticipant struct {
}

// a table mapping codegen-time col indicies to functions returning a scanner for the
// field that was at that column index at codegen-time.
var scannerTabForMatchParticipant = [...]func(*MatchParticipant, *nullableScanTgtsForMatchParticipant) interface{}{
	func(
		r *MatchParticipant,
		nullableTgts *nullableScanTgtsForMatchParticipant,
	) interface{} {
		return &(r.Id)
	},
	func(
		r *MatchParticipant,
		nullableTgts *nullableScanTgtsForMatchParticipant,
	) interface{} {
		return &(r.AccountId)
	},
	func(
		r *MatchParticipant,
		nullableTgts *nullableScanTgtsForMatchParticipant,
	) interface{} {
		return &(r.MatchId)
	},
}

var genTimeColIdxTabForMatchParticipant map[string]int = map[string]int{
	`id`:         0,
	`account_id`: 1,
	`match_id`:   2,
}

type MatchStroke struct {
	Id         int64 `gorm:"column:id;is_primary"`
	AccountId  int64 `gorm:"column:account_id"`
	MatchId    int64 `gorm:"column:match_id"`
	HoleId     int64 `gorm:"column:hole_id"`
	MatchOrder int64 `gorm:"column:match_order"`
	Strokes    int64 `gorm:"column:strokes"`
	Hole       *Hole
	Match      *Match
	Account    *Account
}

func (r *MatchStroke) Scan(ctx context.Context, client *PGClient, rs *sql.Rows) error {
	client.rwlockForMatchStroke.RLock()
	if client.colIdxTabForMatchStroke == nil {
		client.rwlockForMatchStroke.RUnlock() // release the lock to allow the write lock to be aquired
		err := client.fillColPosTab(
			ctx,
			genTimeColIdxTabForMatchStroke,
			&client.rwlockForMatchStroke,
			rs,
			&client.colIdxTabForMatchStroke,
		)
		if err != nil {
			return err
		}
		client.rwlockForMatchStroke.RLock() // get the lock back for the rest of the routine
	}

	var nullableTgts nullableScanTgtsForMatchStroke

	scanTgts := make([]interface{}, len(client.colIdxTabForMatchStroke))
	for runIdx, genIdx := range client.colIdxTabForMatchStroke {
		if genIdx == -1 {
			scanTgts[runIdx] = &pggenSinkScanner{}
		} else {
			scanTgts[runIdx] = scannerTabForMatchStroke[genIdx](r, &nullableTgts)
		}
	}
	client.rwlockForMatchStroke.RUnlock() // we are now done referencing the idx tab in the happy path

	err := rs.Scan(scanTgts...)
	if err != nil {
		// The database schema may have been changed out from under us, let's
		// check to see if we just need to update our column index tables and retry.
		colNames, colsErr := rs.Columns()
		if colsErr != nil {
			return fmt.Errorf("pggen: checking column names: %s", colsErr.Error())
		}
		client.rwlockForMatchStroke.RLock()
		if len(client.colIdxTabForMatchStroke) != len(colNames) {
			client.rwlockForMatchStroke.RUnlock() // release the lock to allow the write lock to be aquired
			err = client.fillColPosTab(
				ctx,
				genTimeColIdxTabForMatchStroke,
				&client.rwlockForMatchStroke,
				rs,
				&client.colIdxTabForMatchStroke,
			)
			if err != nil {
				return err
			}

			return r.Scan(ctx, client, rs)
		} else {
			client.rwlockForMatchStroke.RUnlock()
			return err
		}
	}

	return nil
}

type nullableScanTgtsForMatchStroke struct {
}

// a table mapping codegen-time col indicies to functions returning a scanner for the
// field that was at that column index at codegen-time.
var scannerTabForMatchStroke = [...]func(*MatchStroke, *nullableScanTgtsForMatchStroke) interface{}{
	func(
		r *MatchStroke,
		nullableTgts *nullableScanTgtsForMatchStroke,
	) interface{} {
		return &(r.Id)
	},
	func(
		r *MatchStroke,
		nullableTgts *nullableScanTgtsForMatchStroke,
	) interface{} {
		return &(r.AccountId)
	},
	func(
		r *MatchStroke,
		nullableTgts *nullableScanTgtsForMatchStroke,
	) interface{} {
		return &(r.MatchId)
	},
	func(
		r *MatchStroke,
		nullableTgts *nullableScanTgtsForMatchStroke,
	) interface{} {
		return &(r.HoleId)
	},
	func(
		r *MatchStroke,
		nullableTgts *nullableScanTgtsForMatchStroke,
	) interface{} {
		return &(r.MatchOrder)
	},
	func(
		r *MatchStroke,
		nullableTgts *nullableScanTgtsForMatchStroke,
	) interface{} {
		return &(r.Strokes)
	},
}

var genTimeColIdxTabForMatchStroke map[string]int = map[string]int{
	`id`:          0,
	`account_id`:  1,
	`match_id`:    2,
	`hole_id`:     3,
	`match_order`: 4,
	`strokes`:     5,
}

type Match struct {
	Id                int64               `gorm:"column:id;is_primary"`
	CourseId          *int64              `gorm:"column:course_id"`
	MatchParticipants []*MatchParticipant `gorm:"foreignKey:MatchId"`
	MatchStrokes      []*MatchStroke      `gorm:"foreignKey:MatchId"`
	Course            *Course
}

func (r *Match) Scan(ctx context.Context, client *PGClient, rs *sql.Rows) error {
	client.rwlockForMatch.RLock()
	if client.colIdxTabForMatch == nil {
		client.rwlockForMatch.RUnlock() // release the lock to allow the write lock to be aquired
		err := client.fillColPosTab(
			ctx,
			genTimeColIdxTabForMatch,
			&client.rwlockForMatch,
			rs,
			&client.colIdxTabForMatch,
		)
		if err != nil {
			return err
		}
		client.rwlockForMatch.RLock() // get the lock back for the rest of the routine
	}

	var nullableTgts nullableScanTgtsForMatch

	scanTgts := make([]interface{}, len(client.colIdxTabForMatch))
	for runIdx, genIdx := range client.colIdxTabForMatch {
		if genIdx == -1 {
			scanTgts[runIdx] = &pggenSinkScanner{}
		} else {
			scanTgts[runIdx] = scannerTabForMatch[genIdx](r, &nullableTgts)
		}
	}
	client.rwlockForMatch.RUnlock() // we are now done referencing the idx tab in the happy path

	err := rs.Scan(scanTgts...)
	if err != nil {
		// The database schema may have been changed out from under us, let's
		// check to see if we just need to update our column index tables and retry.
		colNames, colsErr := rs.Columns()
		if colsErr != nil {
			return fmt.Errorf("pggen: checking column names: %s", colsErr.Error())
		}
		client.rwlockForMatch.RLock()
		if len(client.colIdxTabForMatch) != len(colNames) {
			client.rwlockForMatch.RUnlock() // release the lock to allow the write lock to be aquired
			err = client.fillColPosTab(
				ctx,
				genTimeColIdxTabForMatch,
				&client.rwlockForMatch,
				rs,
				&client.colIdxTabForMatch,
			)
			if err != nil {
				return err
			}

			return r.Scan(ctx, client, rs)
		} else {
			client.rwlockForMatch.RUnlock()
			return err
		}
	}
	r.CourseId = convertNullInt64(nullableTgts.scanCourseId)

	return nil
}

type nullableScanTgtsForMatch struct {
	scanCourseId sql.NullInt64
}

// a table mapping codegen-time col indicies to functions returning a scanner for the
// field that was at that column index at codegen-time.
var scannerTabForMatch = [...]func(*Match, *nullableScanTgtsForMatch) interface{}{
	func(
		r *Match,
		nullableTgts *nullableScanTgtsForMatch,
	) interface{} {
		return &(r.Id)
	},
	func(
		r *Match,
		nullableTgts *nullableScanTgtsForMatch,
	) interface{} {
		return &(nullableTgts.scanCourseId)
	},
}

var genTimeColIdxTabForMatch map[string]int = map[string]int{
	`id`:        0,
	`course_id`: 1,
}

type Hole struct {
	Id           int64          `gorm:"column:id;is_primary"`
	CourseId     *int64         `gorm:"column:course_id"`
	CourseOrder  int64          `gorm:"column:course_order"`
	Par          int64          `gorm:"column:par"`
	MatchStrokes []*MatchStroke `gorm:"foreignKey:HoleId"`
	Course       *Course
}

func (r *Hole) Scan(ctx context.Context, client *PGClient, rs *sql.Rows) error {
	client.rwlockForHole.RLock()
	if client.colIdxTabForHole == nil {
		client.rwlockForHole.RUnlock() // release the lock to allow the write lock to be aquired
		err := client.fillColPosTab(
			ctx,
			genTimeColIdxTabForHole,
			&client.rwlockForHole,
			rs,
			&client.colIdxTabForHole,
		)
		if err != nil {
			return err
		}
		client.rwlockForHole.RLock() // get the lock back for the rest of the routine
	}

	var nullableTgts nullableScanTgtsForHole

	scanTgts := make([]interface{}, len(client.colIdxTabForHole))
	for runIdx, genIdx := range client.colIdxTabForHole {
		if genIdx == -1 {
			scanTgts[runIdx] = &pggenSinkScanner{}
		} else {
			scanTgts[runIdx] = scannerTabForHole[genIdx](r, &nullableTgts)
		}
	}
	client.rwlockForHole.RUnlock() // we are now done referencing the idx tab in the happy path

	err := rs.Scan(scanTgts...)
	if err != nil {
		// The database schema may have been changed out from under us, let's
		// check to see if we just need to update our column index tables and retry.
		colNames, colsErr := rs.Columns()
		if colsErr != nil {
			return fmt.Errorf("pggen: checking column names: %s", colsErr.Error())
		}
		client.rwlockForHole.RLock()
		if len(client.colIdxTabForHole) != len(colNames) {
			client.rwlockForHole.RUnlock() // release the lock to allow the write lock to be aquired
			err = client.fillColPosTab(
				ctx,
				genTimeColIdxTabForHole,
				&client.rwlockForHole,
				rs,
				&client.colIdxTabForHole,
			)
			if err != nil {
				return err
			}

			return r.Scan(ctx, client, rs)
		} else {
			client.rwlockForHole.RUnlock()
			return err
		}
	}
	r.CourseId = convertNullInt64(nullableTgts.scanCourseId)

	return nil
}

type nullableScanTgtsForHole struct {
	scanCourseId sql.NullInt64
}

// a table mapping codegen-time col indicies to functions returning a scanner for the
// field that was at that column index at codegen-time.
var scannerTabForHole = [...]func(*Hole, *nullableScanTgtsForHole) interface{}{
	func(
		r *Hole,
		nullableTgts *nullableScanTgtsForHole,
	) interface{} {
		return &(r.Id)
	},
	func(
		r *Hole,
		nullableTgts *nullableScanTgtsForHole,
	) interface{} {
		return &(nullableTgts.scanCourseId)
	},
	func(
		r *Hole,
		nullableTgts *nullableScanTgtsForHole,
	) interface{} {
		return &(r.CourseOrder)
	},
	func(
		r *Hole,
		nullableTgts *nullableScanTgtsForHole,
	) interface{} {
		return &(r.Par)
	},
}

var genTimeColIdxTabForHole map[string]int = map[string]int{
	`id`:           0,
	`course_id`:    1,
	`course_order`: 2,
	`par`:          3,
}

type Course struct {
	Id         int64    `gorm:"column:id;is_primary"`
	LocationId *int64   `gorm:"column:location_id"`
	Name       string   `gorm:"column:name"`
	Holes      []*Hole  `gorm:"foreignKey:CourseId"`
	Matches    []*Match `gorm:"foreignKey:CourseId"`
	Location   *Location
}

func (r *Course) Scan(ctx context.Context, client *PGClient, rs *sql.Rows) error {
	client.rwlockForCourse.RLock()
	if client.colIdxTabForCourse == nil {
		client.rwlockForCourse.RUnlock() // release the lock to allow the write lock to be aquired
		err := client.fillColPosTab(
			ctx,
			genTimeColIdxTabForCourse,
			&client.rwlockForCourse,
			rs,
			&client.colIdxTabForCourse,
		)
		if err != nil {
			return err
		}
		client.rwlockForCourse.RLock() // get the lock back for the rest of the routine
	}

	var nullableTgts nullableScanTgtsForCourse

	scanTgts := make([]interface{}, len(client.colIdxTabForCourse))
	for runIdx, genIdx := range client.colIdxTabForCourse {
		if genIdx == -1 {
			scanTgts[runIdx] = &pggenSinkScanner{}
		} else {
			scanTgts[runIdx] = scannerTabForCourse[genIdx](r, &nullableTgts)
		}
	}
	client.rwlockForCourse.RUnlock() // we are now done referencing the idx tab in the happy path

	err := rs.Scan(scanTgts...)
	if err != nil {
		// The database schema may have been changed out from under us, let's
		// check to see if we just need to update our column index tables and retry.
		colNames, colsErr := rs.Columns()
		if colsErr != nil {
			return fmt.Errorf("pggen: checking column names: %s", colsErr.Error())
		}
		client.rwlockForCourse.RLock()
		if len(client.colIdxTabForCourse) != len(colNames) {
			client.rwlockForCourse.RUnlock() // release the lock to allow the write lock to be aquired
			err = client.fillColPosTab(
				ctx,
				genTimeColIdxTabForCourse,
				&client.rwlockForCourse,
				rs,
				&client.colIdxTabForCourse,
			)
			if err != nil {
				return err
			}

			return r.Scan(ctx, client, rs)
		} else {
			client.rwlockForCourse.RUnlock()
			return err
		}
	}
	r.LocationId = convertNullInt64(nullableTgts.scanLocationId)

	return nil
}

type nullableScanTgtsForCourse struct {
	scanLocationId sql.NullInt64
}

// a table mapping codegen-time col indicies to functions returning a scanner for the
// field that was at that column index at codegen-time.
var scannerTabForCourse = [...]func(*Course, *nullableScanTgtsForCourse) interface{}{
	func(
		r *Course,
		nullableTgts *nullableScanTgtsForCourse,
	) interface{} {
		return &(r.Id)
	},
	func(
		r *Course,
		nullableTgts *nullableScanTgtsForCourse,
	) interface{} {
		return &(nullableTgts.scanLocationId)
	},
	func(
		r *Course,
		nullableTgts *nullableScanTgtsForCourse,
	) interface{} {
		return &(r.Name)
	},
}

var genTimeColIdxTabForCourse map[string]int = map[string]int{
	`id`:          0,
	`location_id`: 1,
	`name`:        2,
}

type Location struct {
	Id      int64     `gorm:"column:id;is_primary"`
	Name    string    `gorm:"column:name"`
	Courses []*Course `gorm:"foreignKey:LocationId"`
}

func (r *Location) Scan(ctx context.Context, client *PGClient, rs *sql.Rows) error {
	client.rwlockForLocation.RLock()
	if client.colIdxTabForLocation == nil {
		client.rwlockForLocation.RUnlock() // release the lock to allow the write lock to be aquired
		err := client.fillColPosTab(
			ctx,
			genTimeColIdxTabForLocation,
			&client.rwlockForLocation,
			rs,
			&client.colIdxTabForLocation,
		)
		if err != nil {
			return err
		}
		client.rwlockForLocation.RLock() // get the lock back for the rest of the routine
	}

	var nullableTgts nullableScanTgtsForLocation

	scanTgts := make([]interface{}, len(client.colIdxTabForLocation))
	for runIdx, genIdx := range client.colIdxTabForLocation {
		if genIdx == -1 {
			scanTgts[runIdx] = &pggenSinkScanner{}
		} else {
			scanTgts[runIdx] = scannerTabForLocation[genIdx](r, &nullableTgts)
		}
	}
	client.rwlockForLocation.RUnlock() // we are now done referencing the idx tab in the happy path

	err := rs.Scan(scanTgts...)
	if err != nil {
		// The database schema may have been changed out from under us, let's
		// check to see if we just need to update our column index tables and retry.
		colNames, colsErr := rs.Columns()
		if colsErr != nil {
			return fmt.Errorf("pggen: checking column names: %s", colsErr.Error())
		}
		client.rwlockForLocation.RLock()
		if len(client.colIdxTabForLocation) != len(colNames) {
			client.rwlockForLocation.RUnlock() // release the lock to allow the write lock to be aquired
			err = client.fillColPosTab(
				ctx,
				genTimeColIdxTabForLocation,
				&client.rwlockForLocation,
				rs,
				&client.colIdxTabForLocation,
			)
			if err != nil {
				return err
			}

			return r.Scan(ctx, client, rs)
		} else {
			client.rwlockForLocation.RUnlock()
			return err
		}
	}

	return nil
}

type nullableScanTgtsForLocation struct {
}

// a table mapping codegen-time col indicies to functions returning a scanner for the
// field that was at that column index at codegen-time.
var scannerTabForLocation = [...]func(*Location, *nullableScanTgtsForLocation) interface{}{
	func(
		r *Location,
		nullableTgts *nullableScanTgtsForLocation,
	) interface{} {
		return &(r.Id)
	},
	func(
		r *Location,
		nullableTgts *nullableScanTgtsForLocation,
	) interface{} {
		return &(r.Name)
	},
}

var genTimeColIdxTabForLocation map[string]int = map[string]int{
	`id`:   0,
	`name`: 1,
}

type Account struct {
	Id                int64               `gorm:"column:id;is_primary"`
	Nickname          string              `gorm:"column:nickname"`
	Email             string              `gorm:"column:email"`
	MatchParticipants []*MatchParticipant `gorm:"foreignKey:AccountId"`
	MatchStrokes      []*MatchStroke      `gorm:"foreignKey:AccountId"`
}

func (r *Account) Scan(ctx context.Context, client *PGClient, rs *sql.Rows) error {
	client.rwlockForAccount.RLock()
	if client.colIdxTabForAccount == nil {
		client.rwlockForAccount.RUnlock() // release the lock to allow the write lock to be aquired
		err := client.fillColPosTab(
			ctx,
			genTimeColIdxTabForAccount,
			&client.rwlockForAccount,
			rs,
			&client.colIdxTabForAccount,
		)
		if err != nil {
			return err
		}
		client.rwlockForAccount.RLock() // get the lock back for the rest of the routine
	}

	var nullableTgts nullableScanTgtsForAccount

	scanTgts := make([]interface{}, len(client.colIdxTabForAccount))
	for runIdx, genIdx := range client.colIdxTabForAccount {
		if genIdx == -1 {
			scanTgts[runIdx] = &pggenSinkScanner{}
		} else {
			scanTgts[runIdx] = scannerTabForAccount[genIdx](r, &nullableTgts)
		}
	}
	client.rwlockForAccount.RUnlock() // we are now done referencing the idx tab in the happy path

	err := rs.Scan(scanTgts...)
	if err != nil {
		// The database schema may have been changed out from under us, let's
		// check to see if we just need to update our column index tables and retry.
		colNames, colsErr := rs.Columns()
		if colsErr != nil {
			return fmt.Errorf("pggen: checking column names: %s", colsErr.Error())
		}
		client.rwlockForAccount.RLock()
		if len(client.colIdxTabForAccount) != len(colNames) {
			client.rwlockForAccount.RUnlock() // release the lock to allow the write lock to be aquired
			err = client.fillColPosTab(
				ctx,
				genTimeColIdxTabForAccount,
				&client.rwlockForAccount,
				rs,
				&client.colIdxTabForAccount,
			)
			if err != nil {
				return err
			}

			return r.Scan(ctx, client, rs)
		} else {
			client.rwlockForAccount.RUnlock()
			return err
		}
	}

	return nil
}

type nullableScanTgtsForAccount struct {
}

// a table mapping codegen-time col indicies to functions returning a scanner for the
// field that was at that column index at codegen-time.
var scannerTabForAccount = [...]func(*Account, *nullableScanTgtsForAccount) interface{}{
	func(
		r *Account,
		nullableTgts *nullableScanTgtsForAccount,
	) interface{} {
		return &(r.Id)
	},
	func(
		r *Account,
		nullableTgts *nullableScanTgtsForAccount,
	) interface{} {
		return &(r.Nickname)
	},
	func(
		r *Account,
		nullableTgts *nullableScanTgtsForAccount,
	) interface{} {
		return &(r.Email)
	},
}

var genTimeColIdxTabForAccount map[string]int = map[string]int{
	`id`:       0,
	`nickname`: 1,
	`email`:    2,
}
var _ = unstable.NotFoundError{}
